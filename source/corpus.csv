Authors,Author(s) ID,Title,Year,Source title,DOI,Link,Abstract,Author Keywords,Index Keywords,References,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Lecun Y., Bengio Y., Hinton G.",55666793600;7003958245;7006699573;,Deep learning,2015,Nature,10.1038/nature14539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930630277&doi=10.1038%2fnature14539&partnerID=40&md5=e324cb9ec992f892ebc74f3e06078083,"Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. © 2015 Macmillan Publishers Limited. All rights reserved.",,data processing; data set; machine learning; parameterization; automatic speech recognition; classifier; deep learning; human; image processing; language processing; learning; learning algorithm; learning theory; machine learning; nonhuman; pattern recognition; priority journal; recognition; Review; speech discrimination; algorithm; artificial intelligence; artificial neural network; computer; language; trends; Algorithms; Artificial Intelligence; Computers; Language; Neural Networks (Computer),"Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) Proc. Advances in Neural Information Processing Systems, 25, pp. 1090-1098; Farabet, C., Couprie, C., Najman, L., Lecun, Y., Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35, pp. 1915-1929; Tompson, J., Jain, A., Lecun, Y., Bregler, C., Joint training of a convolutional network and a graphical model for human pose estimation (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 1799-1807; Szegedy, C., (2014) Going Deeper with Convolutions. Preprint at, , http://arxiv.org/abs/1409.4842; Mikolov, T., Deoras, A., Povey, D., Burget, L., Cernocky, J., Strategies for training large scale neural network language models (2011) Proc. Automatic Speech Recognition and Understanding, pp. 196-201; Hinton, G., Deep neural networks for acoustic modeling in speech recognition (2012) IEEE Signal Processing Magazine, 29, pp. 82-97; Sainath, T., Mohamed, A.-R., Kingsbury, B., Ramabhadran, B., Deep convolutional neural networks for LVCSR (2013) Proc. Acoustics, Speech and Signal Processing, pp. 8614-8618; Ma, J., Sheridan, R.P., Liaw, A., Dahl, G.E., Svetnik, V., Deep neural nets as a method for quantitative structure-activity relationships (2015) J. Chem. Inf. Model., 55, pp. 263-274; Ciodaro, T., Deva, D., De Seixas, J., Damazio, D., Online particle detection with neural networks based on topological calorimetry information (2012) J. Phys. Conf. Series, 368, p. 012030; (2014) Higgs Boson Machine Learning Challenge, , https://www.kaggle.com/c/higgs-boson, Kaggle; Helmstaedter, M., Connectomic reconstruction of the inner plexiform layer in the mouse retina (2013) Nature, 500, pp. 168-174; Leung, M.K., Xiong, H.Y., Lee, L.J., Frey, B.J., Deep learning of the tissue-regulated splicing code (2014) Bioinformatics, 30, pp. i121-i129; Xiong, H.Y., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347, p. 6218; Collobert, R., Natural language processing (almost) from scratch (2011) J. Mach. Learn. Res., 12, pp. 2493-2537; Bordes, A., Chopra, S., Weston, J., Question answering with subgraph embeddings (2014) Proc. Empirical Methods in Natural Language Processing, , http://arxiv.org/abs/1406.3676v3; Jean, S., Cho, K., Memisevic, R., Bengio, Y., On using very large target vocabulary for neural machine translation (2015) Proc. ACL-IJCNLP Http://arxiv. Org/ abs/1412. 2007; Sutskever Vinyals, I.O., Le., Q.V., Sequence to sequence learning with neural networks (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 3104-3112; Bottou, L., Bousquet, O., The tradeoffs of large scale learning (2007) Proc. Advances in Neural Information Processing Systems, 20, pp. 161-168; Duda, R.O., Hart, P.E., (1973) Pattern Classification and Scene Analysis, , Wiley; Schölkopf, B., Smola, A., (2002) Learning with Kernels, , MIT Press; Bengio, Y., Delalleau, O., Le Roux, N., The curse of highly variable functions for local kernel machines (2005) Proc. Advances in Neural Information Processing Systems, 18, pp. 107-114; Selfridge, O.G., Pandemonium: A paradigm for learning in mechanisation of thought processes (1958) Proc. Symposium on Mechanisation of Thought Processes, pp. 513-526; Rosenblatt, F., (1957) The Perceptron-A Perceiving and Recognizing Automaton, , Tech. Rep. 85-460-1 (Cornell Aeronautical Laboratory; Werbos, P., (1974) Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences, , PhD thesis, Harvard Univ; Parker, D.B., (1985) Learning Logic Report TR-47, , MIT Press; Lecun, Y., (1985) Une Procédure d'Apprentissage Pour Réseau À Seuil Assymétrique in Cognitiva 85: A la Frontière de l'Intelligence Artificielle des Sciences de la Connaissance et des Neurosciences, pp. 599-604. , in French; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks (2011) Proc. 14th International Conference on Artificial Intelligence and Statistics, pp. 315-323; Dauphin, Y., Identifying and attacking the saddle point problem in high-dimensional non-convex optimization (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 2933-2941; Choromanska, A., Henaff, M., Mathieu, M., Arous, G.B., Lecun, Y., The loss surface of multilayer networks (2014) Proc. Conference on AI and Statistics, , http://arxiv.org/abs/1412.0233; Hinton, G.E., What kind of graphical model is the brain (2005) Proc. 19th International Joint Conference on Artificial Intelligence, pp. 1765-1775; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comp., 18, pp. 1527-1554; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2006) Proc. Advances in Neural Information Processing Systems, 19, pp. 153-160; Ranzato, M., Poultney, C., Chopra, S., Lecun, Y., Efficient learning of sparse representations with an energy-based model (2006) Proc. Advances in Neural Information Processing Systems, 19, pp. 1137-1144; Hinton, G.E., Salakhutdinov, R., Reducing the dimensionality of data with neural networks (2006) Science, 313, pp. 504-507; Sermanet, P., Kavukcuoglu, K., Chintala, S., Lecun, Y., Pedestrian detection with unsupervised multi-stage feature learning (2013) Proc. International Conference on Computer Vision and Pattern Recognition, , http://arxiv.org/abs/1212.0142; Raina, R., Madhavan, A., Ng, A.Y., Large-scale deep unsupervised learning using graphics processors (2009) Proc. 26th Annual International Conference on Machine Learning, pp. 873-880; Mohamed, A.-R., Dahl, G.E., Hinton, G., Acoustic modeling using deep belief networks (2012) IEEE Trans. Audio Speech Lang. Process., 20, pp. 14-22; Dahl, G.E., Yu, D., Deng, L., Acero, A., Context-dependent pre-trained deep neural networks for large vocabulary speech recognition (2012) IEEE Trans. Audio Speech Lang. Process., 20, pp. 33-42; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Machine Intell., 35, pp. 1798-1828; Lecun, Y., Handwritten digit recognition with a back-propagation network (1990) Proc. Advances in Neural Information Processing Systems, pp. 396-404; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324; Hubel, D.H., Wiesel, T.N., Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex (1962) J. Physiol., 160, pp. 106-154; Felleman, D.J., Essen, D.C.V., Distributed hierarchical processing in the primate cerebral cortex (1991) Cereb. Cortex, 1, pp. 1-47; Cadieu, C.F., Deep neural networks rival the representation of primate it cortex for core visual object recognition (2014) PLoS Comp. Biol., 10, p. e1003963; Fukushima, K., Miyake, S., Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position (1982) Pattern Recognition, 15, pp. 455-469; Waibel, A., Hanazawa, T., Hinton, G.E., Shikano, K., Lang, K., Phoneme recognition using time-delay neural networks (1989) IEEE Trans. Acoustics Speech Signal Process., 37, pp. 328-339; Bottou, L., Fogelman-Soulié, F., Blanchet, P., Lienard, J., Experiments with time delay networks and dynamic time warping for speaker independent isolated digit recognition (1989) Proc. EuroSpeech, 89, pp. 537-540; Simard, D., Steinkraus, P.Y., Platt, J.C., Best practices for convolutional neural networks (2003) Proc. Document Analysis and Recognition, pp. 958-963; Vaillant, R., Monrocq, C., Lecun, Y., Original approach for the localisation of objects in images (1994) Proc. Vision, Image, and Signal Processing, 141, pp. 245-250; Nowlan, S., Platt, J., (1995) Neural Information Processing Systems, pp. 901-908; Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., Face recognition: A convolutional neural-network approach (1997) IEEE Trans. Neural Networks, 8, pp. 98-113; Ciresan, D., Meier Masci, U.J., Schmidhuber, J., Multi-column deep neural network for traffic sign classification (2012) Neural Networks, 32, pp. 333-338; Ning, F., Toward automatic phenotyping of developing embryos from videos (2005) IEEE Trans. Image Process., 14, pp. 1360-1371; Turaga, S.C., Convolutional networks can learn to generate affinity graphs for image segmentation (2010) Neural Comput., 22, pp. 511-538; Garcia, C., Delakis, M., Convolutional face finder: A neural architecture for fast and robust face detection (2004) IEEE Trans. Pattern Anal. Machine Intell., 26, pp. 1408-1423; Osadchy, M., Lecun, Y., Miller, M., Synergistic face detection and pose estimation with energy-based models (2007) J. Mach. Learn. Res., 8, pp. 1197-1215; Tompson, J., Goroshin, R.R., Jain, A., Lecun, Y.Y., Bregler, C.C., Efficient object localization using convolutional networks (2014) Proc. Conference on Computer Vision and Pattern Recognition, , http://arxiv.org/abs/1411.4280; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proc. Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Hadsell, R., Learning long-range vision for autonomous off-road driving (2009) J. Field Robot., 26, pp. 120-144; Farabet, C., Couprie, C., Najman, L., Lecun, Y., Scene parsing with multiscale feature learning, purity trees, and optimal covers (2012) Proc. International Conference on Machine Learning, , http://arxiv.org/abs/1202.2160; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) J. Machine Learning Res., 15, pp. 1929-1958; Sermanet, P., Overfeat: Integrated recognition, localization and detection using convolutional networks (2014) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1312.6229; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. Conference on Computer Vision and Pattern Recognition, pp. 580-587; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1409.1556; Boser, B., Sackinger, E., Bromley, J., Lecun, Y., Jackel, L., An analog neural network processor with programmable topology (1991) J. Solid State Circuits, 26, pp. 2017-2025; Farabet, C., Large-scale FPGA-based convolutional networks (2011) Scaling Up Machine Learning: Parallel and Distributed Approaches, pp. 399-419. , eds Bekkerman, R., Bilenko, M. & Langford, J. Cambridge Univ. Press; Bengio, Y., (2009) Learning Deep Architectures for AI (Now; Montufar, G., Morton, J., When does a mixture of products contain a product of mixtures (2014) J. Discrete Math., 29, pp. 321-347; Montufar, G.F., Pascanu, R., Cho, K., Bengio, Y., On the number of linear regions of deep neural networks (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 2924-2932; Bengio, Y., Ducharme, R., Vincent, P., A neural probabilistic language model (2001) Proc. Advances in Neural Information Processing Systems, 13, pp. 932-938; Cho, K., For statistical machine translation learning phrase representations using rnn encoder-decoder (2014) Proc Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734; Schwenk, H., Continuous space language models (2007) Computer Speech Lang., 21, pp. 492-518; Socher, R., Lin, C.C.-Y., Manning, C., Ng, A.Y., Parsing natural scenes and natural language with recursive neural networks (2011) Proc. International Conference on Machine Learning, pp. 129-136; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Proc. Advances in Neural Information Processing Systems, 26, pp. 3111-3119; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1409.0473; Hochreiter, S., (1991) Untersuchungen zu Dynamischen Neuronalen Netzen, , German] Diploma thesis, T. U. Münich; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Networks, 5, pp. 157-166; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9, pp. 1735-1780; Elhihi, S., Bengio, Y., Hierarchical recurrent neural networks for long-term dependencies (1995) Proc. Advances in Neural Information Processing Systems, 8. , http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-long-term-dependencies; Sutskever, I., (2012) Training Recurrent Neural Networks, , PhD thesis, Univ. Toronto; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) Proc. 30th International Conference on Machine Learning, pp. 1310-1318; Sutskever, I., Martens, J., Hinton, G.E., Generating text with recurrent neural networks (2011) Proc. 28th International Conference on Machine Learning, pp. 1017-1024; Lakoff, G., Johnson, M., Metaphors We Live by, 2008. , Univ Chicago Press; Rogers, T.T., McClelland, J.L., (2004) Semantic Cognition: A Parallel Distributed Processing Approach, , MIT Press; Xu, K., Show, attend and tell: Neural image caption generation with visual attention (2015) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1502.03044; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. International Conference on Acoustics, Speech and Signal Processing, pp. 6645-6649; Graves, A., Wayne, G., Danihelka, I., (2014) Neural Turing Machines, , http://arxiv.org/abs/1410.5401; Weston Chopra, J.S., Bordes, A., (2014) Memory Networks, , http://arxiv.org/abs/1410.3916; Weston, J., Bordes, A., Chopra, S., Mikolov, T., (2015) Towards AI-complete Question Answering: A Set of Prerequisite Toy Tasks, , http://arxiv.org/abs/1502.05698; Hinton, G.E., Dayan, P., Frey, B.J., Neal, R.M., The wake-sleep algorithm for unsupervised neural networks (1995) Science, 268, pp. 1558-1161; Salakhutdinov, R., Hinton, G., Deep Boltzmann machines (2009) Proc. International Conference on Artificial Intelligence and Statistics, pp. 448-455; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proc. 25th International Conference on Machine Learning, pp. 1096-1103; Kavukcuoglu, K., Learning convolutional feature hierarchies for visual recognition (2010) Proc. Advances in Neural Information Processing Systems, 23, pp. 1090-1098; Gregor, K., Lecun, Y., Learning fast approximations of sparse coding (2010) Proc. International Conference on Machine Learning, pp. 399-406; Ranzato, M., Mnih, V., Susskind, J.M., Hinton, G.E., Modeling natural images using gated MRFs (2013) IEEE Trans. Pattern Anal. Machine Intell., 35, pp. 2206-2222; Bengio, Y., Thibodeau-Laufer, E., Alain, G., Yosinski, J., Deep generative stochastic networks trainable by backprop (2014) Proc. 31st International Conference on Machine Learning, pp. 226-234; Kingma, D., Rezende, D., Mohamed, S., Welling, M., Semi-supervised learning with deep generative models (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 3581-3589; Ba, J., Mnih, V., Kavukcuoglu, K., Multiple object recognition with visual attention (2014) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1412.7755; Mnih, V., Human-level control through deep reinforcement learning (2015) Nature, 518, pp. 529-533; Bottou, L., From machine learning to machine reasoning (2014) Mach. Learn., 94, pp. 133-149; Vinyals, O., Toshev, A., Bengio, S., Erhan, D., Show and tell: A neural image caption generator (2014) Proc. International Conference on Machine Learning, , http://arxiv.org/abs/1502.03044; Van Der Maaten, L., Hinton, G.E., Visualizing data using t-SNE (2008) J. Mach. Learn. Research, 9, pp. 2579-2605",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Schmidhuber J.,7003514621;,Deep Learning in neural networks: An overview,2015,Neural Networks,10.1016/j.neunet.2014.09.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910651844&doi=10.1016%2fj.neunet.2014.09.003&partnerID=40&md5=1e380e40a7a616540c705ef8a63ce456,"In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks. © 2014.",Deep learning; Evolutionary computation; Reinforcement learning; Supervised learning; Unsupervised learning,Artificial intelligence; Backpropagation; Evolutionary algorithms; Neural networks; Pattern recognition; Recurrent neural networks; Supervised learning; Surveys; Unsupervised learning; Credit assignment; Deep learning; Large networks; Reinforcement learning; artificial intelligence; artificial neural network; automated pattern recognition; back propagation; computer language; deep learning; feedforward neural network; human; information processing; learning algorithm; machine learning; nnsupervised Learning; nonhuman; positive feedback; problem solving; process optimization; recurrent neural network; reinforcement learning; Review; short term memory; supervised learning; visual cortex; classification; standards; trends; Artificial Intelligence,"Aberdeen, D., (2003) Policy-gradient algorithms for partially observable Markov decision processes, , (Ph.D. thesis), Australian National University; Abounadi, J., Bertsekas, D., Borkar, V.S., Learning algorithms for Markov decision processes with average cost (2002) SIAM Journal on Control and Optimization, 40 (3), pp. 681-698; Akaike, H., Statistical predictor identification (1970) Annals of the Institute of Statistical Mathematics, 22, pp. 203-217; Akaike, H., Information theory and an extension of the maximum likelihood principle (1973) Second intl. symposium on information theory, pp. 267-281. , Akademinai Kiado; Akaike, H., A new look at the statistical model identification (1974) IEEE Transactions on Automatic Control, 19 (6), pp. 716-723; Allender, A., Application of time-bounded Kolmogorov complexity in complexity theory (1992) EATCS monographs on theoretical computer science, pp. 6-22. , Springer, O. Watanabe (Ed.) Kolmogorov complexity and computational complexity; Almeida, L.B., A learning rule for asynchronous perceptrons with feedback in a combinatorial environment (1987) IEEE 1st international conference on neural networks, 2, pp. 609-618; Almeida, L.B., Almeida, L.B., Langlois, T., Amaral, J.D., Redol, R.A., (1997) On-line step size adaptation. Technical report, INESC, 9 Rua Alves Redol, 1000; Amari, S., A theory of adaptive pattern classifiers (1967) IEEE Transactions on Electronic Computers, 16 (3), pp. 299-307; Amari, S.-I., Natural gradient works efficiently in learning (1998) Neural Computation, 10 (2), pp. 251-276; Amari, S., Cichocki, A., Yang, H., A new learning algorithm for blind signal separation (1996) Advances in neural information processing systems (NIPS), vol. 8, , The MIT Press, D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.); Amari, S., Murata, N., Statistical theory of learning curves under entropic loss criterion (1993) Neural Computation, 5 (1), pp. 140-153; Amit, D.J., Brunel, N., Dynamics of a recurrent network of spiking neurons before and following learning (1997) Network: Computation in Neural Systems, 8 (4), pp. 373-404; An, G., The effects of adding noise during backpropagation training on a generalization performance (1996) Neural Computation, 8 (3), pp. 643-674; Andrade, M.A., Chacon, P., Merelo, J.J., Moran, F., Evaluation of secondary structure of proteins from UV circular dichroism spectra using an unsupervised learning neural network (1993) Protein Engineering, 6 (4), pp. 383-390; Andrews, R., Diederich, J., Tickle, A.B., Survey and critique of techniques for extracting rules from trained artificial neural networks (1995) Knowledge-Based Systems, 8 (6), pp. 373-389; Anguita, D., Gomes, B.A., Mixing floating- and fixed-point formats for neural network learning on neuroprocessors (1996) Microprocessing and Microprogramming, 41 (10), pp. 757-769; Anguita, D., Parodi, G., Zunino, R., An efficient implementation of BP on RISC-based workstations (1994) Neurocomputing, 6 (1), pp. 57-65; Arel, I., Rose, D.C., Karnowski, T.P., Deep machine learning-a new frontier in artificial intelligence research (2010) IEEE Computational Intelligence Magazine, 5 (4), pp. 13-18; Ash, T., Dynamic node creation in backpropagation neural networks (1989) Connection Science, 1 (4), pp. 365-375; Atick, J.J., Li, Z., Redlich, A.N., Understanding retinal color coding from first principles (1992) Neural Computation, 4, pp. 559-572; Atiya, A.F., Parlos, A.G., New results on recurrent network training: unifying the algorithms and accelerating convergence (2000) IEEE Transactions on Neural Networks, 11 (3), pp. 697-709; Ba, J., Frey, B., Adaptive dropout for training deep neural networks (2013) Advances in neural information processing systems (NIPS), pp. 3084-3092; Baird, H., (1990) Document image defect models, , Proceddings, IAPR workshop on syntactic and structural pattern recognition; Baird, L.C., Residual algorithms: Reinforcement learning with function approximation (1995) International conference on machine learning, pp. 30-37; Baird, L., Moore, A.W., Gradient descent for general reinforcement learning (1999) Advances in neural information processing systems, vol. 12 (NIPS), pp. 968-974. , MIT Press; Bakker, B., Reinforcement learning with long short-term memory (2002) Advances in neural information processing systems, vol. 14, pp. 1475-1482. , MIT Press, Cambridge, MA, T.G. Dietterich, S. Becker, Z. Ghahramani (Eds.); Bakker, B., Schmidhuber, J., Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization (2004) Proc. 8th conference on intelligent autonomous systems IAS-8, pp. 438-445. , IOS Press, Amsterdam, NL, F. Groen (Ed.); Bakker, B., Zhumatiy, V., Gruener, G., Schmidhuber, J., A robot that reinforcement-learns to identify and memorize important previous observations (2003), pp. 430-435. , Proceedings of the 2003 IEEE/RSJ international conference on intelligent robots and systems; Baldi, P., Gradient descent learning algorithms overview: A general dynamical systems perspective (1995) IEEE Transactions on Neural Networks, 6 (1), pp. 182-195; Baldi, P., Autoencoders, unsupervised learning, and deep architectures (2012) Journal of Machine Learning Research, 27, pp. 37-50. , (Proc. 2011 ICML Workshop on Unsupervised and Transfer Learning); Baldi, P., Brunak, S., Frasconi, P., Pollastri, G., Soda, G., Exploiting the past and the future in protein secondary structure prediction (1999) Bioinformatics, 15, pp. 937-946; Baldi, P., Chauvin, Y., Neural networks for fingerprint recognition (1993) Neural Computation, 5 (3), pp. 402-418; Baldi, P., Chauvin, Y., Hybrid modeling, HMM/NN architectures, and protein applications (1996) Neural Computation, 8 (7), pp. 1541-1565; Baldi, P., Hornik, K., Neural networks and principal component analysis: learning from examples without local minima (1989) Neural Networks, 2, pp. 53-58; Baldi, P., Hornik, K., Learning in linear networks: a survey (1995) IEEE Transactions on Neural Networks, 6 (4), pp. 837-858. , 1995; Baldi, P., Pollastri, G., The principled design of large-scale recursive neural network architectures-DAG-RNNs and the protein structure prediction problem (2003) Journal of Machine Learning Research, 4, pp. 575-602; Baldi, P., Sadowski, P., The dropout learning algorithm (2014) Artificial Intelligence, 210 C, pp. 78-122; Ballard, D.H., Modular learning in neural networks (1987) Proc. AAAI, pp. 279-284; Baluja, S., (1994) Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning. Technical report CMU-CS-94-163, , Carnegie Mellon University; Balzer, R., A 15 year perspective on automatic programming (1985) IEEE Transactions on Software Engineering, 11 (11), pp. 1257-1268; Barlow, H.B., Unsupervised learning (1989) Neural Computation, 1 (3), pp. 295-311; Barlow, H.B., Kaushal, T.P., Mitchison, G.J., Finding minimum entropy codes (1989) Neural Computation, 1 (3), pp. 412-423; Barrow, H.G., Learning receptive fields (1987) Proceedings of the IEEE 1st annual conference on neural networks, vol. IV, pp. 115-121. , IEEE; Barto, A.G., Mahadevan, S., Recent advances in hierarchical reinforcement learning (2003) Discrete Event Dynamic Systems, 13 (4), pp. 341-379; Barto, A.G., Singh, S., Chentanez, N., Intrinsically motivated learning of hierarchical collections of skills (2004) Proceedings of international conference on developmental learning, pp. 112-119. , MIT Press, Cambridge, MA; Barto, A.G., Sutton, R.S., Anderson, C.W., Neuronlike adaptive elements that can solve difficult learning control problems (1983) IEEE Transactions on Systems, Man and Cybernetics, SMC-13, pp. 834-846; Battiti, R., Accelerated backpropagation learning: two optimization methods (1989) Complex Systems, 3 (4), pp. 331-342; Battiti, T., First- and second-order methods for learning: between steepest descent and Newton's method (1992) Neural Computation, 4 (2), pp. 141-166; Baum, E.B., Haussler, D., What size net gives valid generalization? (1989) Neural Computation, 1 (1), pp. 151-160; Baum, L.E., Petrie, T., Statistical inference for probabilistic functions of finite state Markov chains (1966) The Annals of Mathematical Statistics, pp. 1554-1563; Baxter, J., Bartlett, P.L., Infinite-horizon policy-gradient estimation (2001) Journal of Artificial Intelligence Research, 15 (1), pp. 319-350; Bayer, J., Osendorfer, C., (2014) Variational inference of latent state sequences using recurrent networks, , arxiv:1406.1655, ArXiv Preprint ; Bayer, J., Osendorfer, C., Chen, N., Urban, S., van der Smagt, P., (2013) On fast dropout and its applicability to recurrent networks, , arxiv:1311.0701. ArXiv Preprint; Bayer, J., Wierstra, D., Togelius, J., Schmidhuber, J., Evolving memory cell structures for sequence learning (2009) Proc. ICANN, (2), pp. 755-764; Bayes, T., An essay toward solving a problem in the doctrine of chances (1763) Philosophical Transactions of the Royal Society of London, 53, pp. 370-418. , Communicated by R. Price, in a letter to J. Canton; Becker, S., Unsupervised learning procedures for neural networks (1991) International Journal of Neural Systems, 2 (1-2), pp. 17-33; Becker, S., Le Cun, Y., Improving the convergence of back-propagation learning with second order methods (1989) Proc. 1988 connectionist models summer school, 1988, pp. 29-37. , Morgan Kaufmann, San Mateo, D. Touretzky, G. Hinton, T. Sejnowski (Eds.); Behnke, S., Hebbian learning and competition in the neural abstraction pyramid (1999) Proceedings of the international joint conference on neural networks, 2, pp. 1356-1361; Behnke, S., Learning iterative image reconstruction in the neural abstraction pyramid (2001) International Journal of Computational Intelligence and Applications, 1 (4), pp. 427-438; Behnke, S., Learning face localization using hierarchical recurrent networks. (2002) Proceedings of the 12th international conference on artificial neural networks, pp. 1319-1324; Behnke, S., Discovering hierarchical speech features using convolutional non-negative matrix factorization (2003) Proceedings of the international joint conference on neural networks, 4, pp. 2758-2763; Behnke, S., Hierarchical neural networks for image interpretation (2003) LNCS, Lecture notes in computer science, 2766. , Springer; Behnke, S., Face localization and tracking in the neural abstraction pyramid (2005) Neural Computing and Applications, 14 (2), pp. 97-103; Behnke, S., Rojas, R., Neural abstraction pyramid: a hierarchical image understanding architecture (1998) Proceedings of international joint conference on neural networks, 2, pp. 820-825; Bell, A.J., Sejnowski, T.J., An information-maximization approach to blind separation and blind deconvolution (1995) Neural Computation, 7 (6), pp. 1129-1159; Bellman, R., (1957) Dynamic programming, , Princeton University Press, Princeton, NJ, USA; Belouchrani, A., Abed-Meraim, K., Cardoso, J.-F., Moulines, E., A blind source separation technique using second-order statistics (1997) IEEE Transactions on Signal Processing, 45 (2), pp. 434-444; Bengio, Y., (1991) Artificial neural networks and their application to sequence recognition, , (Ph.D. thesis), McGill University, (Computer Science), Montreal, QC, Canada; Bengio, Y., Learning deep architectures for AI (2009) Foundations and trends in machine learning, 2 (1). , Now Publishers; Bengio, Y., Courville, A., Vincent, P., Representation learning: a review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Advances in neural information processing systems, vol. 19 (NIPS), pp. 153-160. , MIT Press, J.D. Cowan, G. Tesauro, J. Alspector (Eds.); Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166; Beringer, N., Graves, A., Schiel, F., Schmidhuber, J., Classifying unprompted speech by retraining LSTM nets (2005) LNCS, 3696, pp. 575-581. , Springer-Verlag, Berlin, Heidelberg, W. Duch, J. Kacprzyk, E. Oja, S. Zadrozny (Eds.) Artificial neural networks: biological inspirations-ICANN 2005; Bertsekas, D.P., (2001) Dynamic programming and optimal control, , Athena Scientific; Bertsekas, D.P., Tsitsiklis, J.N., (1996) Neuro-dynamic programming, , Athena Scientific, Belmont, MA; Bichot, N.P., Rossi, A.F., Desimone, R., Parallel and serial neural mechanisms for visual search in macaque area V4 (2005) Science, 308, pp. 529-534; Biegler-König, F., Bärmann, F., A learning algorithm for multilayered neural networks based on linear least squares problems (1993) Neural Networks, 6 (1), pp. 127-131; Bishop, C.M., Curvature-driven smoothing: A learning algorithm for feed-forward networks (1993) IEEE Transactions on Neural Networks, 4 (5), pp. 882-884; Bishop, C.M., (2006) Pattern recognition and machine learning, , Springer; Blair, A.D., Pollack, J.B., Analysis of dynamical recognizers (1997) Neural Computation, 9 (5), pp. 1127-1142; Blondel, V.D., Tsitsiklis, J.N., A survey of computational complexity results in systems and control (2000) Automatica, 36 (9), pp. 1249-1274; Bluche, T., Louradour, J., Knibbe, M., Moysset, B., Benzeghiba, F., Kermorvant, C., The A2iA Arabic handwritten text recognition system at the OpenHaRT2013 evaluation (2014) International workshop on document analysis systems.; Blum, A.L., Rivest, R.L., Training a 3-node neural network is NP-complete (1992) Neural Networks, 5 (1), pp. 117-127; Blumer, A., Ehrenfeucht, A., Haussler, D., Warmuth, M.K., Occam's razor (1987) Information Processing Letters, 24, pp. 377-380; Bobrowski, L., Learning processes in multilayer threshold nets (1978) Biological Cybernetics, 31, pp. 1-6; Bodén, M., Wiles, J., Context-free and context-sensitive dynamics in recurrent neural networks (2000) Connection Science, 12 (3-4), pp. 197-210; Bodenhausen, U., Waibel, A., The Tempo 2 algorithm: adjusting time-delays by supervised learning (1991) Advances in neural information processing systems, vol. 3, pp. 155-161. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Bohte, S.M., Kok, J.N., La Poutre, H., Error-backpropagation in temporally encoded networks of spiking neurons (2002) Neurocomputing, 48 (1), pp. 17-37; Boltzmann, L., (1909) Wissenschaftliche Abhandlungen, , Barth, Leipzig, (collection of Boltzmann's articles in scientific journals), F. Hasenöhrl (Ed.); Bottou, L., (1991) Une approche théorique de l'apprentissage connexioniste; applications à la reconnaissance de la parole, , (Ph.D. thesis), Université de Paris XI; Bourlard, H., Morgan, N., (1994) Connnectionist speech recognition: a hybrid approach, , Kluwer Academic Publishers; Boutilier, C., Poole, D., Computing optimal policies for partially observable Markov decision processes using compact representations (1996) Proceedings of the AAAI.; Bradtke, S.J., Barto, A.G., Kaelbling, L.P., Linear least-squares algorithms for temporal difference learning (1996) Machine Learning, pp. 22-33; Brafman, R.I., Tennenholtz, M., R-MAX-a general polynomial time algorithm for near-optimal reinforcement learning (2002) Journal of Machine Learning Research, 3, pp. 213-231; Brea, J., Senn, W., Pfister, J.-P., Matching recall and storage in sequence learning with spiking neural networks (2013) The Journal of Neuroscience, 33 (23), pp. 9565-9575; Breiman, L., Bagging predictors (1996) Machine Learning, 24, pp. 123-140; Brette, R., Rudolph, M., Carnevale, T., Hines, M., Beeman, D., Bower, J.M., Simulation of networks of spiking neurons: a review of tools and strategies (2007) Journal of Computational Neuroscience, 23 (3), pp. 349-398; Breuel, T.M., Ul-Hasan, A., Al-Azawi, M.A., Shafait, F., High-performance OCR for printed English and Fraktur using LSTM networks (2013) 12th International conference on document analysis and recognition, pp. 683-687. , IEEE; Bromley, J., Bentz, J.W., Bottou, L., Guyon, I., LeCun, Y., Moore, C., Signature verification using a Siamese time delay neural network (1993) International Journal of Pattern Recognition and Artificial Intelligence, 7 (4), pp. 669-688; Broyden, C.G., A class of methods for solving nonlinear simultaneous equations (1965) Mathematics of Computation, 19 (92), pp. 577-593; Brueckner, R., Schulter, B., Social signal classification using deep BLSTM recurrent neural networks (2014) Proceedings 39th IEEE international conference on acoustics, speech, and signal processing, pp. 4856-4860; Brunel, N., Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons (2000) Journal of Computational Neuroscience, 8 (3), pp. 183-208; Bryson, A.E., A gradient method for optimizing multi-stage allocation processes (1961) Proc. Harvard Univ. symposium on digital computers and their applications.; Bryson, Jr.A.E., Denham, W.F., (1961) A steepest-ascent method for solving optimum programming problems. Technical report BR-1303, , Raytheon Company, Missle and Space Division; Bryson, A., Ho, Y., (1969) Applied optimal control: optimization, estimation, and control, , Blaisdell Pub. Co; Buhler, J., Efficient large-scale sequence comparison by locality-sensitive hashing (2001) Bioinformatics, 17 (5), pp. 419-428; Buntine, W.L., Weigend, A.S., Bayesian back-propagation (1991) Complex Systems, 5, pp. 603-643; Burgess, N., A constructive algorithm that converges for real-valued input patterns (1994) International Journal of Neural Systems, 5 (1), pp. 59-66; Cardoso, J.-F., On the performance of orthogonal source separation algorithms (1994) Proc. EUSIPCO, pp. 776-779; Carreira-Perpinan, M.A., (2001) Continuous latent variable models for dimensionality reduction and sequential data reconstruction, , (Ph.D. thesis), University of Sheffield, UK; Carter, M.J., Rudolph, F.J., Nucci, A.J., Operational fault tolerance of CMAC networks (1990) Advances in neural information processing systems (NIPS), vol. 2, pp. 340-347. , Morgan Kaufmann, San Mateo, CA, D.S. Touretzky (Ed.); Caruana, R., Multitask learning (1997) Machine Learning, 28 (1), pp. 41-75; Casey, M.P., The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction (1996) Neural Computation, 8 (6), pp. 1135-1178; Cauwenberghs, G., A fast stochastic error-descent algorithm for supervised learning and optimization (1993) Advances in neural information processing systems, vol. 5, p. 244. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Chaitin, G.J., On the length of programs for computing finite binary sequences (1966) Journal of the ACM, 13, pp. 547-569; Chalup, S.K., Blair, A.D., Incremental training of first order recurrent neural networks to predict a context-sensitive language (2003) Neural Networks, 16 (7), pp. 955-972; Chellapilla, K., Puri, S., Simard, P., High performance convolutional neural networks for document processing. (2006) International workshop on Frontiers in handwriting recognition.; Chen, K., Salman, A., Learning speaker-specific characteristics with a deep neural architecture (2011) IEEE Transactions on Neural Networks, 22 (11), pp. 1744-1756; Cho, K., (2014) Foundations and advances in deep learning, , (Ph.D. thesis), Aalto University School of Science; Cho, K., Ilin, A., Raiko, T., Tikhonov-type regularization for restricted Boltzmann machines (2012) Intl. conf. on artificial neural networks 2012, pp. 81-88. , Springer; Cho, K., Raiko, T., Ilin, A., Enhanced gradient for training restricted Boltzmann machines (2013) Neural Computation, 25 (3), pp. 805-831; Church, A., An unsolvable problem of elementary number theory (1936) The American Journal of Mathematics, 58, pp. 345-363; Ciresan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Deep neural networks segment neuronal membranes in electron microscopy images (2012) Advances in neural information processing systems (NIPS), pp. 2852-2860; Ciresan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Mitosis detection in breast cancer histology images with deep neural networks (2013) Proc. MICCAI, 2, pp. 411-418; Ciresan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J., Deep big simple neural nets for handwritten digit recogntion (2010) Neural Computation, 22 (12), pp. 3207-3220; Ciresan, D.C., Meier, U., Masci, J., Gambardella, L.M., Schmidhuber, J., Flexible, high performance convolutional neural networks for image classification (2011) Intl. joint conference on artificial intelligence, pp. 1237-1242; Ciresan, D.C., Meier, U., Masci, J., Schmidhuber, J., A committee of neural networks for traffic sign classification (2011) International joint conference on neural networks, pp. 1918-1921; Ciresan, D.C., Meier, U., Masci, J., Schmidhuber, J., Multi-column deep neural network for traffic sign classification (2012) Neural Networks, 32, pp. 333-338; Ciresan, D.C., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) IEEE Conference on computer vision and pattern recognition, , arxiv:1202.2745v1, Long preprint [cs.CV]; Ciresan, D.C., Meier, U., Schmidhuber, J., Transfer learning for Latin and Chinese characters with deep neural networks (2012) International joint conference on neural networks, pp. 1301-1306; Ciresan, D.C., Schmidhuber, J., (2013) Multi-column deep neural networks for offline handwritten Chinese character classification. Technical report, , arxiv:1309.0261, IDSIA; Cliff, D.T., Husbands, P., Harvey, I., Evolving recurrent dynamical networks for robot control (1993) Artificial neural nets and genetic algorithms, pp. 428-435. , Springer; Clune, J., Mouret, J.-B., Lipson, H., The evolutionary origins of modularity (2013) Proceedings of the Royal Society B: Biological Sciences, 280 (1755), p. 20122863; Clune, J., Stanley, K.O., Pennock, R.T., Ofria, C., On the performance of indirect encoding across the continuum of regularity (2011) IEEE Transactions on Evolutionary Computation, 15 (3), pp. 346-367; Coates, A., Huval, B., Wang, T., Wu, D.J., Ng, A.Y., Catanzaro, B., Deep learning with COTS HPC systems (2013) Proc. international conference on machine learning.; Cochocki, A., Unbehauen, R., (1993) Neural networks for optimization and signal processing, , John Wiley & Sons, Inc; Collobert, R., Weston, J., A unified architecture for natural language processing: deep neural networks with multitask learning (2008) Proceedings of the 25th international conference on machine learning, pp. 160-167. , ACM; Comon, P., Independent component analysis-a new concept? (1994) Signal Processing, 36 (3), pp. 287-314; Connor, C.E., Brincat, S.L., Pasupathy, A., Transformation of shape information in the ventral pathway (2007) Current Opinion in Neurobiology, 17 (2), pp. 140-147; Connor, J., Martin, D.R., Atlas, L.E., Recurrent neural networks and robust time series prediction (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 240-254; Cook, S.A., The complexity of theorem-proving procedures (1971) Proceedings of the 3rd annual ACM symposium on the theory of computing, pp. 151-158. , ACM, New York; Cramer, N.L., A representation for the adaptive generation of simple sequential programs (1985) Proceedings of an international conference on genetic algorithms and their applications, Carnegie-Mellon University, , Lawrence Erlbaum Associates, Hillsdale, NJ, J. Grefenstette (Ed.); Craven, P., Wahba, G., Smoothing noisy data with spline functions: estimating the correct degree of smoothing by the method of generalized cross-validation (1979) Numerische Mathematik, 31, pp. 377-403; Cuccu, G., Luciw, M., Schmidhuber, J., Gomez, F., Intrinsically motivated evolutionary search for vision-based reinforcement learning (2011) Proceedings of the 2011 IEEE conference on development and learning and epigenetic robotics IEEE-ICDL-EPIROB, 2, pp. 1-7. , IEEE; Dahl, G.E., Sainath, T.N., Hinton, G.E., Improving deep neural networks for LVCSR using rectified linear units and dropout (2013) IEEE International conference on acoustics, speech and signal processing, pp. 8609-8613. , IEEE; Dahl, G., Yu, D., Deng, L., Acero, A., Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) IEEE Transactions on Audio, Speech and Language Processing, 20 (1), pp. 30-42; D'Ambrosio, D.B., Stanley, K.O., A novel generative encoding for exploiting neural network sensor and output geometry (2007) Proceedings of the conference on genetic and evolutionary computation, pp. 974-981; Datar, M., Immorlica, N., Indyk, P., Mirrokni, V.S., Locality-sensitive hashing scheme based on p-stable distributions (2004) Proceedings of the 20th annual symposium on computational geometry, pp. 253-262. , ACM; Dayan, P., Hinton, G., Feudal reinforcement learning (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 271-278. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Dayan, P., Hinton, G.E., Varieties of Helmholtz machine (1996) Neural Networks, 9 (8), pp. 1385-1403; Dayan, P., Hinton, G.E., Neal, R.M., Zemel, R.S., The Helmholtz machine (1995) Neural Computation, 7, pp. 889-904; Dayan, P., Zemel, R., Competition and multiple cause models (1995) Neural Computation, 7, pp. 565-579; Deco, G., Parra, L., Non-linear feature extraction by redundancy reduction in an unsupervised stochastic neural network (1997) Neural Networks, 10 (4), pp. 683-691; Deco, G., Rolls, E.T., Neurodynamics of biased competition and cooperation for attention: a model with spiking neurons (2005) Journal of Neurophysiology, 94 (1), pp. 295-313; De Freitas, J.F.G., (2003) Bayesian methods for neural networks, , (Ph.D. thesis), University of Cambridge; DeJong, G., Mooney, R., Explanation-based learning: an alternative view (1986) Machine Learning, 1 (2), pp. 145-176; DeMers, D., Cottrell, G., Non-linear dimensionality reduction (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 580-587. , Morgan Kaufmann, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Dempster, A.P., Laird, N.M., Rubin, D.B., Maximum likelihood from incomplete data via the EM algorithm (1977) Journal of the Royal Statistical Society B, 39; Deng, L., Yu, D., (2014) Deep learning: methods and applications, , NOW Publishers; Desimone, R., Albright, T.D., Gross, C.G., Bruce, C., Stimulus-selective properties of inferior temporal neurons in the macaque (1984) The Journal of Neuroscience, 4 (8), pp. 2051-2062; de Souto, M.C., Souto, M.C.P.D., Oliveira, W.R.D., The loading problem for pyramidal neural networks (1999) Electronic Journal on Mathematics of Computation; De Valois, R.L., Albrecht, D.G., Thorell, L.G., Spatial frequency selectivity of cells in macaque visual cortex (1982) Vision Research, 22 (5), pp. 545-559; Deville, Y., Lau, K.K., Logic program synthesis (1994) Journal of Logic Programming, 19 (20), pp. 321-350; de Vries, B., Principe, J.C., A theory for neural networks with time delays (1991) Advances in neural information processing systems (NIPS), 3, pp. 162-168. , Morgan Kaufmann, R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.); DiCarlo, J.J., Zoccolan, D., Rust, N.C., How does the brain solve visual object recognition? (2012) Neuron, 73 (3), pp. 415-434; Dickmanns, E.D., Behringer, R., Dickmanns, D., Hildebrandt, T., Maurer, M., Thomanek, F., The seeing passenger car 'VaMoRs-P' (1994) Proc. int. symp. on intelligent vehicles, pp. 68-73; Dickmanns, D., Schmidhuber, J., Winklhofer, A., (1987) Der genetische algorithmus: eine implementierung in prolog. Technical report, , http://www.idsia.ch/~juergen/geneticprogramming.html, Inst. of Informatics, Tech. Univ. Munich; Dietterich, T.G., Ensemble methods in machine learning (2000) Multiple classifier systems, pp. 1-15. , Springer; Dietterich, T.G., Hierarchical reinforcement learning with the MAXQ value function decomposition (2000) Journal of Artificial Intelligence Research (JAIR), 13, pp. 227-303; Di Lena, P., Nagata, K., Baldi, P., Deep architectures for protein contact map prediction (2012) Bioinformatics, 28, pp. 2449-2457; Director, S.W., Rohrer, R.A., Automated network design-the frequency-domain case (1969) IEEE Transactions on Circuit Theory, CT-16, pp. 330-337; Dittenbach, M., Merkl, D., Rauber, A., The growing hierarchical self-organizing map (2000) IEEE-INNS-ENNS International joint conference on neural networks, vol. 6, p. 6015. , IEEE Computer Society; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., DeCAF: a deep convolutional activation feature for generic visual recognition (2013), ArXiv Preprint. arxiv:1310.1531; Dorffner, G., Neural networks for time series processing (1996) Neural network world.; Doya, K., Samejima, K., Ichi Katagiri, K., Kawato, M., Multiple model-based reinforcement learning (2002) Neural Computation, 14 (6), pp. 1347-1369; Dreyfus, S.E., The numerical solution of variational problems (1962) Journal of Mathematical Analysis and Applications, 5 (1), pp. 30-45; Dreyfus, S.E., The computational solution of optimal control problems with time lag (1973) IEEE Transactions on Automatic Control, 18 (4), pp. 383-385; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) The Journal of Machine Learning, 12, pp. 2121-2159; Egorova, A., Gloye, A., Göktekin, C., Liers, A., Luft, M., Rojas, R., (2004) FU-fighters small size 2004, team description, , RoboCup 2004 symposium: papers and team description papers. CD edition; Elfwing, S., Otsuka, M., Uchibe, E., Doya, K., Free-energy based reinforcement learning for vision-based navigation with high-dimensional sensory inputs (2010) Neural information processing. theory and algorithms (ICONIP), vol. 1, pp. 215-222. , Springer; Eliasmith, C., (2013) How to build a brain: a neural architecture for biological cognition, , Oxford University Press, New York, NY; Eliasmith, C., Stewart, T.C., Choo, X., Bekolay, T., DeWolf, T., Tang, Y., A large-scale model of the functioning brain (2012) Science, 338 (6111), pp. 1202-1205; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14 (2), pp. 179-211; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) Journal of Machine Learning Research, 11, pp. 625-660; Escalante-B, A.N., Wiskott, L., How to solve classification and regression problems on high-dimensional data with a supervised extension of slow feature analysis (2013) Journal of Machine Learning Research, 14, pp. 3683-3719; Eubank, R.L., Spline smoothing and nonparametric regression (1988) Self-organizing methods in modeling, , Marcel Dekker, New York, S. Farlow (Ed.); Euler, L., (1744), Methodus inveniendi; Eyben, F., Weninger, F., Squartini, S., Schuller, B., Real-life voice activity detection with LSTM recurrent neural networks and an application to Hollywood movies (2013) Proc. 38th IEEE international conference on acoustics, speech, and signal processing, pp. 483-487; Faggin, F., Neural network hardware (1992) International joint conference on neural networks, 1, p. 153; Fahlman, S.E., (1988) An empirical study of learning speed in back-propagation networks. Technical report CMU-CS-88-162, , Carnegie-Mellon Univ; Fahlman, S.E., The recurrent cascade-correlation learning algorithm (1991) Advances in neural information processing systems (NIPS), 3, pp. 190-196. , Morgan Kaufmann, R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.); Falconbridge, M.S., Stamps, R.L., Badcock, D.R., A simple Hebbian/anti-Hebbian network learns the sparse, independent components of natural images (2006) Neural Computation, 18 (2), pp. 415-429; Fan, Y., Qian, Y., Xie, F., Soong, F.K., TTS synthesis with bidirectional LSTM based recurrent neural networks (2014) Proc. Interspeech.; Farabet, C., Couprie, C., Najman, L., LeCun, Y., Learning hierarchical features for scene labeling (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1915-1929; Farlow, S.J., (1984) Self-organizing methods in modeling: GMDH type algorithms, vol. 54, , CRC Press; Feldkamp, L.A., Prokhorov, D.V., Eagen, C.F., Yuan, F., Enhanced multi-stream Kalman filter training for recurrent networks (1998) Nonlinear modeling, pp. 29-53. , Springer; Feldkamp, L.A., Prokhorov, D.V., Feldkamp, T.M., Simple and conditioned adaptive behavior from Kalman filter trained recurrent networks (2003) Neural Networks, 16 (5), pp. 683-689; Feldkamp, L.A., Puskorius, G.V., A signal processing framework based on dynamic neural networks with application to problems in adaptation, filtering, and classification (1998) Proceedings of the IEEE, 86 (11), pp. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Huang G., Huang G.-B., Song S., You K.",7403425368;7403425167;13310063000;24923959400;,Trends in extreme learning machines: A review,2015,Neural Networks,10.1016/j.neunet.2014.10.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908682236&doi=10.1016%2fj.neunet.2014.10.001&partnerID=40&md5=1e4b0d1ed4ec9aa4317d0d9d19129474,"Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of ELM from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to ELM which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, ELM has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, ELM have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in ELM together with its future perspectives. © 2014 Elsevier Ltd.",Classification; Clustering; Extreme learning machine; Feature learning; Regression,Big data; Biomedical engineering; Classification (of information); Computation theory; Computer control systems; Data handling; Hardware; Knowledge acquisition; Learning systems; Robotics; Clustering; Extreme learning machine; Feature learning; Generalization performance; Hardware implementations; Implementation aspects; Regression; Universal approximation; Computer vision; accuracy; classification algorithm; computer model; computer prediction; extreme learning machine; image processing; intermethod comparison; kernel method; learning algorithm; machine learning; regression analysis; Review; support vector machine; trend study; algorithm; artificial intelligence; classification; standards; trends; Algorithms; Artificial Intelligence,"Adamos, D.A., Laskaris, N.A., Kosmidis, E.K., Theophilidis, G., Nass: An empirical approach to spike sorting with overlap resolution based on a hybrid noise-assisted methodology (2010) Journal of Neuroscience Methods, 190 (1), pp. 129-142; An, L., Bhanu, B., Image super-resolution by extreme learning machine (2012) 2012 19th IEEE international conference on image processing, pp. 2209-2212. , IEEE; Avci, E., A new method for expert target recognition system: Genetic wavelet extreme learning machine (GAWELM) (2013) Expert Systems with Applications, 40 (10), pp. 3984-3993; Avci, E., Coteli, R., A new automatic target recognition system based on wavelet extreme learning machine (2012) Expert Systems with Applications, 39 (16), pp. 12340-12348; Bai, Z., Huang, G.-B., Wang, D., Wang, H., Westover, M.B., Sparse extreme learning machine for classification (2014) IEEE Transactions on Cybernetics; Balbay, A., Avci, E., Sahin, O., Coteli, R., Modeling of drying process of bittim nuts (Pistacia terebinthus) in a fixed bed dryer system by using extreme learning machine (2012) International Journal of Food Engineering, 8 (4); Balbay, A., Kaya, Y., Sahin, O., Drying of black cumin (Nigella sativa) in a microwave assisted drying system and modeling using extreme learning machine (2012) Energy, 44 (1), pp. 352-357; Baradarani, A., Wu, Q.M.J., Ahmadi, M., An efficient illumination invariant face recognition framework via illumination enhancement and dd-dtcwt filtering (2013) Pattern Recognition, 46 (1), pp. 57-72; Barea, R., Boquete, L., Ortega, S., Lopez, E., Rodriguez-Ascariz, J.M., Eog-based eye movements codification for human computer interaction (2012) Expert Systems with Applications, 39 (3), pp. 2677-2683; Basu, A., Shuo, S., Zhou, H.M., Lim, M.H., Huang, G.B., Silicon spiking neurons for hardware implementation of extreme learning machines (2013) Neurocomputing, 102, pp. 125-134; Bazi, Y., Alajlan, N., Melgani, F., AlHichri, H., Malek, S., Yager, R.R., Differential evolution extreme learning machine for the classification of hyperspectral images (2014) IEEE Geoscience and Remote Sensing Letters, 11 (6), pp. 1066-1070; Belkin, M., Niyogi, P., Laplacian eigenmaps for dimensionality reduction and data representation (2003) Neural Computation, 15 (6), pp. 1373-1396; Belkin, M., Niyogi, P., Sindhwani, V., Manifold regularization: A geometric framework for learning from labeled and unlabeled examples (2006) The Journal of Machine Learning Research, 7, pp. 2399-2434; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning, 2 (1), pp. 1-127; Benoit, F., van Heeswijk, M., Miche, Y., Verleysen, M., Lendasse, A., Feature selection for nonlinear models with extreme learning machines (2013) Neurocomputing, 102, pp. 111-124; Block, H.D., The perceptron: A model for brain function. I (1962) Reviewers of Modern Physics, 34 (1), pp. 123-135; Block, H.D., Knight, J.B.W., Rosenblatt, F., Analysis of a four-layer series-coupled perceptron. II (1962) Reviewers of Modern Physics, 34 (1), pp. 135-142; Boquete, L., Miguel-Jimenez, J.M., Ortega, S., Rodriguez-Ascariz, J.M., Perez-Rico, C., Blanco, R., Multifocal electroretinogram diagnosis of glaucoma applying neural networks and structural pattern analysis (2012) Expert Systems with Applications, 39 (1), pp. 234-238; Branke, J., (1995) Evolutionary algorithms for neural network design and training, , Proceedings of the first nordic workshop on genetic algorithms and its applications; Butcher, J.B., Verstraeten, D., Schrauwen, B., Day, C.R., Haycock, P.W., Reservoir computing and extreme learning machines for non-linear time-series data analysis (2013) Neural Networks, 38, pp. 76-89; Cambria, E., Gastaldo, P., Bisio, F., Zunino, R., An ELM-based model for affective analogical reasoning (2014) Neurocomputing, , in press; Cao, J.W., Lin, Z.P., Huang, G.B., Composite function wavelet neural networks with extreme learning machine (2010) Neurocomputing, 73 (7-9), pp. 1405-1416; Cao, J.W., Lin, Z.P., Huang, G.B., Self-adaptive evolutionary extreme learning machine (2012) Neural Processing Letters, 36 (3), pp. 285-305; Cao, J.W., Lin, Z.P., Huang, G.B., Liu, N., Voting based extreme learning machine (2012) Information Sciences, 185 (1), pp. 66-77; Cao, F.L., Liu, B., Park, D.S., Image classification based on effective extreme learning machine (2013) Neurocomputing, 102, pp. 90-97; Chang, N.B., Han, M., Yao, W., Chen, L.C., Xu, S.G., Change detection of land use and land cover in an urban region with spot-5 images and partial lanczos extreme learning machine (2010) Journal of Applied Remote Sensing, 4; Chen, S., Cowan, C., Grant, P., Orthogonal least squares learning algorithm for radial basis function networks (1991) IEEE Transactions on Neural Networks, 2 (2), pp. 302-309; Chen, Q.S., Ding, J., Cai, J.R., Zhao, J.W., Rapid measurement of total acid content (TAC) in vinegar using near infrared spectroscopy based on efficient variables selection algorithm and nonlinear regression tools (2012) Food Chemistry, 135 (2), pp. 590-595; Chen, X., Dong, Z.Y., Meng, K., Ku, Y., Wong, K.P., Ngan, H.W., Electricity price forecasting with extreme learning machine and bootstrapping (2012) IEEE Transactions on Power Systems, 27 (4), pp. 2055-2062; Chen, F.L., Ou, T.Y., Sales forecasting system based on gray extreme learning machine with taguchi method in retail industry (2011) Expert Systems with Applications, 38 (3), pp. 1336-1345; Chen, H., Peng, J., Zhou, Y., Li, L., Pan, Z., Extreme learning machine for ranking: Generalization analysis and applications (2014) Neural Networks, 53, pp. 119-126; Cheng, C., Tay, W.P., Huang, G.-B., Extreme learning machines for intrusion detection (2012) The 2012 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , IEEE; Chen, Y.Q., Zhao, Z.T., Wang, S.Q., Chen, Z.Y., Extreme learning machine-based device displacement free activity recognition model (2012) Soft Computing, 16 (9), pp. 1617-1625; Chen, Z.X.X., Zhu, H.Y.Y., Wang, Y.G.G., A modified extreme learning machine with sigmoidal activation functions (2013) Neural Computing & Applications, 22 (3-4), pp. 541-550; Choi, K., Toh, K.A., Byun, H., Incremental face recognition for large-scale social network services (2012) Pattern Recognition, 45 (8), pp. 2868-2883; Cortes, C., Vapnik, V., Support vector machine (1995) Machine learning, 20 (3), pp. 273-297; Creech, G., Jiang, F., The application of extreme learning machines to the network intrusion detection problem (2012) International conference of numerical analysis and applied mathematics, 1479, pp. 1506-1511. , AIP Publishing; Daliri, M.R., A hybrid automatic system for the diagnosis of lung cancer based on genetic algorithm and fuzzy extreme learning machines (2012) Journal of Medical Systems, 36 (2), pp. 1001-1005; Decherchi, S., Gastaldo, P., Dahiya, R.S., Valle, M., Zunino, R., Tactile-data classification of contact materials using computational intelligence (2011) IEEE Transactions on Robotics, 27 (3), pp. 635-639; Decherchi, S., Gastaldo, P., Leoncini, A., Zunino, R., Efficient digital implementation of extreme learning machines for classification (2012) IEEE Transactions on Circuits and Systems II-Express Briefs, 59 (8), pp. 496-500; Decherchi, S., Gastaldo, P., Zunino, R., Cambria, E., Redi, J., Circular-ELM for the reduced-reference assessment of perceived image quality (2013) Neurocomputing, 102, pp. 78-89; Deng, J., Li, K., Irwin, G.W., Fast automatic two-stage nonlinear model identification based on the extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2422-2429; Deng, W.-Y., Zheng, Q.-H., Wang, Z.-M., Projection vector machine (2013) Neurocomputing, 120, pp. 490-498; Du, D.J., Li, K., Irwin, G.W., Deng, J., A novel automatic two-stage locally regularized classifier construction method using the extreme learning machine (2013) Neurocomputing, 102, pp. 10-22; Feng, G.R., Huang, G.B., Lin, Q.P., Gay, R., Error minimized extreme learning machine with growth of hidden nodes and incremental learning (2009) IEEE Transactions on Neural Networks, 20 (8), pp. 1352-1357; Feng, G.R., Qian, Z.X., Zhang, X.P., Evolutionary selection extreme learning machine optimization for regression (2012) Soft Computing, 16 (9), pp. 1485-1491; Feng, Y., Wang, Y.N., Yang, Y.M., Inverse kinematics solution for robot manipulator based on neural network under joint subspace (2012) International Journal of Computers Communications & Control, 7 (3), pp. 459-472; Fernández-Delgado, M., Cernadas, E., Barro, S., Ribeiro, J., Neves, J., Direct kernel perceptron (DKP): Ultra-fast kernel ELM-based classification with non-iterative closed-form weight calculation (2014) Neural Networks, 50, pp. 60-71; Frenay, B., Verleysen, M., Parameter-insensitive kernel in extreme learning for non-linear support vector regression (2011) Neurocomputing, 74 (16), pp. 2526-2531; Gao, J.F., Wang, Z., Yang, Y., Zhang, W.J., Tao, C.Y., Guan, J.A., A novel approach for lie detection based on f-score and extreme learning machine (2013) Plos One, 8 (6); Gastaldo, P., Zunino, R., Cambria, E., Decherchi, S., Combining ELM with random projections (2013) IEEE Intelligent Systems, 28 (5), pp. 18-20; Hagan, M.T., Menhaj, M.B., Training feedforward networks with the marquardt algorithm (1994) IEEE Transactions on Neural Networks, 5 (6), pp. 989-993; He, Q., Du, C.Y., Wang, Q., Zhuang, F.Z., Shi, Z.Z., A parallel incremental extreme svm classifier (2011) Neurocomputing, 74 (16), pp. 2532-2540; He, Q., Shang, T.F., Zhuang, F.Z., Shi, Z.Z., Parallel extreme learning machine for regression based on mapreduce (2013) Neurocomputing, 102, pp. 52-58; He, B., Xu, D., Nian, R., van Heeswijk, M., Yu, Q., Miche, Y., Fast face recognition via sparse coding and extreme learning machine (2014) Cognitive Computation, 6, pp. 264-277; Horata, P., Chiewchanwattana, S., Sunat, K., Robust extreme learning machine (2013) Neurocomputing, 102, pp. 31-44; Huang, G.-B., (2014) An insight to extreme learning machines: Random neurons, random features and kernels, , http://dx.doi.org/10.1007/s12559-014-9255-2, Cognitive Computation (Online); Huang, G.-B., Chen, L., Convex incremental extreme learning machine (2007) Neurocomputing, 70 (16), pp. 3056-3062; Huang, G.-B., Chen, L., Enhanced random search based incremental extreme learning machine (2008) Neurocomputing, 71 (16), pp. 3460-3468; Huang, G.-B., Chen, L., Siew, C.-K., Universal approximation using incremental constructive feedforward networks with random hidden nodes (2006) IEEE Transactions on Neural Networks, 17 (4), pp. 879-892; Huang, G.-B., Ding, X.J., Zhou, H.M., Optimization method based extreme learning machine for classification (2010) Neurocomputing, 74 (1-3), pp. 155-163; Huang, G.-B., Li, M.-B., Chen, L., Siew, C.-K., Incremental extreme learning machine with fully complex hidden nodes (2008) Neurocomputing, 71 (4), pp. 576-583; Huang, G., Song, S., Gupta, J., Wu, C., Semi-supervised and unsupervised extreme learning machines (2014) IEEE Transactions on Cybernetics; Huang, G., Song, S., Wu, C., Orthogonal least squares algorithm for training cascade neural networks (2012) IEEE Transactions on Circuits and Systems I: Regular Papers, 59 (11), pp. 2629-2637; Huang, W., Tan, Z.M., Lin, Z., Huang, G.B., Zhou, J., Chui, C.K., (2012) A semi-automatic approach to the segmentation of liver parenchyma from 3D CT images with extreme learning machine, , IEEE; Huang, G.-B., Wang, D.H., Lan, Y., Extreme learning machines: a survey (2011) International Journal of Machine Learning and Cybernetics, 2 (2), pp. 107-122; Huang, G.-B., Zhou, H., Ding, X., Zhang, R., Extreme learning machine for regression and multiclass classification (2012) IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 42 (2), pp. 513-529; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: theory and applications (2006) Neurocomputing, 70 (1), pp. 489-501; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: a new learning scheme of feedforward neural networks (2004), 2, pp. 985-990. , IEEE International Joint Conference on Neural Networks, 2004; Kan, E.M., Lim, M.H., Ong, Y.S., Tan, A.H., Yeo, S.P., Extreme learning machine terrain-based navigation for unmanned aerial vehicles (2013) Neural Computing & Applications, 22 (3-4), pp. 469-477; Karpagachelvi, S., Arthanari, M., Sivakumar, M., Classification of electrocardiogram signals with support vector machines and extreme learning machine (2012) Neural Computing & Applications, 21 (6), pp. 1331-1339; Kasun, L.L.C., Zhou, H., Huang, G.-B., Representational learning with ELMs for big data (2013) IEEE Intelligent Systems, 28 (5), pp. 31-34; Kaya, Y., Uyar, M., A hybrid decision support system based on rough set and extreme learning machine for diagnosis of hepatitis disease (2013) Applied Soft Computing, 13 (8), pp. 3429-3438; Kim, J., Shin, H.S., Shin, K., Lee, M., Robust algorithm for arrhythmia classification in ecg using extreme learning machine (2009) Biomedical Engineering Online, 8; Kong, W.W., Zhang, C., Liu, F., Gong, A.P., He, Y., Irradiation dose detection of irradiated milk powder using visible and near-infrared spectroscopy and chemometrics (2013) Journal of Dairy Science, 96 (8), pp. 4921-4927; Kosmatopoulos, E.B., Kouvelas, A., Large scale nonlinear control system fine-tuning through learning (2009) IEEE Transactions on Neural Networks, 20 (6), pp. 1009-1023; Kosmatopoulos, E.B., Kouvelas, A., Large scale nonlinear control system fine-tuning through learning (2009) IEEE Transactions on Neural Networks, 20 (6), pp. 1009-1023; Kwok, T.-Y., Yeung, D.-Y., Constructive algorithms for structure learning in feedforward neural networks for regression problems (1997) IEEE Transactions on Neural Networks, 8 (3), pp. 630-645; Lahoz, D., Lacruz, B., Mateo, P.M., A multi-objective micro genetic ELM algorithm (2013) Neurocomputing, 111, pp. 90-103; Lan, Y., Soh, Y.C., Huang, G.B., Ensemble of online sequential extreme learning machine (2009) Neurocomputing, 72 (13-15), pp. 3391-3395; Landa-Torres, I., Ortiz-Garcia, E.G., Salcedo-Sanz, S., Segovia-Vargas, M.J., Gil-Lopez, S., Miranda, M., Evaluating the internationalization success of companies through a hybrid grouping harmony search-extreme learning machine approach (2012) IEEE Journal of Selected Topics in Signal Processing, 6 (4), pp. 388-398; Lemme, A., Freire, A., Barreto, G., Steil, J., Kinesthetic teaching of visuomotor coordination for pointing by the humanoid robot icub (2013) Neurocomputing, 112, pp. 179-188; Le, Q., Sarlos, T., Smola, A., (2013) Fastfood-approximating kernel expansions in loglinear time, , Proceedings of the international conference on machine learning; Liang, N.-Y., Huang, G.-B., Saratchandran, P., Sundararajan, N., A fast and accurate online sequential learning algorithm for feedforward networks (2006) IEEE Transactions on Neural Networks, 17 (6), pp. 1411-1423; Li, B., Li, Y.B., Rong, X.W., The extreme learning machine learning algorithm with tunable activation function (2013) Neural Computing & Applications, 22 (3-4), pp. 531-539; Li, L., Liu, D., Ouyang, J., A new regularization classification method based on extreme learning machine in network data (2012) Journal of Information & Computational Science, 9 (12), pp. 3351-3363; Li, Y.J., Li, Y., Zhai, J.H., Shiu, S., Rts game strategy evaluation using extreme learning machine (2012) Soft Computing, 16 (9), pp. 1627-1637; Lin, S.J., Chang, C.H., Hsu, M.F., Multiple extreme learning machines for a two-class imbalance corporate life cycle prediction (2013) Knowledge-Based Systems, 39, pp. 214-223; Li, G.Q., Niu, P.F., Liu, C., Zhang, W.P., Enhanced combination modeling method for combustion efficiency in coal-fired boilers (2012) Applied Soft Computing, 12 (10), pp. 3132-3140; Lin, S., Liu, X., Fang, J., Xu, Z., Is extreme learning machine feasible? a theoretical assessment (part II) (2014) IEEE Transactions on Neural Networks nd Learning Systems; Lin, J., Yin, J., Cai, Z., Liu, Q., Li, K., A secure and practical mechanism of outsourcing extreme learning machine in cloud computing (2013) IEEE Intelligent Systems, 28 (5), pp. 35-38; Li, L.N., Ouyang, J.H., Chen, H.L., Liu, D.Y., A computer aided diagnosis system for thyroid disease using extreme learning machine (2012) Journal of Medical Systems, 36 (5), pp. 3327-3337; Li, K., Peng, J.-X., Irwin, G.W., A fast nonlinear model identification method (2005) IEEE Transactions on Automatic Control, 50 (8), pp. 1211-1216; Liu, J.F., Chen, Y.Q., Liu, M.J., Zhao, Z.T., SELM: Semi-supervised ELM with application in sparse calibrated location estimation (2011) Neurocomputing, 74 (16), pp. 2566-2572; Liu, X.Y., Gao, C.H., Li, P., A comparative analysis of support vector machines and extreme learning machines (2012) Neural Networks, 33, pp. 58-66; Liu, G.H., Jiang, H., Xiao, X.H., Zhang, D.J., Mei, C.L., Ding, Y.H., Determination of process variable ph in solid-state fermentation by ft-nir spectroscopy and extreme learning machine (ELM) (2012) Spectroscopy and Spectral Analysis, 32 (4), pp. 970-973; Liu, X., Lin, S., Fang, J., Xu, Z., Is extreme learning machine feasible? a theoretical assessment (part I) (2014) IEEE Transactions on Neural Networks nd Learning Systems; Liu, N., Wang, H., Ensemble based extreme learning machine (2010) IEEE Signal Processing Letters, 17 (8), pp. 754-757; Liu, Y., Xu, X.J., Wang, C.Y., (2009) Simple ensemble of extreme learning machine, 1-9. , Proceedings of the 2009 2nd international congress on image and signal processing; Li, W.T., Wang, D.H., Chai, T.Y., Burning state recognition of rotary kiln using ELMs with heterogeneous features (2013) Neurocomputing, 102, pp. 144-153; Li, K., Zhang, J., Xu, H., Luo, S., Li, H., A semi-supervised extreme learning machine method based on co-training (2013) Journal of Computational Information Systems, 9 (1), pp. 207-214; Luo, J., Vong, C.-M., Wong, P.-K., Sparse bayesian extreme learning machine for multi-classification (2014) IEEE Transactions on Neural Networks nd Learning Systems, 25 (4), pp. 836-843; Lu, B., Wang, G.R., Yuan, Y., Han, D., Semantic concept detection for video based on extreme learning machine (2013) Neurocomputing, 102, pp. 176-183; Malar, E., Kandaswamy, A., Chakravarthy, D., Dharan, A.G., A novel approach for detection and classification of mammographic microcalcifications using wavelet analysis and extreme learning machine (2012) Computers in Biology and Medicine, 42 (9), pp. 898-905; Malathi, V., Marimuthu, N.S., Baskar, S., Intelligent approaches using support vector machine and extreme learning machine for transmission line protection (2010) Neurocomputing, 73 (10-12), pp. 2160-2167; Malathi, V., Marimuthu, N.S., Baskar, S., Ramar, K., Application of extreme learning machine for series compensated transmission line protection (2011) Engineering Applications of Artificial Intelligence, 24 (5), pp. 880-887; Man, Z.H., Lee, K., Wang, D.H., Cao, Z.W., Khoo, S.Y., Robust single-hidden layer feedforward network-based pattern classifier (2012) IEEE Transactions on Neural Networks and Learning Systems, 23 (12), pp. 1974-1986; Man, Z.H., Lee, K., Wang, D.H., Cao, Z.W., Miao, C.Y., A new robust training algorithm for a class of single-hidden layer feedforward neural networks (2011) Neurocomputing, 74 (16), pp. 2491-2501; Marques, I., Grana, M., Fusion of lattice independent and linear features improving face identification (2013) Neurocomputing, 114, pp. 80-85; Martinez-Martinez, J.M., Escandell-Montero, P., Soria-Olivas, E., Martin-Guerrero, J.D., Magdalena-Benedito, R., Gomez-Sanchis, J., Regularized extreme learning machine for regression problems (2011) Neurocomputing, 74 (17), pp. 3716-3721; Miche, Y., Sorjamaa, A., Bas, P., Simula, O., Jutten, C., Lendasse, A., OP-ELM: Optimally pruned extreme learning machine (2010) IEEE Transactions on Neural Networks, 21 (1), pp. 158-162; Minhas, R., Baradarani, A., Seifzadeh, S., Wu, Q.M.J., Human action recognition using extreme learning machine based on visual vocabularies (2010) Neurocomputing, 73 (10-12), pp. 1906-1917; Minhas, R., Mohammed, A.A., Wu, Q.M.J., A fast recognition framework based on extreme learning machine using hybrid object information (2010) Neurocomputing, 73 (10-12), pp. 1831-1839; Minhas, R., Mohammed, A.A., Wu, Q.M.J., Incremental learning in human action recognition based on snippets (2012) IEEE Transactions on Circuits and Systems for Video Technology, 22 (11), pp. 1529-1541; Mohammed, A.A., Minhas, R., Wu, Q.M.J., Sid-Ahmed, M.A., Human face recognition based on multidimensional pca and extreme learning machine (2011) Pattern Recognition, 44 (10-11), pp. 2588-2597; Muhammad, I.G., Tepe, K.E., Abdel-Raheem, E., QAM equalization and symbol detection in OFDM systems using extreme learning machine (2013) Neural Computing & Applications, 22 (3-4), pp. 491-500; Martínez-Rego, D., Fontenla-Romero, O., Pérez-Sánchez, B., Alonso-Betanzos, A., Fault prognosis of mechanical components using on-line learning neural networks (2010) Artificial Neural Networks-ICANN 2010, pp. 60-66. , Springer; Nian, R., He, B., Lendasse, A., 3d object recognition based on a geometrical topology model and extreme learning machine (2013) Neural Computing & Applications, 22 (3-4), pp. 427-433; Osman, M.K., Mashor, M.Y., Jaafar, H., Performance comparison of extreme learning machine algorithms for mycobacterium tuberculosis detection in tissue sections (2012) Journal of Medical Imaging and Health Informatics, 2 (3), pp. 307-312; Pal, M., Extreme-learning-machine-based land cover classification (2009) International Journal of Remote Sensing, 30 (14), pp. 3835-3841; Pal, M., Maxwell, A.E., Warner, T.A., Kernel-based extreme learning machine for remote-sensing image classification (2013) Remote Sensing Letters, 4 (9), pp. 853-862; Pan, C., Park, D.S., Lu, H.J., Wu, X.P., Color image segmentation by fixation-based active learning with ELM (2012) Soft Computing, 16 (9), pp. 1569-1584; Platt, J., A resource-allocating network for function interpolation (1991) Neural Computation, 3 (2), pp. 213-225; Plutowski, M., Cottrell, G., White, H., Experience with selecting exemplars from clean data (1996) Neural Networks, 9 (2), pp. 273-294; Poggio, T., Girosi, F., Networks for approximation and learning (1990) Proceedings of the IEEE, 78 (9), pp. 1481-1497; Poria, S., Cambria, E., Winterstein, G., Huang, G.-B., (2014) Sentic patterns: Dependency-based rules for concept-level sentiment analysis, , http://dx.doi.org/10.1016/j.knosys.2014.05.005, Knowledge-Based Systems; Qu, Y.P., Shang, C.J., Wu, W., Shen, Q., Evolutionary fuzzy extreme learning machine for mammographic risk analysis (2011) International Journal of Fuzzy Systems, 13 (4), pp. 282-291; Rahimi, A., Recht, B., Random features for large-scale kernel machines (2007) Advances in neural information processing systems, 3, p. 5; Rahimi, A., Recht, B., Uniform approximation of functions with random bases (2008) Communication, control, and computing, 2008 46th annual allerton conference on, pp. 555-561. , IEEE; Rahimi, A., Recht, B., Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning (2008) Advances in neural information processing systems, pp. 1313-1320; Rao, C.R., Mitra, S.K., (1971) Generalized inverse of matrices and its applications, Vol.~7, , Wiley, New York; Rasheed, Z., Rangwala, H., Metagenomic taxonomic classification using extreme learning machines (2012) Journal of Bioinformatics and Computational Biology, 10 (5); Rong, H.J., Huang, G.B., Sundararajan, N., Saratchandran, P., Online sequential fuzzy extreme learning machine for function approximation and classification problems (2009) IEEE Transactions on Systems Man and Cybernetics Part B-Cybernetics, 39 (4), pp. 1067-1072; Rong, H.-J., Ong, Y.-S., Tan, A.-H., Zhu, Z., A fast pruned-extreme learning machine for classification problem (2008) Neurocomputing, 72 (1), pp. 359-366; Rong, H.J., Suresh, S., Zhao, G.S., Stable indirect adaptive neural controller for a class of nonlinear system (2011) Neurocomputing, 74 (16), pp. 2582-2590; Rosenblatt, F., The perceptron: A probabilistic model for information storage and organization in the brain (1958) Psychological Review, 65 (6), pp. 386-408; Rosenblatt, F., (1962) Principles of neurodynamics: perceptrons and the theory of brain mechanisms, , Spartan Books, New York; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323 (9), pp. 533-536; Saavedra-Moreno, B., Salcedo-Sanz, S., Carro-Calvo, L., Gascon-Moreno, J., Jimenez-Fernandez, S., Prieto, L., Very fast training neural-computation techniques for real measure-correlate-predict wind operations in wind farms (2013) Journal of Wind Engineering and Industrial Aerodynamics, 116, pp. 49-60; Sanchez-Monedero, J., Gutierrez, P.A., Fernandez-Navarro, F., Hervas-Martinez, C., Weighting efficient accuracy and minimum sensitivity for evolving multi-class classifiers (2011) Neural Processing Letters, 34 (2), pp. 101-116; Sanchez-Monedero, J., Hervas-Martinez, C., Gutierrez, P.A., Ruz, M.C., Moreno, M.C.R., Cruz-Ramirez, M., Evaluating the performance of evolutionary extreme learning machines by a combination of sensitivity and accuracy measures (2010) Neural Network World, 20 (7), pp. 899-912; Saraswathi, S., Fernandez-Martinez, J.L., Kolinski, A., Jernigan, R.L., Kloczkowski, A., Fast learning optimized prediction methodology (flopred) for protein secondary structure prediction (2012) Journal of Molecular Modeling, 18 (9), pp. 4275-4289; Saraswathi, S., Sundaram, S., Sundararajan, N., Zimmermann, M., Nilsen-Hamilton, M., ICGA-PSO-ELM approach for accurate multiclass cancer classification resulting in reduced gene sets in which genes encoding secreted proteins are highly represented (2011) IEEE-ACM Transactions on Computational Biology and Bioinformatics, 8 (2), pp. 452-463; Savitha, R., Suresh, S., Sundararajan, N., Fast learning circular complex-valued extreme learning machine (CC-ELM) for real-valued classification problems (2012) Information Sciences, 187, pp. 277-290; Savojardo, C., Fariselli, P., Casadio, R., Improving the detection of transmembrane beta-barrel chains with n-to-1 extreme learning machines (2011) Bioinformatics, 27 (22), pp. 3123-3128; Saxe, A., Koh, P.W., Chen, Z., Bhand, M., Suresh, B., Ng, A.Y., (2011) On random weights and unsupervised feature learning, pp. 1089-1096. , Proceedings of the 28th international conference on machine learning; Schmidt, W.F., Kraaijveld, M.A., Duin, R.P., Feed forward neural networks with random weights (1992) Proceedings of 11th IAPR international conference on pattern recognition methodology and systems, pp. 1-4. , Hague, Netherlands; Shi, J., Cai, Y., Zhu, J., Zhong, J., Wang, F., Semg-based hand motion recognition using cumulative residual entropy and extreme learning machine (2013) Medical & Biological Engineering & Computing, 51 (4), pp. 417-427; Shi, L.C., Lu, B.L., Eeg-based vigilance estimation using extreme learning machines (2013) Neurocomputing, 102, pp. 135-143; Song, Y., Crowcroft, J., Zhang, J., Automatic epileptic seizure detection in EEGs based on optimized sample entropy and extreme learning machine (2012) Journal of Neuroscience Methods, 210, pp. 132-146; Song, Y.D., Zhang, J.X., Automatic recognition of epileptic EEG patterns via extreme learning machine and multiresolution feature extraction (2013) Expert Systems with Applications, 40 (14), pp. 5477-5489; Soria-Olivas, E., Gomez-Sanchis, J., Jarman, I., Vila-Frances, J., Martinez, M., Magdalena, J.R., Belm: Bayesian extreme learning machine (2011) IEEE Transactions on Neural Networks, 22 (3), pp. 505-509; Sovilj, D., Sorjamaa, A., Yu, Q., Miche, Y., Severin, E., OPELM and OPKNN in long-term prediction of time series using projected input data (2010) Neurocomputing, 73 (10-12), pp. 1976-1986; Suresh, S., Babu, R.V., Kim, H.J., No-reference image quality assessment using modified extreme learning machine classifier (2009) Applied Soft Computing, 9 (2), pp. 541-552; Suykens, J.A., Vandewalle, J., Least squares support vector machine classifiers (1999) Neural Processing letters, 9 (3), pp. 293-300; Tan, Y.H., Dong, R.L., Chen, H., He, H., Neural network based identification of hysteresis in human meridian systems (2012) International Journal of Applied Mathematics and Computer Science, 22 (3), pp. 685-694; Tang, J., Deng, C., Huang, G.-B., Zhao, B., Compressed-domain ship detection on spaceborne optical image using deep neural network and extreme learning machine (2014) IEEE Transactions on Geoscience and Remote Sensing; Tang, X.L., Han, M., Ternary reversible extreme learning machines: the incremental tri-training method for semi-supervised classification (2010) Knowledge and Information Systems, 23 (3), pp. 345-372; Tian, H.X., Mao, Z.Z., An ensemble ELM based on modified AdaBoost.RT algorithm for predicting the temperature of molten steel in ladle furnace (2010) IEEE Transactions on Automation Science and Engineering, 7 (1), pp. 73-80; van Heeswijk, M., Miche, Y., Oja, E., Lendasse, A., GPU-accelerated and parallelized ELM ensembles for large-scale regression (2011) Neurocomputing, 74 (16), pp. 2430-2437; Vapnik, V., (2000) The nature of statistical learning theory, , Springer; Wang, Y.G., Cao, F.L., Yuan, Y.B., A study on effectiveness of extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2483-2490; Wang, D.H., Do, H.T., Computational localization of transcription factor binding sites using extreme learning machines (2012) Soft Computing, 16 (9), pp. 1595-1606; Wang, N., Er, M.-J., Han, M., Parsimonious extreme learning machine using recursive orthogonal least squares (2014) IEEE Transactions on Neural Networks; Wang, N., Er, M.J., Han, M., Parsimonious extreme learning machine using recursive orthogonal least squares (2014) IEEE Transactions on Neural Networks nd Learning Systems; Wang, X.Y., Han, M., Multivariate chaotic time series prediction based on extreme learning machine (2012) Acta Physica Sinica, 61 (8); Wang, L., Huang, Y.P., Luo, X.Y., Wang, Z., Luo, S.W., Image deblurring with filters learned by extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2464-2474; Wang, J.N., Jin, J.L., Geng, Y., Sun, S.L., Xu, H.L., Lu, Y.H., An accurate and efficient method to predict the electronic excitation energies of bodipy fluorescent dyes (2013) Journal of Computational Chemistry, 34 (7), pp. 566-575; Wang, G.T., Li, P., Cao, J.T., Variable activation function extreme learning machine based on residual prediction compensation (2012) Soft Computing, 16 (9), pp. 1477-1484; Wang, H., Qian, G., Feng, X.Q., Predicting consumer sentiments using online sequential extreme learning machine and intuitionistic fuzzy sets (2013) Neural Computing & Applications, 22 (3-4), pp. 479-489; Wang, X.Z., Shao, Q.Y., Miao, Q., Zhai, J.H., Architecture selection for networks trained with extreme learning machine using localized generalization error model (2013) Neurocomputing, 102, pp. 3-9; Wang, J.N., Xu, H.L., Sun, S.L., Gao, T., Li, H.Z., Li, H., An effective method for accurate prediction of the first hyperpolarizability of alkalides (2012) Journal of Computational Chemistry, 33 (2), pp. 231-236; Wefky, A., Espinosa, F., de Santiago, L., Revenga, P., Lazaro, J.L., Martinez, M., Electrical drive radiated emissions estimation in terms of input control using extreme learning machines (2012) Mathematical Problems in Engineering; White, H., (1989) An additional hidden unit test for neglected nonlinearity in multilayer feedforward networks, pp. 451-455. , Proceedings of the international conference on neural networks; White, H., Approxiate nonlinear forecasting methods (2006) Handbook of economics forecasting, pp. 460-512. , Elsevier, New York, G. Elliott, C.W.J. Granger, A. Timmermann (Eds.); White, H., (1992) Artificial neural networks: approximation and learning theory, , Blackwell Publishers, Inc; Widrow, B., Greenblatt, A., Kim, Y., Park, D., The No-Prop algorithm: A new learning algorithm for multilayer neural networks (2013) Neural Networks, 37, pp. 182-188; Wilamowski, B.M., Yu, H., Neural network learning without backpropagation (2010) IEEE Transactions on Neural Networks, 21 (11), pp. 1793-1803; Wong, W.K., Guo, Z.X., A hybrid intelligent model for medium-term sales forecasting in fashion retail supply chains using extreme learning machine and harmony search algorithm (2010) International Journal of Production Economics, 128 (2), pp. 614-624; Wong, K.I., Wong, P.K., Cheung, C.S., Vong, C.M., Modeling and optimization of biodiesel engine performance using advanced machine learning methods (2013)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dreiseitl S., Ohno-Machado L.",6701810489;7005192335;,Logistic regression and artificial neural network classification models: A methodology review,2002,Journal of Biomedical Informatics,10.1016/S1532-0464(03)00034-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043126911&doi=10.1016%2fS1532-0464%2803%2900034-0&partnerID=40&md5=7b819320e1f32d327ad7c9fdf174378f,"Logistic regression and artificial neural networks are the models of choice in many medical data classification tasks. In this review, we summarize the differences and similarities of these models from a technical point of view, and compare them with other machine learning algorithms. We provide considerations useful for critically assessing the quality of the models and the results based on these models. Finally, we summarize our findings on how quality criteria for logistic regression and artificial neural network models are met in a sample of papers from the medical literature. © 2003 Elsevier Science (USA). All rights reserved.",Artificial neural networks; Classification; Logistic regression; Medical data analysis; Model comparison; Model evaluation,accuracy; algorithm; area under the curve; artificial neural network; calculation; calibration; error; logistic regression analysis; machine; medical literature; methodology; model; parameter; priority journal; probability; qualitative analysis; review; sampling; statistical analysis; theory,"Duda, R., Hart, P., Stork, D., Pattern classification (2000) 2nd ed., , New York: Wiley/Interscience; Vapnik, V., The nature of statistical learning theory (2000) 2nd ed., , New York: Springer; Cristianini, N., Shawe-Taylor, J., (2000) An introduction to support vector machines and other kernel-based learning methods, , Cambridge: Cambridge University Press; Schölkopf, B., Smola, A., (2002) Learning with kernels: Support vector machines, regularization, optimization, and beyond, , Cambridge, MA: MIT Press; Dasarathy, B., (1991) Nearest neighbor pattern classification techniques, , Silver Spring, MD: IEEE Computer Society Press; Ripley, B., (1996) Pattern recognition and neural networks, , Cambridge: Cambridge University Press; Breiman, L., (1984) Classification and regression trees, , Belmont, CA: Wadsworth; Quinlan, R., (1993) C4.5: Programs for machine learning, , Los Altos, CA: Morgan Kaufmann; Bishop, C., (1995) Neural networks for pattern recognition, , Oxford: Oxford University Press; Hastie, T., Tibshirani, R., Friedman, J., (2001) The elements of statistical learning: Data mining, inference, and prediction, , New York: Springer; Press, W., Numerical recipes in C (1993) 2nd ed., , Cambridge: Cambridge University Press; Copas, J., Regression, prediction and shrinkage (with discussion) (1983) J. Roy. Stat. Soc. B, 45, pp. 311-354; Gelfand, A., Sahu, S., Carlin, B., Efficient parametrisations for generalized linear mixed models (1996) Bayesian statistics, 5, pp. 165-180. , Bernardo J. et al. Oxford: Oxford University Press; Neal, R., (1996) Bayesian learning for neural networks, , New York: Springer; Hosmer, D., Lemeshow, S., Applied logistic regression (2000) 2nd ed., , New York: Wiley; Harrell, F., (2001) Regression modeling strategies: With applications to linear models, logistic regression, and survival analysis, , New York: Springer; Zurada, J., Malinowski, A., Cloete, A., Sensitivity analysis for minimization of input dimension for feedforward neural networks (1994) Proc IEEE Int Symp Circuits Systems, 6, pp. 447-450; Stone, M., Cross-validatory choice and assessment of statistical predications (1974) J. Roy. Stat. Soc., 36, pp. 111-147; Allen, D., The relationship between variable selection and data augmentation and a method of prediction (1977) Technometric, 16, pp. 125-127; Efron, B., Tibshirani, R., (1993) An introduction to the bootstrap, , London: Chapman & Hall; Efron, B., Estimating the error rate of a prediction rule: Some improvements on cross-validation (1983) J. Am. Stat. Assoc., 78, pp. 316-331; Hanley, J., McNeil, B., A method of comparing the areas under receiver operating characteristic curves derived from the same cases (1983) Radiology, 148, pp. 839-843; DeLong, E., DeLong, D., Clarke-Pearson, D., Comparing the areas under two or more correlated receiver operating characteristic curves: A nonparametric approach (1988) Biometrics, 44, pp. 837-845; Altman, D., Rayston, P., What do we mean by validating a prognostic model? (2000) Stat. Med., 19, pp. 453-473; Vergouwe, Y., Validity of prognostic models: When is a model clinically useful (2002) Semin. Urol. Oncol., 20, pp. 96-107; Schwarzer, G., Vach, W., Schumacher, M., On the misuses of artificial neural networks for prognostic and diagnostic classification in oncology (2000) Stat. Med., 19, pp. 541-561; Lisboa, P., A review of evidence of health benefit from artificial neural networks in medical intervention (2002) Neural Networks, 15, pp. 11-39; Mitchell, T., (1997) Machine learning, , New York: McGraw-Hill; Dreiseitl, S., A comparison of machine learning methods for the diagnosis of pigmented skin lesions (2001) J. Biomed. Inform., 34, pp. 28-36; Chang, R., Support vector machines for diagnosis of breast tumors on US images (2003) Acad. Radiol., 10, pp. 189-197; Salzberg, S., On comparing classifiers: Pitfalls to avoid and a recommended approach (1997) Data Min. Knowl. Disc, 1, pp. 317-328; Harrell, F., Lee, K., Mark, D., Multivariable prognostic models: Issues in developing models, evaluation assumptions and adequacy, and measuring and reducing errors (1996) Stat. Med., 15, pp. 361-387; Hilden, J., Neural networks and the roles of cross validation (1998) Med. Decis. Making, 18, pp. 122-124; Steyerberg, E., Harrell, F., Goodman, P., Neural networks, logistic regression, and calibration (1998) Med. Decis. Making, 18, pp. 349-350; Steyerberg, E., Harrell, F., Goodman, P., Neural networks, logistic regression, and calibration: A rejoinder (1998) Med. Decis. Making, 18, pp. 445-446",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak J.A.W.M., van Ginneken B., Sánchez C.I.",36622356600;41261813100;56986708300;53264801600;32667506900;55841332000;6701833644;57202688150;8543425100;,A survey on deep learning in medical image analysis,2017,Medical Image Analysis,10.1016/j.media.2017.07.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026529300&doi=10.1016%2fj.media.2017.07.005&partnerID=40&md5=7a8f8ab63ff9d2cdaab2acbbea2e9c2f,"Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research. © 2017 Elsevier B.V.",Convolutional neural networks; Deep learning; Medical imaging; Survey,"Convolution; Image segmentation; Learning algorithms; Medical imaging; Neural networks; Object detection; Surveying; Surveys; Application area; Convolutional networks; Convolutional neural network; Critical discussions; Digital pathologies; State of the art; Deep learning; abdomen; anatomic landmark; artificial neural network; brain; breast; classification; computer; diagnostic imaging; digital imaging; eye; human; image analysis; image enhancement; image retrieval; image segmentation; learning; learning algorithm; priority journal; registration; Review; software; thorax; unsupervised machine learning; algorithm; artificial neural network; diagnostic imaging; image processing; machine learning; procedures; Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ional architecture for fast feature embedding (2014) Proceedings of the Twenty-Second ACM International Conference on Multimedia, pp. 675-678; Kainz, P., Pfeiffer, M., Urschler, M., Semantic segmentation of colon glands with deep convolutional neural networks and total variation segmentation (2015),,, Molin, J., Heyden, A., Lundstr, C., Aström, K., Towards grading gleason score using generically trained deep convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1163-1167; Kallenberg, M., Petersen, K., Nielsen, M., Ng, A., Diao, P., Igel, C., Vachon, C., Lillholm, M., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring (2016) IEEE Trans. Med. Imaging,35, pp. 1322-1331; Kamnitsas, K., Ledig, C., Newcombe, V.F., Simpson, J.P., Kane, A.D., Menon, D.K., Rueckert, D., Glocker, B., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation (2017) Med. Image Anal.,36, pp. 61-78; Karpathy, A., Fei-Fei, L., Deep visual-semantic alignments for generating image descriptions (2015) Proceedings of the Computer Vision and Pattern Recognition, , arxiv:1412.2306; Kashif, M.N., Raza, S.E.A., Sirinukunwattana, K., Arif, M., Rajpoot, N., Handcrafted features with convolutional neural networks for detection of tumor cells in histology images (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1029-1032; Kawahara, J., BenTaieb, A., Hamarneh, G., Deep features to classify skin lesions (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1397-1400; Kawahara, J., Brown, C.J., Miller, S.P., Booth, B.G., Chau, V., Grunau, R.E., Zwicker, J.G., Hamarneh, G., Brainnetcnn: convolutional neural networks for brain networks; towards predicting neurodevelopment (2016) Neuroimage; Kawahara, J., Hamarneh, G., Multi-resolution-tract CNN with hybrid pretrained and skin-lesion trained layers (2016) Proceedings of the Machine Learning in Medical Imaging, Lecture Notes in Computer Science,10019, pp. 164-171; Kendall, A., Gal, Y., What uncertainties do we need in Bayesian deep learning for computer vision? arXiv (2017), arXiv: 1703.04977; Kim, E., Cortre-Real, M., Baloch, Z., A deep semantic mobile application for thyroid cytopathology (2016) Proceedings of the SPIE on Medical Imaging,9789, p. 97890A; Kim, H., Hwang, S., Scale-invariant feature learning using deconvolutional neural networks for weakly-supervised semantic segmentation (2016), arxiv: 1602.04984; Kim, J., Calhoun, V.D., Shim, E., Lee, J.-H., Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: evidence from whole-brain resting-state functional connectivity patterns of schizophrenia (2016) Neuroimage,124, pp. 127-146; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2013), arxiv: 1312.6114; Kisilev, P., Sason, E., Barkan, E., Hashoul, S., Medical image description using multi-task-loss CNN (2016) Proceedings of the International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis, pp. 121-129. , Springer; Kleesiek, J., Urban, G., Hubert, A., Schwarz, D., Maier-Hein, K., Bendszus, M., Biller, A., Deep MRI brain extraction: a 3D convolutional neural network for skull stripping. (2016) Neuroimage,129, pp. 460-469; Kong, B., Zhan, Y., Shin, M., Denny, T., Zhang, S., Recognizing end-diastole and end-systole frames via deep temporal regression network (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 264-272; Kooi, T., van Ginneken, B., Karssemeijer, N., den Heeten, A., Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network (2017) Med. Phys, 44 (3), pp. 1017-1027; Kooi, T., Litjens, G., van Ginneken, B., Gubern-Mérida, A., Sánchez, C.I., Mann, R., den Heeten, A., Karssemeijer, N., Large scale deep learning for computer aided detection of mammographic lesions (2016) Med. Image Anal.,35, pp. 303-312; Korez, R., Likar, B., Pernu_, F., Vrtovec, T., Model-based segmentation of vertebral bodies from MR images with 3D CNNs (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 433-441. , Springer; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the Advances in Neural Information Processing Systems, pp. 1097-1105; Kumar, A., Sridar, P., Quinton, A., Kumar, R.K., Feng, D., Nanan, R., Kim, J., Plane identification in fetal ultrasound images using saliency maps and convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 791-794; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE,86, pp. 2278-2324; Lekadir, K., Galimzianova, A., Betriu, A., Del Mar Vila, M., Igual, L., Rubin, D.L., Fernandez, E., Napel, S., A convolutional neural network for automatic characterization of plaque composition in carotid ultrasound (2017) IEEE J. Biomed. Health Inf.,21, pp. 48-55; Lessmann, N., Isgum, I., Setio, A.A., de Vos, B.D., Ciompi, F., de Jong, P.A., Oudkerk, M., van Ginneken, B., Deep convolutional neural networks for automatic coronary calcium scoring in a screening study with low-dose chest CT (2016) Proceedings of the SPIE on Medical Imaging,9785, 978511-1–978511-6; Li, R., Zhang, W., Suk, H.-I., Wang, L., Li, J., Shen, D., Ji, S., Deep learning based imaging data completion for improved brain disease diagnosis (2014) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8675, pp. 305-312; Li, W., Cao, P., Zhao, D., Wang, J., Pulmonary nodule classification with deep convolutional neural networks on computed tomography images (2016) Comput. Math. Methods Med., p. 6215085; Li, W., Jia, F., Hu, Q., Automatic segmentation of liver tumor in CT images with deep convolutional neural networks (2015) J. Comput. Commun., 3 (11), pp. 146-151; Li, W., Manivannan, S., Akbar, S., Zhang, J., Trucco, E., McKenna, S.J., Gland segmentation in colon histology images using hand-crafted features and convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1405-1408; Liao, S., Gao, Y., Oto, A., Shen, D., Representation learning: A unified deep learning framework for automatic prostate mr segmentation (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 254-261; Lin, M., Chen, Q., Yan, S., Network in network (2013), arxiv: 1312.4400; Litjens, G., Sánchez, C.I., Timofeeva, N., Hermsen, M., Nagtegaal, I., Kovacs, I., Hulsbergen-van de Kaa, C., van der Laak, J., Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis (2016) Nat. Sci. Rep.,6, p. 26286; Liu, J., Wang, D., Wei, Z., Lu, L., Kim, L., Turkbey, E., Summers, R.M., Colitis detection on computed tomography using regional convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 863-866; Liu, X., Tizhoosh, H.R., Kofman, J., Generating binary tags for fast medical image retrieval based on convolutional nets and Radon transform (2016) Proceedings of the International Joint Conference on Neural Networks, , arxiv:1604.04676; Liu, Y., Gadepalli, K., Norouzi, M., Dahl, G.E., Kohlberger, T., Boyko, A., Venugopalan, S., Stumpe, M.C., Detecting cancer metastases on gigapixel pathology images (2017), arxiv: 1703.02442; Lo, S.-C., Lou, S.-L., Lin, J.-S., Freedman, M.T., Chien, M.V., Mun, S.K., Artificial convolution neural network techniques and applications for lung nodule detection (1995) IEEE Trans. Med. Imaging,14, pp. 711-718; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015), arxiv: 1411.4038; Lu, F., Wu, F., Hu, P., Peng, Z., Kong, D., Automatic 3D liver location and segmentation via convolutional neural network and graph cut (2017) Int. J. Comput. Assist. Radiol. Surg.,12, pp. 171-182; Lu, X., Xu, D., Liu, D., Robust 3d organ localization with dual learning architectures and fusion (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 12-20; Ma, J., Wu, F., Zhu, J., Xu, D., Kong, D., A pre-trained convolutional neural network based method for thyroid nodule diagnosis. (2017) Ultrasonics,73, pp. 221-230; Mahapatra, D., Roy, P.K., Sedai, S., Garnavi, R., Retinal image quality classification using saliency maps and CNNs (2016) Proceedings of the Machine Learning in Medical Imaging, Lecture Notes in Computer Science,10019, pp. 172-179; Malon, C.D., Cosatto, E., Classification of mitotic figures with convolutional neural networks and seeded blob features. (2013) J. Pathol. Inform.; Maninis, K.-K., Pont-Tuset, J., Arbeláez, P., Gool, L., Deep retinal image understanding (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 140-148; Mansoor, A., Cerrolaza, J., Idrees, R., Biggs, E., Alsharid, M., Avery, R., Linguraru, M.G., Deep learning guided partitioned shape model for anterior visual pathway segmentation (2016) IEEE Trans. Med. Imaging, 35 (8), pp. 1856-1865; Mao, Y., Yin, Z., A hierarchical convolutional neural network for mitosis detection in phase-contrast microscopy images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 685-692; Menegola, A., Fornaciali, M., Pires, R., Avila, S., Valle, E., Towards automated melanoma screening: exploring transfer learning schemes (2016), arxiv: 1609.01228; Merkow, J., Kriegman, D., Marsden, A., Tu, Z., Dense volume-to-volume vascular boundary detection (2016), arxiv: 1605.08401; Miao, S., Wang, Z.J., Liao, R., A CNN regression approach for real-time 2D/3D registration (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1352-1363; Milletari, F., Ahmadi, S.-A., Kroll, C., Plate, A., Rozanski, V., Maiostre, J., Levin, J., Navab, N.,-2016, Hough-CNN: deep learning for segmentation of deep brain regions in MRI and ultrasound. arxiv: 1601.07014; Milletari, F., Navab, N., Ahmadi, S.-A.,-2016, V-Net: fully convolutional neural networks for volumetric medical image segmentation. arxiv: 1606.04797; Mishra, M., Schmitt, S., Wang, L., Strasser, M.K., Marr, C., Navab, N., Zischka, H., Peng, T., Structure-based assessment of cancerous mitochondria using deep networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 545-548; Moeskops, P., Viergever, M.A., Mendrik, A.M., de Vries, L.S., Benders, M.J.N.L., Isgum, I., Automatic segmentation of MR brain images with a convolutional neural network (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1252-1262; Moeskops, P., Wolterink, J.M., Velden, B.H.M., Gilhuijs, K.G.A., Leiner, T., Viergever, M.A., Isgum, I., Deep learning for multi-task medical image segmentation in multiple modalities (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 478-486; Montavon, G., Lapuschkin, S., Binder, A., Samek, W., Müller, K.-R., Explaining nonlinear classification decisions with deep taylor decomposition (2017) Pattern Recognit.,65, pp. 211-222; Moradi, M., Guo, Y., Gur, Y., Negahdar, M., Syeda-Mahmood, T., A cross-modality neural network transform for semi-automatic medical image annotation (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 300-307; Moradi, M., Gur, Y., Wang, H., Prasanna, P., Syeda-Mahmood, T., A hybrid learning approach for semantic labeling of cardiac CT slices and recognition of body position (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging; Nappi, J.J., Hironaka, T., Regge, D., Yoshida, H., Deep transfer learning of virtual endoluminal views for the detection of polyps in CT colonography (2016) Proceedings of the Medical Imaging, p. 97852B; Nascimento, J.C., Carneiro, G., Multi-atlas segmentation using manifold learning with deep belief networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 867-871; Ngo, T.A., Lu, Z., Carneiro, G., Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance (2017) Med. Image Anal.,35, pp. 159-171; Nie, D., Cao, X., Gao, Y., Wang, L., Shen, D., Estimating CT image from MRI data using 3D fully convolutional networks (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 170-178; Nie, D., Wang, L., Gao, Y., Shen, D., Fully convolutional networks for multi-modality isointense infant brain image segmentation (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1342-1345; Nie, D., Zhang, H., Adeli, E., Liu, L., Shen, D., 3D deep learning for multi-modal imaging-guided survival time prediction of brain tumor patients (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 212-220; Nogues, I., Lu, L., Wang, X., Roth, H., Bertasius, G., Lay, N., Shi, J., Summers, R.M., Automatic lymph node cluster segmentation using holistically-nested neural networks and structured optimization in CT images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 388-397; Oktay, O., Bai, W., Lee, M., Guerrero, R., Kamnitsas, K., Caballero, J., Marvao, A., Rueckert, D., Multi-input cardiac image super-resolution using convolutional neural networks (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9902, pp. 246-254; Ortiz, A., Munilla, J., Górriz, J.M., Ramírez, J., Ensembles of deep learning architectures for the early diagnosis of the Alzheimer's disease (2016) Int. J. Neural Syst.,26, p. 1650025; Paeng, K., Hwang, S., Park, S., Kim, M., Kim, S., A unified framework for tumor proliferation score prediction in breast histopathology (2016), arxiv: 1612.07180; Pan, Y., Huang, W., Lin, Z., Zhu, W., Zhou, J., Wong, J., Ding, Z., Brain tumor grading based on neural networks and convolutional neural networks (2015) Proceedings of the IEEE Engineering in Medicine and Biology Society, pp. 699-702; Payan, A., Montana, G., Predicting Alzheimer's disease: a neuroimaging study with 3D convolutional neural networks (2015), arxiv: 1502.02506; Payer, C., Stern, D., Bischof, H., Urschler, M., Regressing heatmaps for multiple landmark localization using CNNs (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 230-238; Pereira, S., Pinto, A., Alves, V., Silva, C.A., Brain tumor segmentation using convolutional neural networks in MRI images (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1240-1251; Phan, H.T.H., Kumar, A., Kim, J., Feng, D., Transfer learning of a convolutional neural network for HEp-2 cell image classification (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1208-1211; Pinaya, W.H.L., Gadelha, A., Doyle, O.M., Noto, C., Zugman, A., Cordeiro, Q., Jackowski, A.P., Sato, J.R., Using deep belief network modelling to characterize differences in brain morphometry in schizophrenia (2016) Nat. Sci. Rep.,6, p. 38897; Plis, S.M., Hjelm, D.R., Salakhutdinov, R., Allen, E.A., Bockholt, H.J., Long, J.D., Johnson, H.J., Calhoun, V.D., Deep learning for neuroimaging: a validation study (2014) Front. Neurosci.; Poudel, R.P.K., Lamata, P., Montana, G., Recurrent fully convolutional neural networks for multi-slice MRI cardiac segmentation (2016), arxiv: 1608.03974; Prasoon, A., Petersen, K., Igel, C., Lauze, F., Dam, E., Nielsen, M., Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 246-253; Prentasic, P., Heisler, M., Mammo, Z., Lee, S., Merkur, A., Navajas, E., Beg, M.F., Loncaric, S., Segmentation of the foveal microvasculature using deep learning networks. (2016) J. Biomed. Opt.,21, p. 75008; Prentasic, P., Loncaric, S., Detection of exudates in fundus photographs using deep neural networks and anatomical landmark detection fusion (2016) Comput. Methods Programs Biomed.,137, pp. 281-292; Qiu, Y., Wang, Y., Yan, S., Tan, M., Cheng, S., Liu, H., Zheng, B., An initial investigation on developing a new method to predict short-term breast cancer risk based on deep learning technology (2016) Proceedings of the SPIE Medical Imaging,9785, p. 978521; Quinn, J.A., Nakasi, R., Mugagga, P.K.B., Byanyima, P., Lubega, W., Andama, A., Deep convolutional neural networks for microscopy-based point of care diagnostics (2016), arxiv: 1608.02989; Rajchl, M., Lee, M.C., Oktay, O., Kamnitsas, K., Passerat-Palmbach, J., Bai, W., Kainz, B., Rueckert, D., Deepcut: object segmentation from bounding box annotations using convolutional neural networks (2017) IEEE Trans. Med. Imaging, 36 (2), pp. 674-683; Rajchl, M., Lee, M.C., Schrans, F., Davidson, A., Passerat-Palmbach, J., Tarroni, G., Alansary, A., Rueckert, D., Learning under distributed weak supervision (2016), arxiv: 1606.01100; Rajkomar, A., Lingam, S., Taylor, A.G., Blum, M., Mongan, J., High-throughput classification of radiographs using deep convolutional neural networks (2017) J. Digit. Imaging,30, pp. 95-101; Ravi, D., Wong, C., Deligianni, F., Berthelot, M., Andreu-Perez, J., Lo, B., Yang, G.-Z., Deep learning for health informatics. (2017) IEEE J. Biomed. Health Inf.,21, pp. 4-21; Ravishankar, H., Prabhu, S.M., Vaidya, V., Singhal, N., Hybrid approach for automatic segmentation of fetal abdomen from ultrasound images using deep learning (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 779-782; Ravishankar, H., Sudhakar, P., Venkataramani, R., Thiruvenkadam, S., Annangi, P., Babu, N., Vaidya, V., Understanding the mechanisms of deep transfer learning for medical images (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 188-196; Rezaeilouyeh, H., Mollahosseini, A., Mahoor, M.H., Microscopic medical image classification framework via deep learning and shearlet transform (2016) J. Med. Imaging, 3 (4), p. 044501; Romo-Bucheli, D., Janowczyk, A., Gilmore, H., Romero, E., Madabhushi, A., Automated tubule nuclei quantification and correlation with Oncotype DX risk categories in ER+ breast cancer whole slide images (2016) Nat. Sci. Rep.,6, p. 32706; Ronneberger, O., Fischer, P., Brox, T., U-net: convolutional networks for biomedical image segmentation (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9351, pp. 234-241; Roth, H.R., Lee, C.T., Shin, H.-C., Seff, A., Kim, L., Yao, J., Lu, L., Summers, R.M., Anatomy-specific classification of medical images using deep convolutional nets (2015) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 101-104; Roth, H.R., Lu, L., Farag, A., Shin, H.-C., Liu, J., Turkbey, E.B., Summers, R.M., DeepOrgan: Multi-level deep convolutional networks for automated pancreas segmentation (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9349, pp. 556-564; Roth, H.R., Lu, L., Farag, A., Sohn, A., Summers, R.M., Spatial aggregation of holistically-nested networks for automated pancreas segmentation (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 451-459; Roth, H.R., Lu, L., Liu, J., Yao, J., Seff, A., Cherry, K., Kim, L., Summers, R.M., Improving computer-aided detection using convolutional neural networks and random view aggregation (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1170-1181; Roth, H.R., Lu, L., Seff, A., Cherry, K.M., Hoffman, J., Wang, S., Liu, J., Summers, R.M., A new 2.5D representation for lymph node detection using random sets of deep convolutional neural network observations (2014) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8673, pp. 520-527; Roth, H.R., Wang, Y., Yao, J., Lu, L., Burns, J.E., Summers, R.M., Deep convolutional networks for automated detection of posterior-element fractures on spine CT (2016) Proceedings of the SPIE of Medical Imaging,9785, p. 97850P; Roth, H.R., Yao, J., Lu, L., Stieger, J., Burns, J.E., Summers, R.M., Detection of sclerotic spine metastases via random aggregation of deep convolutional?neural network classifications (2015) Proceedings of the Recent Advances in Computational Methods and Clinical Applications for Spine Imaging, Lecture Notes in Computational Vision and Biomechanics,20, pp. 3-12; Rupprecht, C., Huaroc, E., Baust, M., Navab, N., Deep active contours (2016), arxiv: 1607.05074; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2014) Int. J. Comput. Vis., 115 (3), pp. 1-42; Sahiner, B., Chan, H.-P., Petrick, N., Wei, D., Helvie, M.A., Adler, D.D., Goodsitt, M.M., Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images (1996) IEEE Trans. Med. Imaging,15, pp. 598-610; Samala, R.K., Chan, H.-P., Hadjiiski, L., Cha, K., Helvie, M.A., Deep-learning convolution neural network for computer-aided detection of microcalcifications in digital breast tomosynthesis (2016) Proceedings of the SPIE on Medical Imaging,9785, p. 97850Y; Samala, R.K., Chan, H.-P., Hadjiiski, L., Helvie, M.A., Wei, J., Cha, K., Mass detection in digital breast tomosynthesis: deep convolutional neural network with transfer learning from mammography (2016) Med. Phys., 43 (12), pp. 6654-6666; Sarraf, S., Tofighi, G., Classification of Alzheimer's disease using fmri data and deep learning convolutional neural networks (2016), arxiv: 1603.08631; Schaumberg, A.J., Rubin, M.A., Fuchs, T.J., H&e-stained whole slide deep learning predicts SPOP mutation state in prostate cancer (2016), http://biorxiv.org/content/early/2016/07/21/064279.full.pdf, arxiv: 064279. 10.1101/064279; Schlegl, T., Waldstein, S.M., Vogl, W.-D., Schmidt-Erfurth, U., Langs, G., Predicting semantic descriptions from medical images with convolutional neural networks (2015) Proceedings of the Information Processing in Medical Imaging, Lecture Notes in Computer Science,9123, pp. 437-448; Sethi, A., Sha, L., Vahadane, A.R., Deaton, R.J., Kumar, N., Macias, V., Gann, P.H., Empirical comparison of color normalization methods for epithelial-stromal classification in h and e images (2016) J. Pathol. Inf.,7, p. 17; Setio, A.A.A., Ciompi, F., Litjens, G., Gerke, P., Jacobs, C., van Riel, S., Wille, M.W., van Ginneken, B., Pulmonary nodule detection in CT images: false positive reduction using multi-view convolutional networks (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1160-1169; Sevetlidis, V., Giuffrida, M.V., Tsaftaris, S.A., Whole image synthesis using a deep encoder–decoder network (2016) Proceedings of the Simulation and Synthesis in Medical Imaging, Lecture Notes in Computer Science,9968, pp. 127-137; Shah, A., Conjeti, S., Navab, N., Katouzian, A., Deeply learnt hashing forests for content based image retrieval in prostate MR images (2016) Proceedings of the SPIE on Medical Imaging,9784, p. 978414; Shakeri, M., Tsogkas, S., Ferrante, E., Lippe, S., Kadoury, S., Paragios, N., Kokkinos, I., Sub-cortical brain structure segmentation using F-CNNs (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 269-272; Shen, D., Wu, G., Suk, H.-I., Deep learning in medical image analysis. (2017) Annu. Rev. Biomed. Eng.; Shen, W., Yang, F., Mu, W., Yang, C., Yang, X., Tian, J., Automatic localization of vertebrae based on convolutional neural networks (2015) Proceedings of the SPIE on Medical Imaging,9413, p. 94132E; Shen, W., Zhou, M., Yang, F., Dong, D., Yang, C., Zang, Y., Tian, J., Learning from experts: Developing transferable deep features for patient-level lung cancer prediction (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 124-131; Shen, W., Zhou, M., Yang, F., Yang, C., Tian, J., Multi-scale convolutional neural networks for lung nodule classification (2015) Proceedings of the Information Processing in Medical Imaging, Lecture Notes in Computer Science,9123, pp. 588-599; Shi, J., Zheng, X., Li, Y., Zhang, Q., Ying, S., Multimodal neuroimaging feature learning with multimodal stacked deep polynomial networks for diagnosis of aLzheimer's disease (2017) IEEE J. Biomed. Health Inf., , in press; Shin, H.-C., Lu, L., Kim, L., Seff, A., Yao, J., Summers, R.M., Interleaved text/image deep mining on a very large-scale radiology database (2015) Proceedings of the Computer Vision and Pattern Recognition, pp. 1090-1099; Shin, H.-C., Orton, M.R., Collins, D.J., Doran, S.J., Leach, M.O., Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data (2013) IEEE Trans. Pattern Anal. Mach. Intell.,35, pp. 1930-1943; Shin, H.-C., Roberts, K., Lu, L., Demner-Fushman, D., Yao, J., Summers, R.M.,-2016, Learning to read chest x-rays: recurrent neural cascade model for automated image annotation. arxiv: 1603.08486; Shin, H.-C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Summers, R.M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1285-1298; Shkolyar, A., Gefen, A., Benayahu, D., Greenspan, H., Automatic detection of cell divisions (mitosis) in live-imaging microscopy images using convolutional neural networks (2015) Proceedings of the IEEE Engineering in Medicine and Biology Society, pp. 743-746; Simonovsky, M., Gutiérrez-Becker, B., Mateus, D., Navab, N., Komodakis, N., A deep metric for multimodal registration (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9902, pp. 10-18; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014), arxiv: 1409.1556; Sirinukunwattana, K., Raza, S.E.A., Tsang, Y.-W., Snead, D.R., Cree, I.A., Rajpoot, N.M., Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1196-1206; Smistad, E., Løvstakken, L., Vessel detection in ultrasound images using deep convolutional neural networks (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 30-38; Snoek, J., Larochelle, H., Adams, R.P., Practical Bayesian optimization of machine learning algorithms (2012) Proceedings of the Advances in Neural Information Processing Systems, pp. 2951-2959; Song, Y., Tan, E.-L., Jiang, X., Cheng, J.-Z., Ni, D., Chen, S., Lei, B., Wang, T., Accurate cervical cell segmentation from overlapping clumps in pap smear images (2017) IEEE Trans. Med. Imaging,36, pp. 288-300; Song, Y., Zhang, L., Chen, S., Ni, D., Lei, B., Wang, T., Accurate segmentation of cervical cytoplasm and nuclei based on multiscale convolutional network and graph partitioning (2015) IEEE Trans. Biomed. Eng., 62 (10), pp. 2421-2433; Spampinato, C., Palazzo, S., Giordano, D., Aldinucci, M., Leonardi, R., Deep learning for automated skeletal bone age assessment in X-ray images (2017) Med. Image Anal.,36, pp. 41-51; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., Striving for simplicity: the all convolutional net (2014), arxiv: 1412.6806; _tern, D., Payer, C., Lepetit, V., Urschler, M., Automated age estimation from hand MRI volumes using deep learning (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 194-202; Stollenga, M.F., Byeon, W., Liwicki, M., Schmidhuber, J., Parallel multi-dimensional LSTM, with application to fast biomedical volumetric image segmentation (2015) Proceedings of the Advances in Neural Information Processing Systems, pp. 2998-3006; Suk, H.-I., Lee, S.-W., Shen, D., Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis (2014) Neuroimage,101, pp. 569-582; Suk, H.-I., Lee, S.-W., Shen, D., Latent feature representation with stacked auto-encoder for AD/MCI diagnosis (2015) Brain Struct. Funct.,220, pp. 841-859; Suk, H.-I., Shen, D., Deep learning-based feature representation for AD/MCI classification (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 583-590; Suk, H.-I., Shen, D., Deep ensemble sparse regression network for Alzheimer's disease diagnosis (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,10019, pp. 113-121; Suk, H.-I., Wee, C.-Y., Lee, S.-W., Shen, D., State-space model with deep learning for functional dynamics estimation in resting-state FMRI (2016) Neuroimage,129, pp. 292-307; Sun, W., Tseng, T.-L.B., Zhang, J., Qian, W., Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data. (2016) Comput. Med. Imaging Graph; Sun, W., Zheng, B., Qian, W., Computer aided lung cancer diagnosis with deep learning algorithms (2016) Proceedings of the SPIE Medical Imaging,9785, p. 97850Z; Suzani, A., Rasoulian, A., Seitel, A., Fels, S., Rohling, R., Abolmaesumi, P., Deep learning for automatic localization, identification, and segmentation of vertebral bodies in volumetric MR images (2015) Proceedings of the SPIE Medical Imaging,9415, p. 941514; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2014), arxiv: 1409.4842; Tachibana, R., Näppi, J.J., Hironaka, T., Kim, S.H., Yoshida, H., Deep learning for electronic cleansing in dual-energy ct colonography (2016) Proceedings of the SPIE Medical Imaging,9785, p. 97851M; Tajbakhsh, N., Gotway, M.B., Liang, J., Computer-aided pulmonary embolism detection using a novel vessel-aligned multi-planar image representation and convolutional neural networks (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9350, pp. 62-69; Tajbakhsh, N., Gurudu, S.R., Liang, J., A comprehensive computer-aided polyp detection system for colonoscopy videos (2015) Proceedings of the Information Processing in Medical Imaging, Lecture Notes in Computer Science,9123, pp. 327-338; Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T., Kendall, C.B., Gotway, M.B., Liang, J., Convolutional neural networks for medical image analysis: fine tuning or full training? (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1299-1312; Tarando, S.R., Fetita, C., Faccinetto, A., Yves, P., Increasing CAD system efficacy for lung texture analysis using a convolutional network (2016) Proceedings of the SPIE on Medical Imaging,9785, 97850Q–97850Q; Teikari, P., Santos, M., Poon, C., Hynynen, K., Deep learning convolutional networks for multiphoton microscopy vasculature segmentation (2016), arxiv: 1606.02382; Teramoto, A., Fujita, H., Yamamuro, O., Tamaki, T., Automated detection of pulmonary nodules in PET/CT images: ensemble false-positive reduction using a convolutional neural network technique (2016) Med. Phys.,43, pp. 2821-2827; Thong, W., Kadoury, S., Piché, N., Pal, C.J., Convolutional networks for kidney segmentation in contrast-enhanced CT scans (2016) Computer. Methods Biomech. Biomed. Eng. Imag. Vis., pp. 1-6; Tran, P.V., A fully convolutional neural network for cardiac segmentation in short-axis MRI (2016), arxiv: 1604.00494; Turkki, R., Linder, N., Kovanen, P.E., Pellinen, T., Lundin, J., Antibody-supervised deep learning for quantification of tumor-infiltrating immune cells in hematoxylin and eosin stained breast cancer samples. (2016) J. Pathol. Inf.,7, p. 38; Twinanda, A.P., Shehata, S., Mutter, D., Marescaux, J., de Mathelin, M., Padoy, N., Endonet: a deep architecture for recognition tasks on laparoscopic videos (2017) IEEE Trans. Med. Imaging,36, pp. 86-97; van der Burgh, H.K., Schmidt, R., Westeneng, H.-J., de Reus, M.A., van den Berg, L.H., van den Heuvel, M.P., Deep learning predictions of survival based on MRI in amyotrophic lateral sclerosis (2017) Neuroimage Clin.,13, pp. 361-369; van Ginneken, B., Setio, A.A., Jacobs, C., Ciompi, F., Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans (2015) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 286-289; van Grinsven, M.J.J.P., van Ginneken, B., Hoyng, C.B., Theelen, T., Sánchez, C.I., Fast convolutional neural network training using selective data sampling: application to hemorrhage detection in color fundus images (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1273-1284; van Tulder, G., de Bruijne, M., Combining generative and discriminative representation learning for lung CT analysis with convolutional Restricted Boltzmann machines (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1262-1272; Veta, M., van Diest, P.J., Pluim, J.P.W., Cutting out the middleman: measuring nuclear area in histopathology slides without segmentation (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 632-639; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion (2010) J. Mach. Learn. Res.,11, pp. 3371-3408; Vivanti, R., Ephrat, A., Joskowicz, L., Karaaslan, O., Lev-Cohain, N., Sosna, J., Automatic liver tumor segmentation in follow-up CT studies using convolutional neural networks (2015) Proceedings of the Patch-Based Methods in Medical Image Processing Workshop, MICCAI’2015, pp. 54-61; Wang, C., Elazab, A., Wu, J., Hu, Q., Lung nodule classification using deep feature fusion in chest radiography (2016) Comput. Med. Imaging Graph; Wang, C., Yan, X., Smith, M., Kochhar, K., Rubin, M., Warren, S.M., Wrobel, J., Lee, H., A unified framework for automatic wound segmentation and analysis with deep convolutional neural networks (2015) Proceedings of the IEEE Engineering in Medicine and Biology Society, pp. 2415-2418; Wang, D., Khosla, A., Gargeya, R., Irshad, H., Beck, A.H.,-2016, Deep learning for identifying metastatic breast cancer. arxiv: 1606.05718; Wang, G., A perspective on deep imaging (2016) IEEE Access,4, pp. 8914-8924; Wang, H., Cruz-Roa, A., Basavanhally, A., Gilmore, H., Shih, N., Feldman, M., Tomaszewski, J., Madabhushi, A., Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features (2014) J. Med. Imaging,1, p. 034003; Wang, J., Ding, H., Azamian, F., Zhou, B., Iribarren, C., Molloi, S., Baldi, P., Detecting cardiovascular disease from mammograms with deep learning (2017) IEEE Trans. Med. Imaging; Wang, J., MacKenzie, J.D., Ramachandran, R., Chen, D.Z., A deep learning approach for semantic segmentation in histology tissue images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 176-184. , Springer; Wang, S., Yao, J., Xu, Z., Huang, J., Subtype cell detection with an accelerated deep convolution neural network (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 640-648; Wang, X., Lu, L., Shin, H.-C., Kim, L., Nogues, I., Yao, J., Summers, R.,-2016, Unsupervised category discovery via looped deep pseudo-task optimization using a large scale radiology image database. arxiv: 1603.07965; Wolterink, J.M., Leiner, T., de Vos, B.D., van Hamersvelt, R.W., Viergever, M.A., Isgum, I., Automatic coronary artery calcium scoring in cardiac CT angiography using paired convolutional neural networks (2016) Med. Image Anal.,34, pp. 123-136; Worrall, D.E., Wilson, C.M., Brostow, G.J., Automated retinopathy of prematurity case detection with convolutional neural networks (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 68-76; Wu, A., Xu, Z., Gao, M., Buty, M., Mollura, D.J., Deep vessel tracking: a generalized probabilistic approach via deep learning (2016) proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1363-1367; Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., Shen, D., Unsupervised deep feature learning for deformable registration of MR brain images (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 649-656; Xie, W., Noble, J.A., Zisserman, A., Microscopy cell counting and detection with fully convolutional regression networks (2016) Comput. Methods Biomech. Biomed. Eng. Imaging Vis., pp. 1-10; Xie, Y., Kong, X., Xing, F., Liu, F., Su, H., Yang, L., Deep voting: a robust approach toward nucleus localization in microscopy images (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9351, pp. 374-382; Xie, Y., Xing, F., Kong, X., Su, H., Yang, L., Beyond classification: structured regression for robust cell detection using convolutional neural network (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9351, pp. 358-365; Xie, Y., Zhang, Z., Sapkota, M., Yang, L., Spatial clockwork recurrent neural network for muscle perimysium segmentation (2016) Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 185-193. , Springer; Xing, F., Xie, Y., Yang, L., An automatic learning-based framework for robust nucleus segmentation (2016) IEEE Trans. Med. Imaging, 35 (2), pp. 550-566; Xu, J., Luo, X., Wang, G., Gilmore, H., Madabhushi, A., A deep convolutional neural network for segmenting and classifying epithelial and stromal regions in histopathological images (2016) Neurocomputing,191, pp. 214-223; Xu, J., Xiang, L., Liu, Q., Gilmore, H., Wu, J., Tang, J., Madabhushi, A., Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images (2016) IEEE Trans. Med. Imaging,35, pp. 119-130; Xu, T., Zhang, H., Huang, X., Zhang, S., Metaxas, D.N., Multimodal deep learning for cervical dysplasia diagnosis (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 115-123; Xu, Y., Li, Y., Liu, M., Wang, Y., Lai, M., Chang, E.I.-C.,-2016, Gland instance segmentation by deep multichannel side supervision. arxiv: 1607.03222; Xu, Y., Mo, T., Feng, Q., Zhong, P., Lai, M., Chang, E.I.C., Deep learning of feature representation with multiple instance learning for medical image analysis (2014) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1626-1630; Xu, Z., Huang, J., Detecting 10,000_Cells in one second (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 676-684; Xue, D.-X., Zhang, R., Feng, H., Wang, Y.-L., CNN-SVM For microvascular morphological type recognition with data augmentation (2016) J. Med. Biol. Eng.,36, pp. 755-764; Yan, Z., Zhan, Y., Peng, Z., Liao, S., Shinagawa, Y., Zhang, S., Metaxas, D.N., Zhou, X.S., Multi-instance deep learning: discover discriminative local anatomies for bodypart recognition (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1332-1343; Yang, D., Zhang, S., Yan, Z., Tan, C., Li, K., Metaxas, D., Automated anatomical landmark detection on distal femur surface using convolutional neural network (2015) proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 17-21; Yang, H., Sun, J., Li, H., Wang, L., Xu, Z., Deep fusion net for multi-atlas segmentation: Application to cardiac mr images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 521-528; Yang, L., Zhang, Y., Guldner, I.H., Zhang, S., Chen, D.Z., 3d segmentation of glial cells using fully convolutional networks and k-terminal cut (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 658-666. , Springer; Yang, W., Chen, Y., Liu, Y., Zhong, L., Qin, G., Lu, Z., Feng, Q., Chen, W., Cascade of multi-scale convolutional neural networks for bone suppression of chest radiographs in gradient domain. (2016) Med. Image Anal.,35, pp. 421-433; Yang, X., Kwitt, R., Niethammer, M., Fast predictive image registration (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 48-57; Yao, J., Wang, S., Zhu, X., Huang, J., Imaging biomarker discovery for lung cancer survival prediction (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 649-657; Yoo, Y., Tang, L.W., Brosch, T., Li, D.K.B., Metz, L., Traboulsee, A., Tam, R., Deep learning of brain lesion patterns for predicting future disease activity in patients with early symptoms of multiple sclerosis (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 86-94; Ypsilantis, P.-P., Siddique, M., Sohn, H.-M., Davies, A., Cook, G., Goh, V., Montana, G., Predicting response to neoadjuvant chemotherapy with pet imaging using convolutional neural networks (2015) PLoS One, 10 (9), pp. 1-18; Yu, L., Chen, H., Dou, Q., Qin, J., Heng, P.A., Automated melanoma recognition in dermoscopy images via very deep residual networks (2017) IEEE Trans. Med. Imaging, 36 (4), pp. 994-1004; Yu, L., Guo, Y., Wang, Y., Yu, J., Chen, P., Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks (2017) IEEE Trans. Biomed. Eng., 64 (8), pp. 1886-1895; Yu, L., Yang, X., Chen, H., Qin, J., Heng, P.A., Volumetric convnets with mixed residual connections for automated prostate segmentation from 3D MR images (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proceedings of the European Conference on Computer Vision, pp. 818-833; Zhang, H., Li, L., Qiao, K., Wang, L., Yan, B., Li, L., Hu, G.,-2016, Image prediction for limited-angle tomography via deep learning with convolutional neural network. arxiv: 1607.08707; Zhang, L., Gooya, A., Dong, B.H.R., Petersen, S.E., Medrano-Gracia, K.P., Frangi, A.F., Automated quality assessment of cardiac MR images using convolutional neural networks (2016) Proceedings of the Simulation and Synthesis in Medical Imaging (SASHIMI), Lecture Notes in Computer Science,9968, pp. 138-145; Zhang, Q., Xiao, Y., Dai, W., Suo, J., Wang, C., Shi, J., Zheng, H., Deep learning based classification of breast tumors with shear-wave elastography (2016) Ultrasonics,72, pp. 150-157; Zhang, R., Zheng, Y., Mak, T.W.C., Yu, R., Wong, S.H., Lau, J.Y.W., Poon, C.C.Y., Automatic detection and classification of colorectal polyps by transferring low-level CNN features from nonmedical domain (2017) IEEE J. Biomed. Health Inf.,21, pp. 41-47; Zhang, W., Li, R., Deng, H., Wang, L., Lin, W., Ji, S., Shen, D., Deep convolutional neural networks for multi-modality isointense infant brain image segmentation (2015) Neuroimage,108, pp. 214-224; Zhao, J., Zhang, M., Zhou, Z., Chu, J., Cao, F., Automatic detection and classification of leukocytes using convolutional neural networks (2016) Med. Biol. Eng. Comput.; Zhao, L., Jia, K., Multiscale CNNs for brain tumor segmentation and diagnosis (2016) Comput. Math. Methods Med.,2016, p. 8356294; Zheng, Y., Liu, D., Georgescu, B., Nguyen, H., Comaniciu, D., 3D deep learning for efficient and robust landmark detection in volumetric data (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9349, pp. 565-572; Zhou, X., Ito, T., Takayama, R., Wang, S., Hara, T., Fujita, H., Three-dimensional CT image segmentation by combining 2D fully convolutional network with 3D majority voting (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 111-120; Zhu, Y., Wang, L., Liu, M., Qian, C., Yousuf, A., Oto, A., Shen, D., MRI Based prostate cancer detection with high-level representation and hierarchical classification (2017) Med. Phys., 44 (3), pp. 1028-1039. , in press; Zilly, J., Buhmann, J.M., Mahapatra, D., Glaucoma detection using entropy sampling and ensemble learning for automatic optic cup and disc segmentation (2017) Comput. Med. Imaging Graph,55, pp. 28-41; Zreik, M., Leiner, T., de Vos, B., van Hamersvelt, R., Viergever, M., Isgum, I., Automatic segmentation of the left ventricle in cardiac CT angiography using convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging," pp. 40-43"""
"Jordan M.I., Mitchell T.M.",7202293939;7402175019;,"Machine learning: Trends, perspectives, and prospects",2015,Science,10.1126/science.aaa8415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937801713&doi=10.1126%2fscience.aaa8415&partnerID=40&md5=1d384806d6aad8d5de295df324a892aa,"Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today's most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",,"algorithm; automation; computer simulation; decision making; education; financial system; health care; machine learning; manufacturing; marketing; World Wide Web; accuracy; causal modeling; decision theory; decision tree; human; kernel method; learning algorithm; machine learning; natural language processing; prediction; priority journal; Review; speech discrimination; support vector machine; algorithm; artificial intelligence; computer system; statistical analysis; trends; Algorithms; Artificial Intelligence; Computer Systems; Data Interpretation, Statistical; Humans","Hastie, T., Tibshirani, R., Friedman, J., (2011) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, , Springer New York; Murphy, K., (2012) Machine Learning: A Probabilistic Perspective, , MIT Press Cambridge MA; Valiant, L., (1984) Commun. ACM, 27, pp. 1134-1142; Chandrasekaran, V., Jordan, M.I., (2013) Proc. Natl. Acad. Sci. U.S.A., 110, pp. 1181-1190; Decatur, S., Goldreich, O., Ron, D., (2000) SIAM J. Comput., 29, pp. 854-879; Shalev-Shwartz, S., Shamir, O., Tromer, E., Using more data to speed up training time (2012) Proceedings of the Fifteenth Conference on Artificial Intelligence and Statistics, , Canary Islands, Spain, 21 to 23 April; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., (2011) Foundations and Trends in Machine Learning, 3, pp. 1-122. , (Now Publishers, Boston; Sra, S., Nowozin, S., Wright, S., (2011) Optimization for Machine Learning, , MIT Press Cambridge MA; Schmidhuber, J., (2015) Neural Netw., 61, pp. 85-117; Bengio, Y., (2009) Foundations and Trends in Machine Learning, 2, pp. 1-127. , (Now Publishers, Boston; Krizhevsky, A., Sutskever, I., Hinton, G., (2015) Adv. Neural Inf. Process. Syst., 25, pp. 1097-1105; Hinton, G., (2012) IEEE Signal Process Mag., 29, pp. 82-97; Hinton, G.E., Salakhutdinov, R.R., (2006) Science, 313, pp. 504-507; Mnih, V., (2015) Nature, 518, pp. 529-533; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , MIT Press Cambridge MA; Yaylali, E., Ivy, J.S., Partially observable mdps (pomdps): Introduction and examples (2011) Encyclopedia of Operations Research and Management Science, , (John Wiley New York; Schultz, W., Dayan, P., Montague, P.R., (1997) Science, 275, pp. 1593-1599; Dwork, C., McSherry, F., Nissim, K., Smith, A., (2006) Proceedings of the Third Theory of Cryptography Conference, pp. 265-284. , New York, 4 to 7 March; Blum, A., Ligett, K., Roth, A., (2013) J. ACM, 20; Duchi, J., Jordan, M.I., Wainwright, J., (2014) J. ACM, 61, pp. 1-57; Balcan, M.-F., Blum, A., Fine, S., Mansour, Y., Distributed learning, communication complexity and privacy Proceedings of the 29th Conference on Computational Learning Theory, , Edinburgh, UK, 26 June to 1 July 2012; Zhang, Y., Duchi, J., Jordan, M., Wainwright, M., (2014) Advances in Neural Information Processing Systems, 26, pp. 1-23. , L. Bottou, C. Burges, Z. Ghahramani, M. Welling, Eds. (Curran Associates, Red Hook, NY; Berthet, Q., Rigollet, P., (2013) Ann. Stat., 41, pp. 1780-1815; Kleiner, A., Talwalkar, A., Sarkar, P., Jordan, M.I., (2014) J. R. Stat. Soc. B, 76, pp. 795-816; Mahoney, M., (2011) Found. Trends Machine Learn., 3, pp. 123-224; Mitchell, T., Proceedings of the Twenty-Ninth Conference on Artificial Intelligence (AAAI-15), , 25 to 30 January 2015, Austin, TX; Taylor, M., Stone, P., (2009) J. Mach. Learn. Res., 10, pp. 1633-1685; Thrun, S., Pratt, L., (1998) Learning to Learn, , Kluwer Academic Press Boston; Wehbe, L., (2014) PLOS ONE, 9, p. e112575; Xu, K., Proceedings of the 32nd International Conference on Machine Learning, 37, pp. 2048-2057. , Lille, France, 6 to 11 July 2015; Blei, D., (2012) Commun. ACM, 55, pp. 77-84",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Nowak M.A., Komarova N.L., Niyogi P.",7201493023;7004475998;7004259002;,Computational and evolutionary aspects of language,2002,Nature,10.1038/nature00771,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037030641&doi=10.1038%2fnature00771&partnerID=40&md5=dcb4c40af00ad97411a1ba7e14b841b8,"Language is our legacy. It is the main evolutionary contribution of humans, and perhaps the most interesting trait that has emerged in the past 500 million years. Understanding how darwinian evolution gives rise to human language requires the integration of formal language theory, learning theory and evolutionary dynamics. Formal language theory provides a mathematical description of language and grammar. Learning theory formalizes the task of language acquisition - it can be shown that no procedure can learn an unrestricted set of languages. Universal grammar specifies the restricted set of languages learnable by the human brain. Evolutionary dynamics can be formulated to describe the cultural evolution of language and the biological evolution of universal grammar.",,"Evolutionary algorithms; Formal languages; Learning systems; Evolutionary dynamics; Computational linguistics; evolution; language; learning; calculation; evolution; human; language; learning; linguistics; mathematical analysis; molecular dynamics; priority journal; review; theory; Brain; Culture; Evolution; Humans; Language; Learning; Linguistics; Models, Biological; Sound; Darwinia","Pinker, S., Bloom, A., Natural language and natural selection (1990) Behav. Brain Sci., 73, pp. 707-784; Jackendoff, R., Possible stages in the evolution of the language capacity (1999) Trends Cogn. Sci., 3, pp. 272-279; Bickerton, D., (1990) Language and Species, , Univ. Chicago Press, Chicago; Lighffoot, D., (1999) The Development of Language: Acquisition, Changes and Evolution, , Blackwell, Oxford; Brandon, R., Hornstein, N., From icon to symbol: Some speculations on the evolution of natural language (1986) Phil. Biol., 1, pp. 169-189; Hurford, J.R., Studdert-Kennedy, M.A., Knight, C., (1998) Approaches to the Evolution of Language, , Cambridge Univ. Press, Cambridge, UK; Newmeyer, F., Functional explanation in linguistics and the origins of language (1991) Lang. Commun., 11, pp. 3-28; Lieberman, P., (1984) The Biology and Evolution of Language, , Harvard Univ. Press, Cambridge, Massachusetts; Maynard Smith, I., Szathmary, E., (1995) The Major Transitions in Evolution, , Freeman Spektrum, Oxford; Hawkins, J.A., Gell-Mann, M., (1992) The Evolution of Human Languages, , Addison-Wesley, Reading, Massachusetts; Aitchinsom, J., (1996) The Seeds of Speech, , Cambridge Univ. Press, Cambridge, UK; Cavalli-Sforza, L.L., Genes, peoples and languages (1997) Proc. Natl Acad. Sci. USA, 94, pp. 7719-7724; Gopnik, M., Crago, M., Familial aggregation of a developmental language disorder (1991) Cognition, 39, pp. 1-50; Lai, C.S.L., Fisher, S.E., Hurst, J.A., Vargha-Khadem, F., Monaco, A.P., A forhead-domain gene is mutated in a severe speech and language disorder (2001) Nature, 413, pp. 519-523; Deacon, T., (1997) The Symbolic Species, , Penguin, London; Vargha-Khadem, F., Neural basis of an inherited speech and language disorder (1998) Proc. Natl Acad. Sci. USA, 95, pp. 12695-12700; Smith, W.J., (1977) The Behaviour of Communicating, , Harvard Univ. Press, Cambridge, UK; Dunbar, R., (1996) Grooming, Gossip, and the Evolution of Language, , Cambridge Univ. Press, Cambridge, UK; Fitch, W.T., The evolution of speech: A comparative review (2000) Trends Cogn. Sci., 4, pp. 258-267; Hauser, M.D., (1996) The Evolution of Communication, , Harvard Univ. Press, Cambridge, Massachusetts; Chomsky, N.A., (1957) Syntactic Structures, , Mouton, New York; Harrison, M.A., (1978) Introduction to Formal Language Theory, , Addison-Wesley, Reading, Massachusetts; Gold, E.M., Language identification in the limit (1961) Informat. Control, 10, pp. 447-474; Vapnik, V.N., Chervonenkis, A.Y., On the uniform convergence of relative frequencies of events to their probabilities (1971) Theor. Prob. Applicat., 17, pp. 264-280; Valiant, L.G., A theory of learnable (1984) Commun. ACM, 27, pp. 436-445; Vapnik, V.N., (1998) Statistical Learning Theory, , Wiley, New York; Osherson, D., Stob, M., Weinstein, S., (1986) Systems That Learn, , MIT Press, Cambridge, Massachusetts; Pinker, S., Formal models of language learning (1979) Cognition, 7, pp. 217-283; Pullum, G.K., Gazdar, G., Natural languages and context free languages (1982) Linguist. Phil., 4, pp. 471-504; Shieber, S.M., Evidence against the context-freeness of natural language (1985) Linguist. Phil., 8, pp. 333-343; Chomsky, N.A., (1984) Lectures on Government and Binding: The Pisa Lectures, , Foris, Dordrecht; Sadock, J.M., (1991) Autolexical Syntax: A Theory of Parallel Grammatical Representations. Studies in Contemporary, Linguistics, , Univ. Chicago Press, Chicago; Bresnan, J., (2001) Lexical-Functional Syntax, , Blackwells, London; Pollard, C.J., Sag, I.A., (1994) Head-Driven Phrase Structure Grammar, , Univ. Chicago Press, Chicago; Chomsky, N., (1972) Language and Mind, , Harcourt Brace Jovanovich, New York; Wexler, K., Culicover, P., (1980) Formal Principles of Language Acquisition, , MIT Press, Cambridge, Massachusetts; Jackendoff, R., (2001) Foundations of Language, , Oxford Univ. Press, Oxford; Chomsky, N., (1981) Explanation in Linguistics, pp. 123-146. , (eds Hornstein, N. & Lightfoot, D.) (Longman, London); Baker, M.C., (2001) Atoms of Language, , Basic Books, New York; Prince, A., Smolensky, P., Optimality: From neural networks to universal grammar (1997) Science, 275, pp. 1604-1610; Elman, J.L., (1996) Rethinking Innateness, , MIT Press, Cambridge, Massachusetts; Tomasello, M., (1999) The Cultural Origins of Human Cognition, , Harvard Univ. Press, Cambridge, Massachusetts; Sampson, G., (1999) Educating Eve: The Language Instinct Debate, , Cassell Academic, London; Greenberg, J.H., Ferguson, C.A., Moravcsik, E.A., (1978) Universals of Human Language, , Stanford Univ. Press, Stanford; Comrie, B., (1981) Language Universals and Linguistic Typology, , Univ. Chicago Press, Chicago; Geman, S., Bienenstock, E., Doursat, R., Neural networks and the bias/variance dilemma (1992) Neural Comput., 4, pp. 1-58; Langacker, R., (1987) Foundations of cognitive Linguistics, 1. , Stanford Univ. Press, Stanford; Lakoff, G., (1987) Women, Fire and Dangerous Things: What Categories Reveal about the Mind, , Univ. Chicago Press, Chicago; Bates, E., MacWhinney, B., (1982) Language Acquisition: The State of the Art, , Cambridge Univ. Press, Cambridge; Aoki, K., Feldman, M.W., Toward a theory for the evolution of cultural communication: Coevolution of signal transmission and reception (1987) Proc. Natl Acad. Sci. USA, 84, pp. 7164-7168; Hurford, J.R., Biological evolution of the Saussurean sign as a component of the language acquisition device (1989) Lingua, 77, pp. 187-222; Cangelosi, A., Parisi, D., (2002) Simulating the Evolution of Language, , Springer, London; Kirby, S., Hurford, J., (1997) Proc. Fourth European Conf. on Artificial Life, pp. 493-502. , (eds Husbands, P. & Harvey, I.) (MIT Press, Cambridge, Massachusetts); Steels, L., (1996) Proc. Fifth Artificial Life Conf, pp. 113-131. , (eds Langton, C. G. & Shimohara, T.) (MIT Press, Tokyo); Nowak, M.A., Krakauer, D.C., The evolution of language (1999) Proc. Natl. Acad. Sci. USA, 96, pp. 8028-8033; Nowak, M.A., Plotkin, J.B., Jansen, V.A.A., Evolution of syntactic communication (2000) Nature, 404, pp. 495-498; Komarova, N.L., Nowak, M.A., Evolutionary dynamics of the lexical matrix (2001) Bull. Math. Biol., 63, pp. 451-485; Christiansen, M.H., Dale, R.A.C., Ellefson, M.R., Conway, C.M., (2002) Simulating the Evolution of Language, pp. 165-187. , (eds Cangelosi, A. & Parisi, D.) (Springer, London); Hashimoto, T., Ikegami, T., Emergence of net-grammar in communicating agents (1996) Biosystyms, 38, pp. 1-14; Hazlehurst, B., Hutchins, E., The emergence of propositions from the coordination of talk and action in a shared worlds (1998) Lang. Cogn. Process., 13, pp. 373-424; Pinker, S., (1994) The Language Instinct, , Morrow, New York; Nowak, M.A., Komarova, N.L., Niyogi, P., Evolution of universal grammar (2001) Science, 291, pp. 114-118; Komarova, N.L., Rivin, I., (2001) Mathematics of learning, , http://lanLarXiv.org, Preprint math.PR/0105235; Rivin, I., (2001) Yet another zeta function and learning, , http://lanLarXiv.org, Preprint cs.LG/0107033; Lightfoot, D., (1991) How to Set Parameters: Arguments from Language Change, , MIT Press, Cambridge, Massachusetts; Kroch, A., Reflexes of grammar in patterns of language change (1989) Long. Variat. Change, 1, pp. 199-244; Wang, W.S.Y., (1998) The Origins and Past of Modern Humans, pp. 247-262. , (eds Omoto, K. & Tobias, P. V.) (World Scientific, Singapore); Niyogi, P., Berwick, R.C., Evolutionary consequences of language learning (1997) Linguist. Phil., 20, pp. 697-719; Hopper, P., Traugott, E., (1993) Grammaticalization, , Cambridge Univ. Press, Cambridge; De Graff, M., (1999) Language Creation and Language Change: Creolization, Diachrony and Development, , MIT Press, Cambridge, MA; Mufwene, S., (2001) The Ecology of Language Evolution, , Cambridge Univ. Press, Cambridge; Angluin, D., Learning regular sets from queries and counterexamples (1987) Informat. Comput., 75, pp. 87-106; Angluin, D., Kharitonov, M., When won't membership queries help? (1995) J. Comput. Syst. Sci., 50, pp. 336-355; Gasarch, W., Smith, C., Learning via queries (1992) J. Assoc. Comput. Machin., 39, pp. 649-674",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Podgorelec V., Kokol P., Stiglic B., Rozman I.",6701496970;7006196824;6602685509;7003701924;,Decision trees: An overview and their use in medicine,2002,Journal of Medical Systems,10.1023/A:1016409317640,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036778479&doi=10.1023%2fA%3a1016409317640&partnerID=40&md5=59ef7a3f5ef37e5ad360b1bccd5b9823,"In medical decision making (classification, diagnosing, etc.) there are many situations where decision must be made effectively and reliably. Conceptual simple decision making models with the possibility of automatic learning are the most appropriate for performing such tasks. Decision trees are a reliable and effective decision making technique that provide high classification accuracy with a simple representation of gathered knowledge and they have been used in different areas of medical decision making. In the paper we present the basic characteristics of decision trees and the successful alternatives to the traditional induction approach with the emphasis on existing and possible future applications in medicine.",Classification; Decision making; Decision trees; Machine learning,"algorithm; data analysis; decision making; decision theory; diagnostic accuracy; heart disease; human; human computer interaction; man machine interaction; medical decision making; model; review; systolic blood pressure; clinical medicine; decision support system; decision tree; United States; Clinical Medicine; Decision Support Systems, Clinical; Decision Trees; Humans; United States","Quinlan, J.R., (1993) C4.5: Programs for Machine Learning, , Morgan Kaufmann, San Francisco; Quinlan, J.R., Induction of decision trees (1986) Mach. Learn., 1, pp. 81-106; Quinlan, J.R., Simplifying decision trees (1987) Int. J. Man-Mach. Stud., 27, pp. 221-234; Shannon, C., Weaver, W., (1949) The Mathematical Theory of Communication, , University of Illinois Press, USA; Breiman, L., Friedman, J.H., Olsen, R.A., Stone, C.J., (1984) Classification and Regression Trees, , Wadsworth, USA; Paterson, A., Niblett, T.B., (1982) ACLS Manual, , Intelligent Terminals Ltd., Edinburgh; Zorman, M., Podgorelec, V., Kokol, P., Peterson, M., Lane, J., Decision tree's induction strategies evaluated on a hard real world problem (2000) Proc. 13th IEEE Symp. Comp.-Based Med. Syst. (CBMS-2000), pp. 19-24; Zorman, M., Hieb, S., Sprogar, M., Advanced tool for building decision trees MtDecit 2.0 (1999) Proc. Int. Conf. Artif. Intellig. (ICAI-99); Tou, J.T., Gonzalez, R.C., Pattern Recognition Principles, p. 1974. , Addison-Wesley, Reading, MA; Murthy, K.V.S., (1997) On Growing Better Decision Trees from Data, , PhD dissertation, Johns Hopkins University, Baltimore, MD; Neapolitan, R., Naimipour, K., (1996) Foundations of Algorithms, , D. C. Heath and Company, Lexington, MA; Heath, D., Kasif, S., Salzberg, S., k-DT: A multi-tree learning method (1993) Proc. Second Int. Workshop Multistrategy Learn, pp. 138-149; Heath, D., Kasif, S., Salzberg, S., Learning oblique decision trees (1993) Proc. Thirteenth Int. Joint Conf. Artif. Intellig. (IJCAI-93), pp. 1002-1007; Rich, E., Knight, K., (1991) Artificial Intelligence (2nd Edn.), , McGraw Hill, New York; Kirkpatrick, S., Gelatt, C.D., Vecchi, M.P., Optimization by simulated annealing (1983) Science, 220, p. 4598; Utgoff, P.E., Incremental induction of decision trees (1989) Mach. Learn., 4 (2), pp. 161-186; Crawford, S., Extensions to the CART algorithm (1989) Int. J. Man-Mach. Stud., 31 (2), pp. 197-217; Dietterich, T.G., Kong, E.B., Machine Learning Bias, Statistical Bias and Statistical Variance of Decision Tree Algorithms, p. 1995. , Technical Report, Oregon State University; Ho, T.K., The random subspace method for constructing decision forests (1998) IEEE Trans. Pattern Anal. Mach. Intellig., 20 (8), pp. 832-844; Podgorelec, V., Kokol, P., Evolutionary decision forests - Decision making with multiple evolutionary constructed decision trees (2001) Problems in Applied Mathematics and Computational Intelligence, pp. 97-103. , WSES Press; Shlien, S., Multiple binary decision tree classifiers (1992) Pattern Recogn. Lett., 23 (7), pp. 757-763; Utgoff, P.E., Perceptron trees: A case study in hybrid concept representations (1989) Connect. Science, 1, pp. 377-391; Craven, M.W., Shavlik, J.W., Extracting tree-structured representations of trained networks (1996) Advances in Neural Information Processing Systems, 8. , MIT Press, Cambridge, MA; Zorman, M., Kokol, P., Podgorelec, V., Medical decision making supported by hybrid decision trees (2000) Proc. ICSC Symp. Intellig. Syst. Appl. (ISA-2000), , ICSC Academic Press; Banerjee, A., Initializing neural networks using decision trees (1994) Proc. Int. Workshop Comput. Learn. Nat. Learn. Syst., pp. 3-15; Goldberg, D.E., (1989) Genetic Algorithms in Search, Optimization, and Machine Learning, , Addison Wesley, Reading, MA; Nikolaev, N., Slavov, V., Inductive genetic programming with decision trees (1998) Intellig. Data Anal. Int. J., 2 (1), pp. 31-44; Podgorelec, V., Kokol, P., Induction f medical decision trees with genetic algorithms (1999) Proc. Int. ICSC Congr. Comput. Intellig. Methods Appl. (CIMA 1999); Cantu-Paz, E., Kamath, C., Using evolutionary algorithms to induce oblique decision trees (2000) Proc. Genet. Evol. Comput. Conf. (GECCO-2000), pp. 1053-1060; Podgorelec, V., Kokol, P., Towards more optimal medical diagnosing with evolutionary algorithms (2001) J. Med. Syst., 25 (3), pp. 195-219; Sprogar, M., Kokol, P., Hleb, S., Podgorelec, V., Zorman, M., Vector decision trees (2000) Intellig. Data Anal., 4 (3-4), pp. 305-321; Podgorelec, V., (2001) Intelligent Systems Design and Knowledge Discovery with Automatic Programming, , PhD thesis, University of Maribor, Oct; Cremilleux, B., Robert, C., A theoretical framework for decision trees in uncertain domains: Application to medical data sets (1997) Lecture Notes in Artificial Intelligence, 1211, pp. 145-156. , Springer-Verlag; Kokol, P., Zorman, M., Stiglic, M.M., Malcic, I., The limitations of decision trees and automatic learning in real world medical decision making (1998) Proc. 9th World Congr. Med. Inform. (MEDINFO-98), 52, pp. 529-533; Tsien, C.L., Fraser, H.S.F., Eong, W.J., Kennedy, R.L., Using classification tree and logistic regression methods to diagnose myocardial infarction (1998) Proc. 9th World Congr. Med. Inform. (MEDINFO-98), 52, pp. 493-497; Babic, S.H., Kokol, P., Stiglic, M.M., Fuzzy decision trees in the support of breastfeeding (2000) Proc. 13th IEEE Symp. Comp.-Based Med. Syst. (CBMS-2000), pp. 7-11; Jones, J.K., The role of data mining technology in the identification of signals of possible adverse drug reactions: Value and limitations (2001) Curr. Ther. Res.-Clin. Exp., 62 (9), pp. 664-672; Ohno-Machado, L., Lacson, R., Massad, E., Decision trees and fuzzy logic: A comparison of models for the selection of measles vaccination strategies in Brazil (2000) J. Am. Med. Inform. Assoc., (SUPPL.), pp. 625-629. , September; Dantchev, N., Therapeutic decision frees in psychiatry (1996) Encephale-Revue de Psychiatrie Clinique Biologique et Therapeutique, 22 (3), pp. 205-214; Gambhir, S.S., Decision analysis in nuclear medicine (1999) J. Nucl. Med., 40 (9), pp. 1570-1581; Tsien, C.E., Kohane, I.S., McIntosh, N., Multiple signal integration by decision tree induction to detect artifacts in the neonatal intensive care unit (2000) Artif. Intellig. Med., 19 (3), pp. 189-202; Bonner, G., Decision making for health care professionals: Use of decision trees within the community mental health setting (2001) J. Adv. Nurs., 35, pp. 349-356; Letourneau, S., Jensen, L., Impact of a decision tree on chronic wound care (1998) J. Wound Ostomy Continence Nurs., 25, pp. 240-247; Sanders, G.D., Hagerty, C.G., Sonnenberg, F.A., Hlatky, M.A., Owens, D.K., Distributed decision support using a web-based interface: Prevention of sudden cardiac death (2000) Med. Decision Making, 19 (2), pp. 157-166; Sims, C.J., Meyn, L., Caruana, R., Rao, R.B., Mitchell, T., Krohn, M., Predicting cesarean delivery with decision tree models (2000) Am. J. Obstet. Gynecol., 183, pp. 1198-1206",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Khosravi A., Nahavandi S., Creighton D., Atiya A.F.",56234594800;55992860000;9334174900;7004005716;,Comprehensive review of neural network-based prediction intervals and new advances,2011,IEEE Transactions on Neural Networks,10.1109/TNN.2011.2162110,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052409097&doi=10.1109%2fTNN.2011.2162110&partnerID=40&md5=c6856a878a9625d218309623b4840f88,"This paper evaluates the four leading techniques proposed in the literature for construction of prediction intervals (PIs) for neural network point forecasts. The delta, Bayesian, bootstrap, and mean-variance estimation (MVE) methods are reviewed and their performance for generating high-quality PIs is compared. PI-based measures are proposed and applied for the objective and quantitative assessment of each method's performance. A selection of 12 synthetic and real-world case studies is used to examine each method's performance for PI construction. The comparison is performed on the basis of the quality of generated PIs, the repeatability of the results, the computational requirements and the PIs variability with regard to the data uncertainty. The obtained results in this paper indicate that: 1) the delta and Bayesian methods are the best in terms of quality and repeatability, and 2) the MVE and bootstrap methods are the best in terms of low computational load and the width variability of PIs. This paper also introduces the concept of combinations of PIs, and proposes a new method for generating combined PIs using the traditional PIs. Genetic algorithm is applied for adjusting the combiner parameters through minimization of a PI-based cost function subject to two sets of restrictions. It is shown that the quality of PIs produced by the combiners is dramatically better than the quality of PIs obtained from each individual method. © 2006 IEEE.",Bayesian; bootstrap; delta; mean-variance estimation; neural network; prediction interval,Bayesian; bootstrap; delta; Mean variance; prediction interval; Bayesian networks; Forecasting; Neural networks; algorithm; animal; artificial neural network; Bayes theorem; computer simulation; human; predictive value; review; time; Algorithms; Animals; Bayes Theorem; Computer Simulation; Humans; Neural Networks (Computer); Predictive Value of Tests; Time Factors,"Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Netw., 2 (5), pp. 359-366; Bishop, C.M., (1995) Neural Networks for Pattern Recognition, , London, U. K.: Oxford Univ. Press; Hussain, M.A., Review of the applications of neural networks in chemical process control - Simulation and online implementation (1999) Artif. Intell. Eng., 13 (1), pp. 55-68. , Jan; De Gooijer, J.G., Hyndman, R.J., 25 years of time series forecasting (2006) Int. J. Forecast., 22 (3), pp. 443-473; Bose, B.K., Neural network applications in power electronics and motor drives-an introduction and perspective (2007) IEEE Trans. Ind. Electron., 54 (1), pp. 14-33. , Feb; Paliwal, M., Kumar, U.A., Review: Neural networks and statistical techniques: A review of applications (2009) Expert Syst. Appl., 36 (1), pp. 2-17. , Jan; Liu, W.-H., Forecasting the semiconductor industry cycles by bootstrap prediction intervals (2007) Appl. Econ., 39 (13), pp. 1731-1742; Ho, S., Xie, M., Tang, L., Xu, K., Goh, T., Neural network modeling with confidence bounds: A case study on the solder paste deposition process (2001) IEEE Trans. Electron. Packag. Manuf., 24 (4), pp. 323-332. , Oct; Zhao, J.H., Dong, Z.Y., Xu, Z., Wong, K.P., A statistical approach for interval forecasting of the electricity price (2008) IEEE Trans. Power Syst., 23 (2), pp. 267-276. , May; Khosravi, A., Nahavandi, S., Creighton, D., Construction of optimal prediction intervals for load forecasting problems (2010) IEEE Trans. Power Syst., 25 (3), pp. 1496-1503. , Aug; Pierce, S.G., Worden, K., Bezazi, A., Uncertainty analysis of a neural network used for fatigue lifetime prediction (2008) Mech. Syst. Signal Process., 22 (6), pp. 1395-1411. , Aug; Benoit, D.F., Van Den Poel, D., Benefits of quantile regression for the analysis of customer lifetime value in a contractual setting: An application in financial services (2009) Expert Syst. Appl., 36 (7), pp. 10475-10484. , Sep; Shrestha, D.L., Solomatine, D.P., Machine learning approaches for estimation of prediction interval for the model output (2006) Neural Netw., 19 (2), pp. 225-235. , Mar; Van Hinsbergen, C., Van Lint, J., Van Zuylen, H., Bayesian committee of neural networks to predict travel times with confidence intervals (2009) Transport. Res. Part C: Emerg. Technol., 17 (5), pp. 498-509. , Oct; Khosravi, A., Mazloumi, E., Nahavandi, S., Creighton, D., Van Lint, J.W.C., Prediction intervals to account for uncertainties in travel time prediction (2011) IEEE Trans. Intell. Transport. Syst., 12 (2), pp. 537-547. , Jun; Khosravi, A., Mazloumi, E., Nahavandi, S., Creighton, D., Van Lint, J.W.C., A genetic algorithm-based method for improving quality of travel time prediction interval (2011) Transport. Res. Part C: Emerg. Technol., , Jun, to be published; Khosravi, A., Nahavandi, S., Creighton, D., A prediction intervalbased approach to determine optimal structures of neural network metamodels (2010) Expert Syst. Appl., 37 (3), pp. 2377-2387. , Mar; Hwang, J.T.G., Ding, A.A., Prediction intervals for artificial neural networks (1997) J. Amer. Stat. Assoc., 92 (438), pp. 748-757. , Jun; De Veaux, R.D., Schumi, J., Schweinsberg, J., Ungar, L.H., Prediction intervals for neural networks via nonlinear regression (1998) Technometrics, 40 (4), pp. 273-282. , Nov; MacKay, D.J.C., The evidence framework applied to classification networks (1992) Neural Comput., 4 (5), pp. 720-736. , Sep; Nix, D.A., Weigend, A.S., Estimating the mean and variance of the target probability distribution (1994) Proc. IEEE Int. Conf. Neural Netw., 1, pp. 55-60. , Orlando, FL, Jun.-, Jul; Efron, B., Bootstrap methods: Another look at the jackknife (1979) Ann. Stat., 7 (1), pp. 1-26. , Jan; Heskes, T., Practical confidence and prediction intervals (1997) Neural Information Processing Systems, 9, pp. 176-182. , T. P. M. Mozer and M. Jordan, Eds. Cambridge, MA: MIT Press; Papadopoulos, G., Edwards, P.J., Murray, A.F., Confidence estimation methods for neural networks: A practical comparison (2001) IEEE Trans. Neural Netw., 12 (6), pp. 1278-1287. , Nov; Ding, A., He, X., Backpropagation of pseudo-errors: Neural networks that are adaptive to heterogeneous noise (2003) IEEE Trans. Neural Netw., 14 (2), pp. 253-262. , Mar; Giordano, F., La Rocca, M., Perna, C., Forecasting nonlinear time series with neural network sieve bootstrap (2007) Comput. Stat. Data Anal., 51 (8), pp. 3871-3884. , May; Rivals, I., Personnaz, L., Construction of confidence intervals for neural networks based on least squares estimation (2000) Neural Netw., 13 (4-5), pp. 463-484. , Jun; Wild, C.J., Seber, G.A.F., (1989) Nonlinear Regression, , New York: Wiley; Tibshirani, R., A comparison of some error estimates for neural network models (1996) Neural Comput., 8 (1), pp. 152-163. , Jan; Hagan, M., Menhaj, M., Training feedforward networks with the Marquardt algorithm (1994) IEEE Trans. Neural Netw., 5 (6), pp. 989-993. , Nov; Dybowski, R., Roberts, S., Confidence intervals and prediction intervals for feed-forward neural networks (2000) Clinical Applications of Artificial Neural Networks, , R. Dybowski and V. Gant, Eds. Cambridge, U. K.: Cambridge Univ. Press; Khosravi, A., Nahavandi, S., Creighton, D., Atiya, A.F., Lower upper bound estimation method for construction of neural network-based prediction intervals (2011) IEEE Trans. Neural Netw., 22 (3), pp. 337-346. , Mar; Halberg, A.-M., Teigen, K.H., Fostervold, K.I., Maximum versus minimum values: Preferences of speakers and listeners for upper and lower limit estimates (2009) Acta Psychol., 132 (3), pp. 228-239. , Nov; Hashem, S., Optimal linear combinations of neural networks (1997) Neural Netw., 10 (4), pp. 599-614. , Jun; Ma, L., Khorasani, K., New training strategies for constructive neural networks with application to regression problems (2004) Neural Netw., 17 (4), pp. 589-609. , May; Vlachos, P., (2010) StatLib Datasets Archive, , http://lib.stat.cmu.edu/datasets, Jan; Khosravi, A., Nahavandi, S., Creighton, D., Constructing prediction intervals for neural network metamodels of complex systems (2009) Proc. Int. Joint Conf. Neural Netw., pp. 1576-1582. , Atlanta, GA, Jun; Asuncion, A., Newman, D.J., (2010) UCI Machine Learning Repository, , http://www.ics.uci.edu/~mlearn/MLRepository.html, Jan., School Inf. Comput. Sci., Univ. California, Irvine; De Moor, B., (2010) DaISy: Database for the Identification of Systems, , http://homes.esat.kuleuven.be/~smc/daisy, Jan., Dept. Electr. Eng., ESAT/SISTA, K. U. Leuven, Leuven, Belgium; Kirkpatrick, S., Gelatt Jr., C.D., Vecchi, M.P., Optimization by simulated annealing (1983) Science, 220 (4598), pp. 671-680. , May; Breiman, L., Bagging predictors (1996) Mach. Learn., 24 (2), pp. 123-140; Islam, M., Yao, X., Murase, K., A constructive algorithm for training cooperative neural network ensembles (2003) IEEE Trans. Neural Netw., 14 (4), pp. 820-834. , Jul; Efron, B., Tibshirani, R.J., (1993) An Introduction to the Bootstrap, , New York: Chapman & Hall; Davison, A.C., Hinkley, D.V., (1997) Bootstrap Methods and Their Application, , Cambridge, U. K.: Cambridge Univ. Press; Hansen, L., Salamon, P., Neural network ensembles (1990) IEEE Trans. Pattern Anal. Mach. Intell., 12 (10), pp. 993-1001. , Oct; Yao, X., Islam, M., Evolving artificial neural network ensembles (2008) IEEE Comput. Intell. Mag., 3 (1), pp. 31-42. , Feb; Gunter, S.I., Nonnegativity restricted least squares combinations (1992) Int. J. Forecast., 8 (1), pp. 45-59. , Jun; Taylor, J.W., Majithia, S., Using combined forecasts with changing weights for electricity demand profiling (2000) J. Oper. Res. Soc., 51 (1), pp. 72-82; Goldberg, D.E., (1989) Genetic Algorithms in Search, Optimization and Machine Learning, , Reading, MA: Addison-Wesley; Mitchell, M., (1996) An Introduction to Genetic Algorithms, , Cambridge, MA: MIT Press; Reeves, C.R., Rowe, J.E., (2003) Genetic Algorithms: Principles and Perspectives: A Guide to GA Theory, , Norwell, MA: Kluwer",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Mjolsness E., DeCoste D.",56822278400;55923760400;,Machine learning for science: State of the art and future prospects,2001,Science,10.1126/science.293.5537.2051,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035860537&doi=10.1126%2fscience.293.5537.2051&partnerID=40&md5=fc5137ac1da89c7dac27dd8dc0b9d05b,"Recent advances in machine learning methods, along with successful applications across a wide variety of fields such as planetary science and bioinformatics, promise powerful new tools for practicing scientists. This viewpoint highlights some useful characteristics of modern machine learning methods and their relevance to scientific applications. We conclude with some speculations on near-term progress and promising directions.",,"Biotechnology; Space research; Bioinformatics; Planetary science; Learning systems; artificial neural network; astronomy; automation; educational technology; hypothesis; information science; methodology; model; observation; phenomenology; priority journal; review; science; Algorithms; Animals; Artificial Intelligence; Astronomy; Cluster Analysis; Computational Biology; Computer Simulation; Gene Expression Profiling; Gene Expression Regulation; Image Processing, Computer-Assisted; Neural Networks (Computer); Physics; Robotics","Mitchell, T., (1997) Machine Learning, , McGraw-Hill, New York; Burge, C., Karlin, S., (1997) J. Mol. Biol., 268, p. 78; Shoemaker, D.D., (2001) Nature, 409, p. 922; Spellman, P.T., (1998) Mol. Biol. Cell, 9, p. 3273; Eisen, N.B., Spellman, P.T., Brown, P.O., Botstein, D., (1998) Proc. Natl. Acad. Sci. U.S.A., 95, p. 14863; Schölkopf, B., Smola, A., Müller, K.-R., (1999) Advances in Kernel Methods-SV Learning, pp. 327-352. , B. Schölkopf, C. J. C. Burges, A. J. Smola, Eds. (MIT Press, Cambridge, MA); Bell, A.J., Sejnowski, T.J., (1995) Neural Comput., 7, p. 6; Roweis, S., Saul, L., (2000) Science, 290, p. 2323; Shiozawa, M., (1999) Nucl. Instrum. Methods Phys. Res. Sect. A, 433, p. 240; Golub, T.R., (1999) Science, 286, p. 531; Brown, M., (2000) Proc. Natl. Acad. Sci. U.S.A., 97, p. 1; Mjolsness, E., Mann, T., Castaño, R., Wold, B., (2000) Adv. Neural Inform. Processing Syst., 12, p. 928; Jung, T.-P., (2001) Proc. IEEE, 89, p. 7; Burl, M.C., (1998) Machine Learning, 30, pp. 16S; Burl, M.C., (2001) 5th International Symposium on Artificial Intelligence, Robotics, and Automation in Space (i-SAIRAS), , Montreal, Canada, June; DeCoste, D., Schölkopf, B., Machine Learning, , in press; Levison, H.F., Dones, L., Duncan, M.J., (2001) Astron. J., 121, p. 4; Williams, B., Damle, S., Wold, B., unpublished data; Reinitz, J., Sharp, D.H., (1995) Mech. Dev., 49, p. 133; Mjolsness, E.D., Sharp, H., Reinitz, J., (1991) J. Theor. Biol., 152, p. 429; Gilmore, M.S., (2000) J. Geophys. Res., 105, p. 29233; Estlin, T., (1999) Proceedings of the American Association for Artificial Intelligence Conference, pp. 613-620. , AAAI Press/MIT Press, Orlando, FL; Davies, A., (2001) Autonomous Sciencecraft Constellation Science Study Report, , http://asc.jpl.nasa.gov, (Jet Propulsion Laboratory, Pasadena, CA, August); Turmon, M., Mukhtar, S., Pap, J., (1997) Proceedings of the Third Conference on Knowledge Discovery and Data Mining, pp. 267-270. , AAAI Press, Newport Beach, CA; Turmon, M., Pap, J.M., Mukhtar, S., (1998) Structure and Dynamics of the Interior of the Sun and Sun-like Stars, pp. 979-984. , ESA SP-418, European Space Agency Publications Division, Noordwijk, Netherlands; Jordan, M., (1998) Learning in Graphical Models, , Kluwer, Dordrecht, Netherlands; Murphy, K., Weiss, Y., Jordan, M., (1999) Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, pp. 467-475. , K. B. Laskey, H. Prade, Eds. (Kaufmann, San Francisco, CA); Weiss, Y., (2000) Neural Comput., 12, p. 1; Burges, C.J.C., (1998) Data Mining Knowledge Discov., 2, p. 2; Tong, S., Koller, D., (2000) Proceedings of the Seventeenth International Conference on Machine Learning, pp. 999-1006. , Kaufman, San Francisco, CA; Gold, S., Rangarajan, A., Mjolsness, E., (1996) Neural Comput., 8, p. 4; Mika, S., Rätsch, G., Müller, K.-R., (2001) Adv. Neural Inform. Processing Syst., 13, p. 591; Zien, A., (2000) Bioinformatics, 16, p. 799; note; note",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gold C., Sollich P.",9245309500;7004107468;,Model selection for support vector machine classification,2003,Neurocomputing,10.1016/S0925-2312(03)00375-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242288807&doi=10.1016%2fS0925-2312%2803%2900375-8&partnerID=40&md5=81857133688ee48d5571963ab1bdd639,"We address the problem of model selection for Support Vector Machine (SVM) classification. For fixed functional form of the kernel, model selection amounts to tuning kernel parameters and the slack penalty coefficient C. We begin by reviewing a recently developed probabilistic frame-work for SVM classification. An extension to the case of SVMs with quadratic slack penalties is given and a simple approximation for the evidence is derived, which can be used as a criterion for model selection. We also derive the exact gradients of the evidence in terms of posterior averages and describe how they can be estimated numerically using Hybrid Monte-Carlo techniques. Though computationally demanding, the resulting gradient ascent algorithm is a useful baseline tool for probabilistic SVM model selection, since it can locate maxima of the exact (unapproximated) evidence. We then perform extensive experiments on several benchmark data sets. The aim of these experiments is to compare the performance of probabilistic model selection criteria with alternatives based on estimates of the test error, namely the so-called ""span estimate"" and Wahba's Generalized Approximate Cross-Validation (GACV) error. We find that all the ""simple"" model criteria (Laplace evidence approximations, and the span and GACV error estimates) exhibit multiple local optima with respect to the hyperparameters. While some of these give performance that is competitive with results from other approaches in the literature, a significant fraction lead to rather higher test errors. The results for the evidence gradient ascent method show that also the exact evidence exhibits local optima, but these give test errors which are much less variable and also consistently lower than for the simpler model selection criteria. © 2003 Elsevier B.V. All rights reserved.",Bayesian evidence; Classification; Model selection; Probabilistic methods; Support vector machines,Algorithms; Approximation theory; Mathematical models; Monte Carlo methods; Probability; Vectors; Model selection; Neural networks; algorithm; analytic method; analytical error; classification; controlled study; machine; mathematical computing; mathematical model; Monte Carlo method; normal distribution; priority journal; probability; review; system analysis; validation process,"Barber, D., Williams, C.K.I., Gaussian processes for Bayesian classification via hybrid Monte Carlo (1997) Advances in Neural Information Processing Systems, 9, pp. 340-346. , M.C. Mozer, M.I. Jordan, T. Petsche (Eds.), MIT Press, Cambridge, MA; Burges, C.J.C., A tutorial on support vector machines for pattern recognition (1998) Data Mining Knowledge Discovery, 2 (2), pp. 121-167; Chapelle, O., Vapnik, V.N., Model selection for support vector machines (2000) Advances in Neural Information Processing Systems, 12, pp. 230-236. , S.A. Solla, T.K. Leen, K.-R. Müller (Eds.), MIT Press, Cambridge, MA; Chapelle, O., Vapnik, V., Bousquet, O., Mukherjee, S., Choosing multiple parameters for support vector machines (2002) Mach. Learning, 46 (1-3), pp. 131-159; Cristianini, N., Campbell, C., Shawe-Taylor, J., Dynamically adapting kernels in support vector machines (1999) Advances in Neural Information Processing Systems, 11, pp. 204-210. , M. Kearns, S.A. Solla, D. Cohn (Eds.), MIT Press, Cambridge, MA; Cristianini, N., Shawe-Taylor, J., (2000) an Introduction to Support Vector Machines, , Cambridge University Press, Cambridge; Jaakkola, T., Haussler, D., Probabilistic kernel regression models (1999) Proceedings of the Seventh International Workshop on Artificial Intelligence and Statistics, , D. Heckerman, J. Whittaker (Eds.), San Francisco, CA, Morgan Kaufmann, Los Altos, CA; Krauth, W., Introduction to Monte Carlo algorithms (1998) Advances in Computer Simulation, , J. Kertesz, I. Kondor (Eds.), Springer, Berlin; Kwok, J.T.Y., Moderating the outputs of support vector machine classifiers (1999) IEEE Trans. Neural Networks, 10 (5), pp. 1018-1031; Kwok, J.T.Y., The evidence framework applied to support vector machines (2000) IEEE Trans. Neural Networks, 11 (5), pp. 1162-1173; MacKay, D.J.C., Bayesian interpolation (1992) Neural Comput., 4, pp. 415-447; MacKay, D.J.C., The evidence framework applied to classification networks (1992) Neural Comput., 4, pp. 720-736; Neal, R.M., Probabilistic inference using Markov chain Monte Carlo methods (1993), Technical Report CRG-TR-93-1, University of Toronto; Neal, R.M., (1996) Bayesian Learning for Neural Networks, , Springer, New York; Opper, M., Winther, O., Gaussian process classification and SVM: Mean field results and leave-one-out estimator (2000) Advances in Large Margin Classifiers, pp. 311-326. , A.J. Smola, P. Bartlett, B. Schölkopf, D. Schuurmans (Eds.), MIT Press, Cambridge, MA; Opper, M., Winther, O., Gaussian processes for classification: Mean-field algorithms (2000) Neural Comput., 12 (11), pp. 2655-2684; Press, W.H., Teukolsky, S.A., Vetterling, W.T., Flannery, B.P., (1992) Numerical Recipes in C, , 2nd Edition, Cambridge University Press, Cambridge; Seeger, M., Bayesian model selection for support vector machines, Gaussian processes and other kernel classifiers (2000) Advances in Neural Information Processing Systems, 12, pp. 603-609. , S.A. Solla, T.K. Leen, K.R. Müller (Eds.), MIT Press, Cambridge, MA; Smola, A.J., Schölkopf, B., Müller, K.R., The connection between regularization operators and support vector kernels (1998) Neural Networks, 11 (4), pp. 637-649; Sollich, P., Probabilistic interpretation and Bayesian methods for support vector machines (1999), pp. 91-96. , ICANN99 - Ninth International Conference on Artificial Neural Networks, The Institution of Electrical Engineers, London; Sollich, P., Probabilistic methods for support vector machines (2000) Advances in Neural Information Processing Systems, 12, pp. 349-355. , S.A. Solla, T.K. Leen, K.-R. Müller (Eds.), MIT Press, Cambridge, MA; Sollich, P., Bayesian methods for support vector machines: Evidence and predictive class probabilities (2002) Mach. Learning, 46 (1-3), pp. 21-52; Tipping, M.E., The relevance vector machine (2000) Advances in Neural Information Processing Systems, 12, pp. 652-658. , S.A. Solla, T.K. Leen, K.-R. Müller (Eds.), MIT Press, Cambridge, MA; Vapnik, V., (1995) The Nature of Statistical Learning Theory, , Springer, New York; Vapnik, V., (1998) Statistical Learning Theory, , Wiley, New York; Vapnik, V., Chapelle, O., Bounds on error expectation for support vector machines (2000) Neural Comput., 12 (9), pp. 2013-2036; Wahba, G., Support vector machines, reproducing kernel Hilbert spaces and the randomized GACV (1998) Advances in Kernel Methods: Support Vector Machines, pp. 69-88. , B. Schölkopf, C. Burges, A.J. Smola (Eds.), MIT Press, Cambridge, MA; Williams, C.K.I., Prediction with Gaussian processes: From linear regression to linear prediction and beyond (1998) Learning and Inference in Graphical Models, pp. 599-621. , M.I. Jordan (Ed.), Kluwer Academic, Dordrecht; Williams, C.K.I., Barber, D., Bayesian classification with Gaussian processes (1998) IEEE Trans. Pattern Anal. Mach. Intell., 20 (12), pp. 1342-1351; Williams, C.K.I., Seeger, M., Using the Nyström method to speed up kernel machines (2001) Advances in Neural Information Processing Systems, 13, pp. 682-688. , T.K. Leen, T.G. Dietterich, V. Tresp (Eds.), MIT Press, Cambridge, MA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mittal S.,36158412700;,A survey of techniques for approximate computing,2016,ACM Computing Surveys,10.1145/2893356,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963984095&doi=10.1145%2f2893356&partnerID=40&md5=6ad7d90f3f5cac5617dff60d26381e53,"Approximate computing trades off computation quality with effort expended, and as rising performance demands confront plateauing resource budgets, approximate computing has become not merely attractive, but even imperative. In this article, we present a survey of techniques for approximate computing (AC). We discuss strategies for finding approximable program portions and monitoring output quality, techniques for using AC in different processing units (e.g., CPU, GPU, and FPGA), processor components, memory technologies, and so forth, as well as programming frameworks for AC. We classify these techniques based on several key characteristics to emphasize their similarities and differences. The aim of this article is to provide insights to researchers into working of AC techniques and inspire more efforts in this area to make AC the mainstream computing approach in future systems. © 2016 ACM.",Approximate computing technique (ACT); Approximate storage; Classification; CPU; FPGA; GPU; Neural networks; Quality configurability; Review,Budget control; Classification (of information); Field programmable gate arrays (FPGA); Neural networks; Program processors; Reconfigurable hardware; Reviews; Surveys; Computation quality; Computing techniques; Configurability; Key characteristics; Memory technology; Processing units; Programming framework; Resource budget; FORTH (programming language),"Akturk, I., Khatamifard, K., Karpuzcu, U.R., On quantification of accuracy loss in approximate computing (2015) Workshop on Duplicating, Deconstructing and Debunking; Alvarez, C., Corbal, J., Valero, M., Fuzzy memoization for floating-point multimedia applications (2005) IEEE Transactions on Computers, 54 (7), pp. 922-927; St Amant, R., Yazdanbakhsh, A., Park, J., Thwaites, B., Esmaeilzadeh, H., Hassibi, A., Ceze, L., Burger, D., General-purpose code acceleration with limited-precision analog computation (2014) International Symposium on Computer Architecture, pp. 505-516; Anam, M.A., Whatmough, P., Andreopoulos, Y., Precision-energythroughput scaling of generic matrix multiplication and discrete convolution kernels via linear projections (2013) Symposium on Embedded Systems for Real-time Multimedia (ESTIMedia'13), pp. 21-30; Ansel, J., Wong, Y.L., Chan, C., Olszewski, M., Edelman, A., Amarasinghe, S., Language and compiler support for auto-tuning variable-accuracy algorithms (2011) International Symposium on Code Generation and Optimization, pp. 85-96; Baek, W., Chilimbi, T.M., Green: A framework for supporting energy-conscious programming using controlled approximation (2010) ACM SIGPLAN Notices, 45, pp. 198-209; Bornholt, J., Mytkowicz, T., McKinley, K.S., Uncertain<T>: A first-order type for uncertain data (2014) ACM SIGARCH Computer Architecture News, 42 (1), pp. 51-66; Byna, S., Meng, J., Raghunathan, A., Chakradhar, S., Cadambi, S., Besteffort semantic document search on GPUs (2010) General-Purpose Computation on Graphics Processing Units, pp. 86-93; Carbin, M., Misailovic, S., Rinard, M.C., Verifying quantitative reliability for programs that execute on unreliable hardware (2013) ACM SIGPLAN Notices, 48, pp. 33-52; Chakradhar, S.T., Raghunathan, A., Best-effort computing: Re-thinking parallel software and hardware (2010) Design Automation Conference, pp. 865-870; Chippa, V.K., Chakradhar, S.T., Roy, K., Raghunathan, A., Analysis and characterization of inherent application resilience for approximate computing (2013) Design Automation Conference, p. 113; Chippa, V.K., Mohapatra, D., Roy, K., Chakradhar, S.T., Raghunathan, A., Scalable effort hardware design (2014) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 22 (9), pp. 2004-2016; Cho, K., Lee, Y., Oh, Y.H., Hwang, G.-C., Lee, J.W., EDRAM-based tieredreliability memory with applications to low-power frame buffers (2014) International Symposium on Low Power Electronics and Design, pp. 333-338; Du, Z., Lingamneni, A., Chen, Y., Palem, K., Temam, O., Wu, C., Leveraging the error resilience of machine-learning applications for designing highly energy efficient accelerators (2014) Asia and South Pacific Design Automation Conference (ASP-DAC'14), pp. 201-206; Düben, P., Schlachter, J., Parishkrati, Yenugula, S., Augustine, J., Enz, C., Palem, K., Palmer, T.N., Opportunities for energy efficient computing: A study of inexact general purpose processors for high-performance and big-data applications (2015) Design, Automation & Test in Europe, pp. 764-769; Eldridge, S., Raudies, F., Zou, D., Joshi, A., Neural network-based accelerators for transcendental function approximation (2014) Great Lakes Symposium on VLSI, pp. 169-174; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Architecture support for disciplined approximate programming (2012) ACM SIGPLAN Notices, 47, pp. 301-312; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Neural acceleration for generalpurpose approximate programs (2012) IEEE/ACM International Symposium on Microarchitecture, pp. 449-460; Fang, Y., Li, H., Li, X., SoftPCM: Enhancing energy efficiency and lifetime of phase change memory in video applications via approximate write (2012) IEEE Asian Test Symposium (ATS), pp. 131-136; Ganapathy, S., Karakonstantis, G., Teman, A.S., Burg, A.P., Mitigating the impact of faults in unreliable memories for error-resilient applications (2015) Design Automation Conference; Gantz, J., Reinsel, D., (2011) Extracting Value from Chaos, , http://www.emc.com/collateral/analyst-reports/idc-extracting-value-from-chaos-ar.pdf, Retrieved February 25, 2016 from; Goiri, Í., Bianchini, R., Nagarakatte, S., Nguyen, T.D., Approx hadoop: Bringing approximations to MapReduce frameworks (2015) International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 383-397; Grigorian, B., Farahpour, N., Reinman, G., BRAINIAC: Bringing reliable accuracy into neurally-implemented approximate computing (2015) International Symposium on High Performance Computer Architecture (HPCA'15), pp. 615-626; Grigorian, B., Reinman, G., Dynamically adaptive and reliable approximate computing using light-weight error analysis (2014) Conference on Adaptive Hardware and Systems (AHS'14), pp. 248-255; Grigorian, B., Reinman, G., Accelerating divergent applications on SIMD architectures using neural networks (2015) ACM Transactions on Architecture and Code Optimization (TACO), 12 (1), p. 2; Gupta, V., Mohapatra, D., Park, S.P., Raghunathan, A., Roy, K., IMPACT: Imprecise adders for low-power approximate computing (2011) International Symposium on Low Power Electronics and Design, pp. 409-414; Hegde, R., Shanbhag, N.R., Energy-efficient signal processing via algorithmic noisetolerance (1999) International Symposium on Low Power Electronics and Design, pp. 30-35; Hsiao, C.-C., Chu, S.-L., Chen, C.-Y., Energy-aware hybrid precision selection framework for mobile GPUs (2013) Computers and Graphics, 37 (5), pp. 431-444; Kahng, A.B., Kang, S., Accuracy-configurable adder for approximate arithmetic designs (2012) Design Automation Conference, pp. 820-825; Keramidas, G., Kokkala, C., Stamoulis, I., Clumsy value cache: An approximate memoization technique for mobile GPU fragment shaders (2015) Workshop on Approximate Computing (WAPCO'15); Khudia, D.S., Zamirai, B., Samadi, M., Mahlke, S., Rumba: An online quality management system for approximate computing (2015) International Symposium on Computer Architecture, pp. 554-566; Kulkarni, P., Gupta, P., Ercegovac, M., Trading accuracy for power with an underdesigned multiplier architecture (2011) International Conference on VLSI Design (VLSI Design'11), pp. 346-351; Li, B., Gu, P., Shan, Y., Wang, Y., Chen, Y., Yang, H., RRAM-based analog approximate computing (2015) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems; Liu, S., Pattabiraman, K., Moscibroda, T., Zorn, B.G., Flikker: Saving DRAM refresh-power through critical data partitioning (2012) ACM SIGPLAN Notices, 47 (4), pp. 213-224; Lopes, A.R., Shahzad, A., Constantinides, G., Kerrigan, E.C., More flops or more precision? Accuracy parameterizable linear equation solvers for model predictive control (2009) Symposium on Field Programmable Custom Computing Machines (FCCM'09), pp. 209-216; Mahajan, D., Yazdanbakhsh, A., Park, J., Thwaites, B., Esmaeilzadeh, H., Prediction-based quality control for approximate accelerators (2015) Workshop on Approximate Computing Across the System Stack; McAfee, L., Olukotun, K., EMEURO: A framework for generating multi-purpose accelerators via deep learning (2015) International Symposium on Code Generation and Optimization, pp. 125-135; Miguel, J.S., Badr, M., Jerger, E.N., Load value approximation (2014) MICRO; Misailovic, S., Carbin, M., Achour, S., Qi, Z., Rinard, M.C., Chisel: Reliabilityand accuracy-aware optimization of approximate computational kernels (2014) International Conference on Object Oriented Programming Systems Languages and Applications, pp. 309-328; Mishra, A.K., Barik, R., Paul, S., IACT: A software-hardware framework for understanding the scope of approximate computing (2014) Workshop on Approximate Computing Across the System Stack (WACAS'14); Mittal, S., A survey of architectural techniques for DRAM power management (2012) International Journal of High Performance Systems Architecture, 4 (2), pp. 110-119; Mittal, S., (2014) Power Management Techniques for Data Centers: A Survey, , Technical Report. Oak Ridge National Laboratory, Oak Ridge, TN; Mittal, S., A survey of architectural techniques for improving cache power efficiency (2014) Sustainable Computing: Informatics and Systems, 4 (1), pp. 33-43; Mittal, S., A survey of architectural techniques for near-threshold computing (2015) ACM Journal on Emerging Technologies in Computing Systems, 12 (4), pp. 1-26; Mittal, S., Vetter, J., A survey of techniques for modeling and improving reliability of computing systems (2015) IEEE Transactions on Parallel and Distributed Systems (TPDS); Mittal, S., Vetter, J.S., Li, D., A survey of architectural approaches for managing embedded DRAM and non-volatile on-chip caches (2015) IEEE Transactions on Parallel and Distributed Systems (TPDS), 26 (6), pp. 1524-1537; Moreau, T., Wyse, M., Nelson, J., Sampson, A., Esmaeilzadeh, H., Ceze, L., Oskin, M., SNNAP: Approximate computing on programmable SoCs via neural acceleration (2015) International Symposium on High Performance Computer Architecture (HPCA'15), pp. 603-614; NRDC, (2015), http://www.nrdc.org/energy/data-center-efficiencyassessment.asp, Retrieved February 25, 2016 from; Rahimi, A., Benini, L., Gupta, R.K., Spatial memoization: Concurrent instruction reuse to correct timing errors in SIMD architectures (2013) IEEE Transactions on Circuits and Systems II: Express Briefs, 60 (12), pp. 847-851; Rahimi, A., Ghofrani, A., Cheng, K.-T., Benini, L., Gupta, R.K., Approximate associative memristive memory for energy-efficient GPUs (2015) Design, Automation and Test in Europe, pp. 1497-1502; Raha, A., Venkataramani, S., Raghunathan, V., Raghunathan, A., Quality configurable reduce-and-rank for energy efficient approximate computing (2015) Design, Automation and Test in Europe, pp. 665-670; Rahimi, A., Marongiu, A., Gupta, R.K., Benini, L., A variability-aware OpenMP environment for efficient execution of accuracy-configurable computation on shared-FPU processor clusters (2013) International Conference on Hardware/Software Codesign and System Synthesis, p. 35; Ranjan, A., Venkataramani, S., Fong, X., Roy, K., Raghunathan, A., Approximate storage for energy efficient spintronic memories (2015) Design Automation Conference, p. 195; Ringenburg, M., Sampson, A., Ackerman, I., Ceze, L., Grossman, D., Monitoring and debugging the quality of results in approximate programs (2015) International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 399-411; Ringenburg, M.F., Sampson, A., Ceze, L., Grossman, D., Profiling and autotuning for energy-aware approximate programming (2014) Workshop on Approximate Computing Across the System Stack (WACAS'14); Roy, P., Ray, R., Wang, C., Wong, W.F., ASAC: Automatic sensitivity analysis for approximate computing (2014) Conference on Languages, Compilers and Tools for Embedded Systems, pp. 95-104; Samadi, M., Jamshidi, D.A., Lee, J., Mahlke, S., Paraprox: Patternbased approximation for data parallel applications (2014) ACM SIGARCH Computer Architecture News, 42, pp. 35-50; Samadi, M., Lee, J., Anoushe Jamshidi, D., Hormati, A., Mahlke, S., SAGE: Self-tuning approximation for graphics engines (2013) International Symposium on Microarchitecture, pp. 13-24; Samadi, M., Mahlke, S., CPU-GPU collaboration for output quality monitoring (2014) Workshop on Approximate Computing Across the System Stack, pp. 1-3; Sampson, A., Baixo, A., Ransford, B., Moreau, T., Yip, J., Ceze, L., Oskin, M., (2015) ACCEPT: A Programmer-Guided Compiler Framework for Practical Approximate Computing, , Technical Report. University of Washington, Seattle, WA; Sampson, A., Dietl, W., Fortuna, E., Gnanapragasam, D., Ceze, L., Grossman, D., EnerJ: Approximate data types for safe and general low-power computation (2011) ACM SIGPLAN Notices, 46, pp. 164-174; Sampson, A., Nelson, J., Strauss, K., Ceze, L., Approximate storage in solid-state memories (2013) International Symposium on Microarchitecture, pp. 25-36; Sartori, J., Kumar, R., Branch and data herding: Reducing control andmemory divergence for error-tolerant GPU applications (2013) IEEE Transactions on Multimedia, 15 (2), pp. 279-290; Shi, Q., Hoffmann, H., Khan, O., A HW-SW multicore architecture to tradeoff program accuracy and resilience overheads (2015) Computer Architecture Letters; Shim, B., Sridhara, S.R., Shanbhag, N.R., Reliable low-power digital signal processing via reduced precision redundancy (2004) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 12 (5), pp. 497-510; Shoushtari, M., Mofrad, A.B., Dutt, N., Exploiting partially-forgetful memories for approximate computing (2015) IEEE Embedded Systems Letters, 7 (1), pp. 19-22; Sidiroglou, S., Misailovic, S., Hoffmann, H., Rinard, M., Managing performance vs. Accuracy trade-offs with loop perforation (2011) ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering, pp. 124-134; Sutherland, M., Miguel, J.S., Jerger, N.E., Texture cache approximation on GPUs (2015) Workshop on Approximate Computing Across the Stack; Tian, Y., Zhang, Q., Wang, T., Yuan, F., Xu, Q., Approx MA: Approximate memory access for dynamic precision scaling (2015) ACM Great Lakes Symposium on VLSI, pp. 337-342; Varatkar, G.V., Shanbhag, N.R., Error-resilient motion estimation architecture (2008) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 16 (10), pp. 1399-1412; Vassiliadis, V., Parasyris, K., Chaliosy, C., Antonopoulos, C.D., Lalis, S., Bellas, N., Vandierendoncky, H., Nikolopoulos, D.S., A programming model and runtime system for significance-aware energy-efficient computing (2015) 1st Workshop on Approximate Computing (WAPCO'15); Venkataramani, S., Chakradhar, S.T., Roy, K., Raghunathan, A., Approximate computing and the quest for computing efficiency (2015) Design Automation Conference, p. 120; Venkataramani, S., Chippa, V.K., Chakradhar, S.T., Roy, K., Raghunathan, A., Quality programmable vector processors for approximate computing (2013) International Symposium on Microarchitecture, pp. 1-12; Venkataramani, S., Raghunathan, A., Liu, J., Shoaib, M., Scalable-effort classifiers for energy-efficient machine learning (2015) Design Automation Conference, p. 67; Venkataramani, S., Ranjan, A., Roy, K., Raghunathan, A., AxNN: Energyefficient neuromorphic systems using approximate computing (2014) International Symposium on Low Power Electronics and Design, pp. 27-32; Venkataramani, S., Sabne, A., Kozhikkottu, V., Roy, K., Raghunathan, A., SALSA: Systematic logic synthesis of approximate circuits (2012) Design Automation Conference, pp. 796-801; Vetter, J.S., Mittal, S., Opportunities for nonvolatile memory systems in extreme-scale high performance computing (2015) Computing in Science and Engineering, 17 (2), pp. 73-82; Xu, X., Howie Huang, H., Exploring data-level error tolerance in high-performance solid-state drives (2015) IEEE Transactions on Reliability, 64 (1), pp. 15-30; Yazdanbakhsh, A., Mahajan, D., Thwaites, B., Park, J., Nagendrakumar, A., Sethuraman, S., Ramkrishnan, K., Bazargan, K., Axilog: Language support for approximate hardware design (2015) Design, Automation and Test in Europe Conference and Exhibition, pp. 812-817; Yazdanbakhsh, A., Pekhimenko, G., Thwaites, B., Esmaeilzadeh, H., Kim, T., Mutlu, O., Mowry, T.C., (2015) RFVP: Rollback-Free Value Prediction with Safe-to-Approximate Loads, , Technical Report. Georgia Institute of Technology, Atlanta, GA; Yeh, T.Y., Faloutsos, P., Ercegovac, M., Patel, S.J., Reinman, G., The art of deception: Adaptive precision reduction for area efficient physics acceleration (2007) International Symposium on Microarchitecture, pp. 394-406; Yetim, Y., Martonosi, M., Malik, S., Extracting useful computation from errorprone processors for streaming applications (2013) Design, Automation and Test in Europe Conference and Exhibition (DATE'13), pp. 202-207; Zhang, H., Putic, M., Lach, J., Low power GPGPU computation with imprecise hardware (2014) Design Automation Conference (DAC'14), pp. 1-6; Zhang, Q., Wang, T., Tian, Y., Yuan, F., Xu, Q., Approx ANN: An approximate computing framework for artificial neural network (2015) Design, Automation and Test in Europe, pp. 701-706",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tsodyks M., Gilbert C.",7003469335;7201382780;,Neural networks and perceptual learning,2004,Nature,10.1038/nature03013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-7244257333&doi=10.1038%2fnature03013&partnerID=40&md5=8e72247fbb2232b76cdadb8abac6ce48,"Sensory perception is a learned trait. The brain strategies we use to perceive the world are constantly modified by experience. With practice, we subconsciously become better at identifying familiar objects or distinguishing fine details in our environment. Current theoretical models simulate some properties of perceptual learning, but neglect the underlying cortical circuits. Future neural network models must incorporate the top-down alteration of cortical function by expectation or perceptual tasks. These newly found dynamic processes are challenging earlier views of static and feedforward processing of sensory information.",,"Brain; Computer simulation; Feedforward neural networks; Information analysis; Sensors; Sensory perception; Brain strategies; Cortical functions; Dynamic processes; Perceptual learning; Learning systems; biology; learning; brain; brain function; expectation; experience; information processing; learning; nerve cell network; perception; positive feedback; priority journal; review; sensory system; task performance; theoretical model; Brain; Humans; Learning; Models, Neurological; Nerve Net; Neuronal Plasticity; Perception","Wang, Q., Cavanagh, P., Green, M., Familiarity and pop-out in visual search (1994) Percept. Psychophys., 56, pp. 495-500; Sigman, M., Gilber, C.D., Learning to find a shape (2000) Nature Neurosci., 3, pp. 264-269; Hertz, J., Krogh, A., Palmer, R.G., (1991) Introduction to the Theory of Neural Computation, , Perseus Publishing, Cambridge, Massachussetts; Zhaoping, L., Herzog, M., Dayan, P., Nonlinear observation and recurrent preprocessing in perceptual learning (2003) Network, 14, pp. 233-247; Poggio, T., Fahle, M., Edelman, S., Fast perceptual learning in visual hyperacuity (1992) Science, 256, pp. 1018-1021; Herzog, M.H., Fahle, M., The role of feedback in learning a vernier discrimination task (1997) Vision Res., 37, pp. 2133-2141; Adini, Y., Sagi, D., Tsodyks, M., Context enabled learning in human visual system (2003) Nature, 415, pp. 790-794; Tsodyks, M., Adini, Y., Sagi, D., Associative learning in early vision (2004) Neural Netw., 17, pp. 823-832; Wilson, H.R., Cowan, J.D., Excitatory and inhibitory interactions in localized populations of model neurons (1972) Biophys. J., 12, pp. 1-24; Hoshino, O., Neuronal bases of perceptual learning revealed by a synaptic balance scheme (2004) Neural Comput., 16, pp. 563-594; Teich, A., Qian, N., Learning and adaptation in a recurrent model of V1 orientation selectivity (2003) J. Neurophysiol., 89, pp. 2086-2100; Schoups, A., Vogels, R., Qian, N., Orban, G., Practising orientation identification improves orientation coding in V1 neurons (2001) Nature, 412, pp. 549-553; Ben-Yishai, R., Bar-Or, R.L., Sompolinsky, H., Theory of orientation tuning in visual cortex (1995) Proc. Natl. Acad. Sci. USA, 92, pp. 3844-3848; Douglas, R., Koch, C., Mahowald, M., Martin, K., Suarez, H., Recurrent excitation in neocortical circuits (1995) Science, 269, pp. 981-985; Somers, D., Nelson, S., Sur, M., An emergent model of orientation selectivity in cat visual cortical simple cells (1995) J. Neurosci., 15, pp. 5448-5465; Gilbert, C.D., Wiesel, T.N., The influence of contextual stimuli on the orientation selectivity of cells in primary visual cortex of the cat (1990) Vision Res., 30, pp. 1689-1701; Dragoi, V., Sharma, J., Sur, M., Adaptation-induced plasticity of orientation tuning in adult visual cortex (2000) Neuron, 28, pp. 287-298; Polat, U., Sagi, D., Spatial interactions in human vision: From near to far via experience-dependent cascade of connections (1994) Proc. Natl. Acad. Sci. USA, 91, pp. 1206-1209; Seung, H.S., Learning in spiking neural networks by reinforcement of stochastic synaptic transmission (2003) Neuron, 40, pp. 1063-1073; Williams, R., Simple statistical gradient-following algorithms for connectionst reinforcement learning (1992) Mach. Learn., 8, pp. 229-256; Grist, R.E., Kapadia, M., Westheimer, G., Gilbert, C.D., Perceptual learning of spatial localization: Specificity for orientation, position and context (1997) J. Neurophysiol., 78, pp. 2889-2894; McKee, S.P., Westheimer, G., Improvement in vernier acuity with practice (1978) Percept. Psychophys., 24, pp. 258-262; Polat, U., Ma-Naim, T., Belkin, M., Sagi, D., Improving vision in adult amblyopia by perceptual learning (2004) Proc. Natl. Acad. Sci. USA, 101, pp. 6692-6697; Ullman, S., Bart, E., Recognition invariance obtained by extended and invariant features (2004) Neural Netw., 17, pp. 833-848; Grist, R., Li, W., Gilbert, C., Learning to see: Experience and attention in primary visual cortex (2001) Nature Neurosci., 4, pp. 519-525; Li, W., Piech, V., Gilber, C.D., Perceptual learning and top-down influences in primary visual cortex (2004) Nature Neurosci., 7, pp. 651-657; Recanzone, G.H., Merzenich, M.M., Jenkins, W.M., Frequency discrimination training engaging a restricted skin surface results in an emergence of a cutaneous response zone in cortical area 3a (1992) J. Neurophysiol., 67, pp. 1057-1070; Recanzone, G.H., Schreiner, C.E., Merzenich, M.M., Plasticity in the frequency representation of primary auditory cortex following discrimination training in adult owl monkeys (1993) J. Neurosci., 13, pp. 87-103; Recanzone, G.H., Merzenich, M.M., Schreiner, C.E., Changes in the distributed temporal response properties of SI cortical neurons reflect improvements in performance on a temporally based tactile discrimination task (1992) J. Neurophysiol., 67, pp. 1071-1091; Bakin, J.S., Winberger, N.M., Induction of a physiological memory in the cerebral cortex by stimulation of the nuclear basalis (1996) Proc. Natl. Acad. Sci. USA, 93, pp. 11219-11224; Kilgard, M.P., Merzenich, M.M., Cortical map reorganization enabled by nucleus basalis activity (1998) Science, 279, pp. 1714-1718; Seung, H.S., Sompolinsky, H., Tishby, N., Statistical mechanics of learning from examples (1992) Phys. Rev. A, 45, pp. 6056-6091; Herzog, M.H., Fahle, M., Modeling perceptual learning difficulties and how they can be overcome (1998) Biol. Cybern., 78, pp. 107-117; Mato, G., Sompolinsky, H., Neural network models of perceptual learning of angle discrimination (1996) Neural Comput., 8, pp. 270-299; Dosher, B.A., Lu, Z.L., Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting (1998) Proc. Natl. Acad. Sci. USA, 95, pp. 13988-13993; Moses, Y., Schechtman, G., Ullman, S., Self-calibrated collinearity detector (1990) Biol. Cybern., 63, pp. 463-475; Weiss, Y., Edelman, S., Fahle, M., Models of perceptual learning in vernier hyperacuity (1993) Neural Comput., 5, pp. 695-718; Karni, A., Sagi, D., The time course of learning a visual skill (1993) Nature, 365, pp. 250-252; Ahissar, M., Hochstein, S., Attentional control of early perceptual learning (1993) Proc. Natl. Acad. Sci. USA, 90, pp. 5718-5722; Watanabe, T., Nanez, J.E., Sasaki, Y., Perceptual learning without perception (2001) Nature, 413, pp. 844-848; Seitz, A.R., Watanabe, T., Psychophysics: Is subliminal learning really passive? (2003) Nature, 422, p. 36; Rao, R.P., Ballard, D.H., Dynamic model of visual recognition predicts neural response properties in the visual cortex (1997) Neural Comput., 9, pp. 721-763; Ullman, S., Sequence seeking and counter streams: A computational model for bidirectional information flow in the visual cortex (1995) Cereb. Cortex, 5, pp. 1-11; Hebb, D.O., (1949) Organization of Behavior, , John Wiley & Sons Inc; Barlow, H.B., Foldiak, P., (1989) The Computing Neuron, pp. 54-72. , (eds Durbin, R. Miall, C. & Mitchison, G.) (Addison-Wesley, Workingham, England); Markram, H., Lubke, J., Frotscher, M., Sakmann, B., Regulation of synaptic efficacy by coincidence of postsynaptic Aps and EPSPs (1997) Science, 275, pp. 213-215; Senn, W., Markram, H., Tsodyks, M., An algorithm for modifying neurotransmitter release probability based on pre- and post-synaptic spike timing (2001) Neural Comput., 13, pp. 35-67; Yu, C., Levi, D.M., Klein, S.A., Perceptual learning in contrast discrimination and the (minimal) role of context (2004) J. Vision, 4, pp. 169-182; Adini, Y., Wilkonsky, A., Haspel, R., Tsodyks, M., Sagi, D., Perceptual learning in contrast discrimination: The effect of contrast uncertainty J. Vision, , in the press; Chose, G.M., Yang, T., Maunsell, J.H.R., Physiological correlates of perceptual learning in monkey V1 and V2 (2002) J. Nearophysiol., 87, pp. 1867-1888",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Eiben A.E., Smith J.",7004362543;7410180217;,From evolutionary computation to the evolution of things,2015,Nature,10.1038/nature14544,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930674315&doi=10.1038%2fnature14544&partnerID=40&md5=3649e5b9c6aa0813132e2ae3624ff0c0,"Evolution has provided a source of inspiration for algorithm designers since the birth of computers. The resulting field, evolutionary computation, has been successful in solving engineering tasks ranging in outlook from the molecular to the astronomical. Today, the field is entering a new phase as evolutionary algorithms that take place in hardware are developed, opening up new avenues towards autonomous machines that can adapt to their environment. We discuss how evolutionary computation compares with natural evolution and what its benefits are relative to other computing approaches, and we introduce the emerging area of artificial evolution in physical systems. © 2015 Macmillan Publishers Limited. All rights reserved .",,"algorithm; hardware; machinery; technological development; art; artificial intelligence; astronomy; computer; evolutionary adaptation; evolutionary algorithm; genotype; human; machine learning; priority journal; problem solving; research; Review; adaptation; algorithm; automation; biomimetics; computer; devices; evolution; mathematics; robotics; theoretical model; trends; Adaptation, Physiological; Algorithms; Automation; Biological Evolution; Biomimetics; Computers; Genotype; Mathematics; Models, Theoretical; Problem Solving; Robotics","Turing, A.M., (1969) Machine Intelligence, 5. , eds Meltzer, B. & Michie, D. Edinburgh Univ. Press; Fogel, L., Owens, L.A.J., Walsh, M.J., (1966) Artificial Intelligence Through Simulated Evolution, , Wiley; Rechenberg, I., (1973) Evolutionstrategie: Optimierung Technisher Systeme Nach Prinzipien des Biologischen Evolution, , in German. Fromman-HozlboogHozlboog; Schwefel, H.-P., (1977) Numerical Optimization of Computer Models, , Birkhäuser; Holland, J.H., (1975) Adaption in Natural and Artificial Systems, , Univ. Michigan Press; Koza, J.R., (1992) Genetic Programming, , MIT Press; Eiben, A.E., Smith, J.E., (2003) Introduction to Evolutionary Computing, , Springer; Ashlock, D., (2006) Evolutionary Computation for Modeling and Optimization, , Springer; De Jong, K., (2006) Evolutionary Computation: A Unified Approach, , MIT Press; Wang, C., Yu, S., Chen, W., Sun, C., Highly efficient light-trapping structure design inspired by natural evolution (2013) Sci. Rep., 3, p. 1025; Schmidt, M., Lipson, H., Distilling free-form natural laws from experimental data (2009) Science, 324, pp. 81-85; Eiben, A.E., Kernbach, S., Haasdijk, E., Embodied artificial evolution: Artificial evolutionary systems in the 21st Century (2012) Evol. Intel., 5, pp. 261-272; Eiben, A.E., (2014) Parallel Problem Solving from Nature-PPSNXII, pp. 24-39. , eds Filipic, B., Bartz-Beielstein, T. Branke, J. & Smith, J. Springer; Piperno, D.R., Ranere, A.J., Holst, I., Iriarte, J., Dickau, R., Starch grain and phytolith evidence for early ninth millennium B.P. Maize from the central balsas river valley, Mexico (2009) Proc. Natl Acad. Sci. USA, 106, pp. 5019-5024; Akey, J.M., Tracking footprints of artificial selection in the dog genome (2010) Proc. Natl Acad. Sci. USA, 107, pp. 1160-1165; Dennett, D., (1995) Darwin's Dangerous Idea, , Penguin; Goldberg, D., (1989) Genetic Algorithms in Search, Optimization, and Machine Learning, , Addison-Wesley; Fogel, D.B., (1995) Evolutionary Computation, , IEEE; Schwefel, H.-P., (1995) Evolution and Optimum Seeking, , Wiley; Bäck, T., (1996) Evolutionary Algorithms in Theory and Practice, , Oxford Univ. Press; Banzhaf, W., Nordin, P., Keller, R.E., Francone, F.D., (1998) Genetic Programming: An Introduction, , Morgan Kaufmann; Storn, R., Price, K., Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces (1997) J. Glob. Optim., 11, pp. 341-359; Price, K.V., Storn, R.N., Lampinen, J.A., (2005) Differential Evolution: A Practical Approach to Global Optimization, , Springer; Kennedy, J., Eberhart, R.C., Particle swarm optimization (1995) Proc. IEEE International Conference on Neural Networks, pp. 1942-1948. , IEEE; Kennedy, J., Eberhart, R.C., (2001) Swarm Intelligence, , Morgan Kaufmann; De Jong, K.A., Are genetic algorithms function optimizers (1992) Proc. 2nd Conference on Parallel Problem Solving from Nature, pp. 3-13. , eds Manner, R. & Manderick, B. North-Holland; Hornby, G.S., Lohn, J.D., Linden, D.S., Computer-automated evolution of an X-band antenna for NASA's space technology 5 mission (2011) Evol. Comput., 19, pp. 1-23; Arias-Montano, A., Coello, C.A.C., Mezura-Montes, E., Multiobjective evolutionary algorithms in aeronautical and aerospace engineering (2012) IEEE Trans. Evol. Comput., 16, pp. 662-694; Besnard, J., Automated design of ligands to polypharmacological profiles (2012) Nature, 492, pp. 215-220; Posìk Huyer, P.W., Pal, L., A comparison of global search algorithms for continuous black box optimization (2012) Evol. Comput., 20, pp. 509-541; Hansen, N., Ostermeier, A., Completely derandomized self-adaptation in evolution strategies (2001) Evol. Comput., 9, pp. 159-195; Bäck, T., Foussette, C., Krause, P., (2013) Contemporary Evolution Strategies, , Springer; Yao, X., Evolving artificial neural networks (1999) Proc. IEEE, 87, pp. 1423-1447; Floreano, D., Dürr, P., Mattiussi, C., Neuroevolution: From architectures to learning (2008) Evol. Intel., 1, pp. 47-62; Barros, R.C., Basgalupp, M.P., De Carvalho, A.C.P.L.F., Freitas, A.A., A survey of evolutionary algorithms for decision-tree induction (2012) IEEE Trans. Syst. Man Cybern. C, 42, pp. 291-312; Widera, P., Garibaldi, J.M., Krasnogor, N., GP challenge: Evolving energy function for protein structure prediction (2010) Genet. Program. Evolvable Mach., 11, pp. 61-88; Filipi, B., Urbani, T., Kri_man, V., A combined machine learning and genetic algorithm approach to controller design (1999) Eng. Appl. Artif. Intell., 12, pp. 401-409; Watson, R.A., Ficici, S.G., Pollack, J.B., Embodied evolution: Distributing an evolutionary algorithm in a population of robots (2002) Robot. Auton. Syst., 39, pp. 1-18; Bredeche, N., Montanier, J.M., Liu, W., Winfield, A.F.T., Environment-driven distributed evolutionary adaptation in a population of autonomous robotic agents (2012) Math. Comput. Model. Dyn. Syst., 18, pp. 101-129; Nolfi, S., Floreano, D., (2000) Evolutionary Robotics: The Biology, Intelligence, and Technology of Self-Organizing Machines, , MIT Press; Bongard, J., Evolutionary robotics (2013) Commun. ACM, 56, pp. 74-85; Floreano, D., Keller, L., Evolution of adaptive behavior in robots by means of darwinian selection (2010) PLoS Biol., 8, p. e1000292; Hinton, G.E., Nowlan, S.J., How learning can guide evolution (1987) Complex Syst., 1, pp. 495-502; Borenstein, E., Meilijson, I., Ruppin, E., The effect of phenotypic plasticity on evolution in multipeaked fitness landscapes (2006) J. Evol. Biol., 19, pp. 1555-1570; Paenke, I., Jin, Y., Branke, J., Balancing population and individual level of adaptation in changing environments (2009) Adapt. Behav., 17, pp. 153-174; Chen, X.S., Ong, Y.S., Lim, M.H., Tan, K.C.A., Multi-facet survey on memetic computation (2011) IEEE Trans. Evol. Comput., 15, pp. 591-607; Krasnogor, N., Smith, J.E., A tutorial for competent memetic algorithms: Model, taxonomy and design issues (2005) IEEE Trans. Evol. Comput., 9, pp. 474-488; Smith, J.E., Clark, A.R., Staggemeier, A.T., Serpell, M.C., A genetic approach to statistical disclosure control (2012) IEEE Trans. Evol. Comput., 16, pp. 431-441; Bentley, P., Corne, D., (2002) Creative Evolutionary Systems, , Morgan Kaufmann; Romero, J.J., Machado, P., (2008) The Art of Artificial Evolution: A Handbook on Evolutionary Art and Music, , Springer; Secretan, J., Picbreeder: A case study in collaborative evolutionary exploration of design space (2011) Evol. Comput., 19, pp. 373-403; Bentley, P., (1999) Evolutionary Design by Computers, , Morgan Kaufmann; Hingston, P.F., Barone, L.C., Michalewicz, Z., (2008) Advances in Evolutionary Design, , Springer; Koza, J.R., Human-competitive results produced by genetic programming (2010) Genet. Program. Evolvable Mach., 11, pp. 251-284; Eiben, A.E., Rudolph, G., Theory of evolutionary algorithms: A bird's eye view (1999) Theor. Comput. Sci., 229, pp. 3-9; Wolpert, D.H., Macready, W.G., No free lunch theorems for optimisation (1997) IEEE Trans. Evol. Comput., 1, pp. 67-82; Rudolph, G., Convergence analysis of canonical genetic algorithms (1994) IEEE Trans. Neural Netw., 5, pp. 96-101; Lehre, P.R., Yao, X., On the impact of mutation-selection balance on the runtime of evolutionary algorithms (2012) IEEE Trans. Evol. Comput., 16, pp. 225-241; Jansen, T., (2005) Analyzing Evolutionary Algorithms: The Computer Science Perspective, , Springer; Borenstein, Y., Moraglio, A., (2014) Theory and Principled Methods for Designing Metaheuristics, , Springer; Eiben, A.E., Hinterding, R., Michalewicz, Z., Parameter control in evolutionary algorithms (1999) IEEE Trans. Evol. Comput., 3, pp. 124-141; Bartz-Beielstein, T.T., (2006) Experimental Research in Evolutionary Computation: The New Experimentalism, , Springer; Hutter, F., Hoos, H.H., Leyton-Brown, K., Stützle, T., ParamILS: An automatic algorithm configuration framework (2009) J. Artif. Intell. Res., 36, pp. 267-306; Eiben, A.E., Smit, S.K., Parameter tuning for configuring and analyzing evolutionary algorithms (2011) Swarm Evol. Comput., 1, pp. 19-31; Bartz-Beielstein, T., Preuss, M., (2014) Theory and Principled Methods for Designing Metaheuristics, pp. 205-245. , eds Borenstein, Y. & Moraglio, A. Springer; Lobo, F.J., Lima, C.F., Michalewicz, Z., (2007) Parameter Setting in Evolutionary Algorithms, , Springer; Serpell, M., Smith, J.E., Self-adaption of mutation operator and probability for permutation representations in genetic algorithms (2010) Evol. Comput., 18, pp. 491-514; Fialho, A., Da Costa, L., Schoenauer, M., Sebag, M., Analyzing bandit-based adaptive operator selection mechanisms (2010) Ann. Math. Artif. Intell., 60, pp. 25-64; Karafotias, G., Hoogendoorn, M., Eiben, A.E., Parameter control in evolutionary algorithms: Trends and challenges (2015) IEEE Trans. Evol. Comput., 19, pp. 167-187; Jin, Y.A., Comprehensive survey of fitness approximation in evolutionary computation (2005) Soft Comput., 9, pp. 3-12; Jin, Y., Surrogate-assisted evolutionary computation: Recent advances and future challenges (2011) Swarm Evol. Comput., 1, pp. 61-70; Loshchilov, I., Schoenauer, M., Sebag, M., Self-adaptive surrogate-assisted covariance matrix adaptation evolution strategy (2012) Proc. Conference on Genetic and Evolutionary Computation, pp. 321-328. , eds Soule, T. & Moore, J. H. ACM; Zaefferer, M., Efficient global optimization for combinatorial problems (2014) Proc. Conference on Genetic and Evolutionary Computation, pp. 871-878. , eds Igel, C. & Arnold, D. V. ACM; Deb, K., (2001) Multi-objective Optimization Using Evolutionary Algorithms, , Wiley; Zhang, Q., Li, H., MOEA/D: A multi-objective evolutionary algorithm based on decomposition (2007) IEEE Trans. Evol. Comput., 11, pp. 712-731; Deb, K., Jain, H., An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: Solving problems with box constraints (2014) IEEE Trans. Evol. Comput., 18, pp. 577-601; Jain, H., Deb, K., An evolutionary many-objective optimization algorithm using reference-point based non-dominated sorting approach, part II: Handling constraints and extending to an adaptive approach (2014) IEEE Trans. Evol. Comput., 18, pp. 602-622; Branke, J., Greco, S., Slowinski, R., Zielniewicz, P., Learning value functions in interactive evolutionary multiobjective optimization (2015) IEEE Trans. Evol. Comput., 19, pp. 88-102; Stanley, K.O., Compositional pattern producing networks: A novel abstraction of development (2007) Genet. Program. Evolvable Mach., 8, pp. 131-162; O'Reilly, U.-M., Hemberg, H., Integrating generative growth and evolutionary computation for form exploration (2007) Genet. Program. Evolvable Mach., 8, pp. 163-186; Clune, J., Stanley, K.O., Pennock, R., Ofria, C., On the performance of indirect encoding across the continuum of regularity (2011) IEEE Trans. Evol. Comput., 15, pp. 346-367; Jin, Y., Meng, Y., Morphogenetic robotics: An emerging new field in developmental robotics (2011) IEEE Trans. Syst. Man Cybern. C, 41, pp. 145-160; Doursat, R., Sayama, H., Michel, O., (2013) Orphogenetic Engineering: Toward Programmable Complex Systems, , Springer; Doncieux, S., Bredeche, N., Mouret, J.-B., (2011) New Horizons in Evolutionary Robotics, , Springer; Vargas, P.A., Di Paolo, E.A., Harvey, I., Husbands, P., (2014) The Horizons of Evolutionary Robotics, , MIT Press; Harman, M., McMinn, P., A theoretical and empirical study of search-based testing: Local, global, and hybrid search (2010) IEEE Trans. Softw. Eng., 36, pp. 226-247; Preen, R., Bull, L., Towards the coevolution of novel vertical-axis wind turbines (2015) IEEE Trans. Evol. Comput., 19, pp. 284-294; Banzhaf, W., From artificial evolution to computational evolution: A research agenda (2006) Nature Rev. Genet., 7, pp. 729-735; Maynard Smith, J., Byte-sized evolution (1992) Nature, 355, pp. 772-773; Waibel, M., Floreano, D., Keller, L., A quantitative test of Hamilton's rule for the evolution of altruism (2011) PLoS Biol., 9, p. e1000615; Long, J., Darwin's devices: What evolving robots can teach us about the history of life and the future of technology (2012) Basic Books; Virgo, N., Fernando, C., Bigge, B., Husbands, P., Evolvable physical self-replicators (2012) Artif. Life, 18, pp. 129-142; Bongard, J., Lipson, H., Evolved machines shed light on robustness and resilience (2014) Proc. IEEE, 102, pp. 899-914; Bongard, J., Morphological change in machines accelerates the evolution of robust behavior (2011) Proc. Natl Acad. Sci. USA, 108, pp. 1234-1239; Eiben, A.E., Grand challenges for evolutionary robotics (2014) Front. Robot. AI, p. 1. , http://dx.doi.org/10.3389/frobt.2014.00004; Fernando, C., Kampis, G., Szathmáry, E., Evolvability of natural and artificial systems (2011) Procedia Comput. Sci., 7, pp. 73-76",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Hirschberg J., Manning C.D.",7005619286;35280197500;,Advances in natural language processing,2015,Science,10.1126/science.aaa8685,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937806794&doi=10.1126%2fscience.aaa8685&partnerID=40&md5=fa9fad53db9bf2a3108cba2e55687864,"Natural language processing employs computational techniques for the purpose of learning, understanding, and producing human language content. Early computational approaches to language research focused on automating the analysis of the linguistic structure of language and developing basic technologies such asmachine translation, speech recognition, and speech synthesis.Today's researchers refine and make use of such tools in real-world applications, creating spoken dialogue systems and speech-to-speech translation engines, mining social media for information about health or finance, and identifying sentiment and emotion toward products and services.We describe successes and challenges in this rapidly advancing area.",,automation; computer simulation; finance; language; learning; research work; technological change; technological development; computer interface; human; linguistics; machine learning; natural language processing; oral communication; priority journal; reading; Review; social media; speech; translating (language); data mining; procedures; translating (language); Data Mining; Humans; Natural Language Processing; Social Media; Translating,"Manning, C.D., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S.J., McClosky, D., The stanford corenlp natural language processing toolkit (2014) Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, System Demonstrations, pp. 55-60. , (Association for Computational Linguistics Stroudsburg, PA; Linguistic Data Consortium, , www.ldc.upenn.edu; CoNLL Shared Tasks, , http://ifarm.nl/signll/conll; Kaggle, , www.kaggle.com; Brown, P.F., Della Pietra, S.A., Della Pietra, V.J., Mercer, R.L., (1993) Comput. Linguist., 19, pp. 263-311; Koehn, P., Och, F.J., Marcu, D., Statistical phrase-based translation (2003) Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pp. 48-54. , (Association for Computational Linguistics, Stroudsburg, PA; Chiang, D., A hierarchical phrase-based model for statistical machine translation (2005) Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pp. 263-270. , (Association for Computational Linguistics, Stroudsburg, PA; Galley, M., Hopkins, M., Knight, K., Marcu, D., What's in a translation rule? (2004) Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL 2004), , (Association for Computational Linguistics, Stroudsburg, PA; Jones, B., Andreas, J., Bauer, D., Hermann, K.M., Knight, K., Semantics-based machine translation with hyperedge replacement grammars (2012) Proceedings of COLING 2012 (Technical Papers, pp. 1359-1376. , The COLING 2012 Organizing Committee, Mumbai, India; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, 27, pp. 3104-3112. , (NIPS 2014), Z. Ghahramani M. Welling, C. Cortes, N. D. Lawrence, K. Q. Weinberger, Eds. (Curran Associates, Red Hook, NY; Bahdanau, D., Cho, K., Bengio, Y., (2015) Neural Machine Translation by Jointly Learning to Align and Translate, , http://arxiv.org/abs/1409.0473; Luong, M.-T., Sutskever, I., Le, Q.V., Vinyals, O., Zaremba, W., (2015) Addressing the Rare Word Problem in Neural Machine Translation, , http://arxiv.org/abs/1410.8206; Jean, S., Cho, K., Memisevic, R., Bengio, Y., (2015) On Using Very Large Target Vocabulary for Neural Machine Translation, , http://arxiv.org/abs/1412.2007; Stymne, S., Hardmeier, C., Tiedemann, J., Nivre, J., Feature weight optimization for discourse-level SMT (2013) Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pp. 60-69. , (Association for Computational Linguistics, Stroudsburg, PA; Green, S., Chuang, J., Heer, J., Manning, C.D., Predictive translation memory: A mixed-initiative system for human language translation (2014) Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology, pp. 177-187. , Honolulu, HI, 5 to 8 October 2014 (Association for Computing Machinery, New York; Rosenthal, S., Biswas, J., Veloso, M., An effective personal mobile robot agent through symbiotic human-robot interaction (2010) Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2010), pp. 915-922. , Toronto, Canada, 10 to 14 May 2010 (International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC; Fasola, J., Matari, M.J., (2013) J. Human-Robot Interact., 2, pp. 3-32; Core, M., Lane, H.C., Traum, D., Intelligent tutoring support for learners interacting with virtual humans (2014) Design Recommendations for Intelligent Tutoring Systems, 2, pp. 249-257. , (U.S. Army Research Laboratory Orlando, FL; Devault, D., Artstein, R., Benn, G., Dey, T., Fast, E., Gainer, A., Georgila, K., Morency, L.-P., SimSensei Kiosk: A virtual human interviewer for healthcare decision support (2014) Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014), pp. 1061-1068. , http://aamas2014.lip6.fr/proceedings/aamas/p1061.pdf, Paris, France, 5 to 9 May 2014 (International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC; Hinton, G., (2012) IEEE Signal Process Mag., 29, pp. 82-97; Weizenbaum, J., (1966) Commun. ACM, 9, pp. 36-45; Nonaka, Y., Sakai, Y., Yasuda, K., Nakano, Y., Towards assessing the communication responsiveness of people with dementia (2012) 12th International Conference on Intelligent Virtual Agents, pp. 496-498. , IVA'12 Springer, Berlin; Nass, C., Moon, Y., Fogg, B.J., Reeves, B., Dryer, D.C., (1995) Int. J. Hum. Comput. Stud., 43, pp. 223-239; Giles, H., Mulac, A., Bradac, J.J., Johnson, P., Speech accommodation theory: The next decade and beyond (1987) Communication Yearbook, 10, pp. 13-48. , Sage, Newbury Park, CA; Young, S., Gasic, M., Thomson, B., Williams, J., (2013) Proc. IEEE, 101, pp. 1160-1179; Wikipedia, , www.wikipedia.org; Hunter, L., Cohen, K.B., (2006) Mol. Cell, 21, pp. 589-594; Culotta, A., Sorensen, J., Dependency tree kernels for relation extraction (2004) Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (Association for Computational Linguistics, pp. 423-429. , Stroudsburg, PA; Fundel, K., Küffner, R., Zimmer, R., (2007) Bioinformatics, 23, pp. 365-371; Björne, J., (2011) Comput Intell., 27, pp. 541-557; Van Landeghem, S., (2013) PLOS ONE, 8, p. e55814; Ashburner, M., The gene ontology consortium (2000) Nat. Genet., 25, pp. 25-29; PaleoBiology Database, , https://paleobiodb.org; Coulet, A., Cohen, K.B., Altman, R.B., (2012) J. Biomed. Inform., 45, pp. 825-826; Percha, B., Garten, Y., Altman, R.B., (2012) Pac. Symp. Biocomput., 2012, pp. 410-421; Freebase, , www.freebase.com; Dbpedia, , http://dbpedia.org; Wikidata, , www.wikidata.org; Mintz, M., Bills, S., Snow, R., Jurafsky, D., Distant supervision for relation extraction without labeled data (2009) Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (Association for Computational Linguistics, 2, pp. 1003-1011. , Stroudsburg, PA; Surdeanu, M., Tibshirani, J., Nallapati, R., Manning, C.D., Multi-instance multi-label learning for relation extraction (2012) Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL), pp. 455-465. , Jeju Island, South Korea, 12 to 14 July 2012 (Association for Computational Linguistics, Stroudsburg, PA; Min, B., Grishman, R., Wan, L., Wang, C., Gondek, D., Distant supervision for relation extraction with an incomplete knowledge base (2013) Proceedings of NAACL-HLT 2013, pp. 777-782. , Atlanta, GA, 9 to 14 June 2013 (Association for Computational Linguistics, Stroudsburg, PA; DeepDive, , http://deepdive.stanford.edu; Peters, S.E., Zhang, C., Livny, M., Ré, C., (2014) PLOS ONE, 9, p. e113523; Etzioni, E., Banko, M., Cafarella, M.J., Machine reading (2006) Proceedings of the 21st National Conference on Artificial Intelligence (AAAI 2006), 2, pp. 1517-1519. , Boston, MA, 16 to 20 July 2006 (AAAI Press, Menlo Park, CA; Banko, M., Cafarella, M.J., Soderland, S., Broadhead, M., Etzioni, O., Open information extraction from the web (2007) Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI 2007), pp. 2670-2676. , (Morgan Kaufmann, San Francisco; Etzioni, O., Fader, A., Christensen, J., Soderland Mausam, S., Open information extraction: The second generation (2011) Proceedings of the 22nd International Joint Conference on Artificial Intelligence, pp. 3-10. , Barcelona, Spain, 16 to 22 July 2011 (AAAI Press, Menlo Park, CA; Riedel, S., Yao, L., McCallum, A., Marlin, B.M., Relation extraction with matrix factorization and universal schemas (2013) Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics (HLT NAACL 2013), pp. 74-84. , (Stroudsburg, PA; Angeli, G., Manning, C.D., NaturalLI: Natural logic inference for common sense reasoning (2014) Proceedings of the 2014 Conference on Emprical Methods in Natural Language Processing, pp. 534-545. , Doha, Qatar, 25 to 29 October 2014 (Association for Computational Linguistics, Stroudsburg, PA; Berant, J., Srikumar, V., Chen, P.-C., Vander Linden, A., Harding, B., Huang, B., Clark, P., Manning, C.D., Modeling biological processes for reading comprehension (2014) Proceedings of the 2014 Conference on Emprical Methods in Natural Language Processing, pp. 1499-1510. , Doha, Qatar, 25 to 29 October 2014 (Association for Computational Linguistics, Stroudsburg, PA; Fader, A., Zettlemoyer, L., Etzioni, O., Open question answering over curated and extracted knowledge bases (2014) Proceedings of the Conference on Knowledge Discovery and Data Mining (KDD), pp. 1156-1165. , (Association for Computing Machinery, New York; Russell, M.A., (2013) Mining the Social Web: Data Mining Facebook Twitter LinkedIn Google+ GitHub and More, 2. , O'Reilly Media Sebastopol, CA, ed; Elhadad, N., Gravano, L., Hsu, D., Balter, S., Reddy, V., Waechter, H., Information extraction from social media for public health (2014) KDD at Bloomberg Workshop, Data Frameworks Track, , (KDD 2014) (Association for Computing Machinery, New York; Ott, M., Cardie, C., Hancock, J.T., Estimating the prevalence of deception in online review communities (2012) Proceedings of the 21st International Conference on World Wide Web Conference, pp. 201-210. , Lyon, France, 16 to 20 April 2012 (Association for Computing Machinery, New York; Liscombe, J., (2007) Thesis, , Columbia University; Wiebe, J., Wilson, T., Cardie, C., (2005) Lang. Resour. Eval., 39, pp. 165-210; Whissell, C., The dictionary of affect in language (1989) Emotion: Theory, Research and Experience, , R. Plutchik, H. Kellerman, Eds. Academic Press, London; Tausczik, Y.R., Pennebaker, J.W., (2010) J. Lang. Soc. Psychol., 29, pp. 24-54; Türk, O., Schröder, M., (2010) IEEE Trans. Audio Speech Lang. Proc., 18, pp. 965-973; Pang, B., Lee, L., Vaithyanathan, S., Thumbs up? Sentiment classification using machine learning techniques (2002) Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, 10, pp. 79-86. , Philadelphia, PA, July 2002 (Association for Computational Linguistics, Stroudsburg, PA; Wang, H., Ester, M., A sentiment-aligned topic model for product aspect rating prediction (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1192-1202. , Doha, Qatar, 25 to 29 October 2014 (Association for Computational Linguistics, Stroudsburg, PA; Thomas, M., Pang, B., Lee, L., Get out the vote: Determining support or opposition from Congressional floor-debate transcripts (2006) Proceedings of the 2006 Conference on Emprical Methods in Natural Language Processing, pp. 327-335. , Sydney, Australia, 22 to 23 July 2006 (Association for Computational Linguistics, Stroudsburg, PA; Bollen, J., Mao, H., Pepe, A., Modeling public mood and emotion: Twitter sentiment and socio-economic phenomena (2011) Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media, pp. 450-453. , Barcelona, Spain, 17 to 21 July 2011 (AAAI Press, Menlo Park; Gonzalez-Ibanez, R., Muresan, S., Wacholder, N., Identifying sarcasm in Twitter: A closer look (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pp. 581-586. , Portland, Oregon, 19 to 24 June 2011 (Association for Computational Linguistics, Stroudsburg, PA; Biran, O., Rosenthal, S., Andreas, J., McKeown, K., Rambow, O., Detecting influencers in written online conversations Proceedings of the 2012 Workshop on Language in Social Media, Montreal, pp. 37-45. , Canada, 7 June 2012 (Association for Computational Linguistics, Stroudsburg, PA, 2012; Yu, L.-C., Ho, C.-Y., Identifying emotion labels from psychiatric social texts using independent component analysis (2014) Proceedings of COLING 2014 (Technical Papers, Association for Computational Linguistics, pp. 837-847. , Stroudsburg, PA; Hayes, B., Londe, Z., (2006) Phonology, 23, pp. 59-104; Levy, R., (2008) Cognition, 106, pp. 1126-1177; Goodman, N.D., Lassiter, D., Probabilistic semantics and pragmatics: Uncertainty in language and thought (2015) Handbook of Contemporary Semantics, 2. , C. Fox, S. Lappin, Eds. Blackwell, Hoboken,NJ, ed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gershman S.J., Horvitz E.J., Tenenbaum J.B.",35108983800;6701318945;7006818404;,"Computational rationality: A converging paradigm for intelligence in brains, minds, and machines",2015,Science,10.1126/science.aac6076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937783963&doi=10.1126%2fscience.aac6076&partnerID=40&md5=6d50fa20c1a26e74a67dfca1c683603b,"After growing up together, and mostly growing apart in the second half of the 20th century, the fields of artificial intelligence (AI), cognitive science, and neuroscience are reconverging on a shared view of the computational foundations of intelligence that promotes valuable cross-disciplinary exchanges on questions, methods, and results. We chart advances over the past several decades that address challenges of perception and action under uncertainty through the lens of computation. Advances include the development of representations and inferential procedures for large-scale probabilistic inference and machinery for enabling reflection and decisions about tradeoffs in effort, precision, and timeliness of computations. These tools are deployed toward the goal of computational rationality: identifying decisions with highest expected utility, while taking into consideration the costs of computation in complex real-world problems in which most relevant calculations can only be approximated.We highlight key concepts with examples that show the potential for interchange between computer science, cognitive science, and neuroscience.",,artificial intelligence; brain; cognition; computer simulation; decision analysis; machinery; mathematical analysis; neurology; paradigm shift; perception; trade-off; accuracy; artificial intelligence; Bayes theorem; brain; brain function; cognition; computational fluid dynamics; computer; decision making; executive function; history; human; intelligence; machine; neuroscience; perception; priority journal; probability; psychologist; psychology; Review; thinking; uncertainty; brain; intelligence; physiology; trends; Artificial Intelligence; Brain; Humans; Intelligence; Neurosciences; Thinking; Uncertainty,"Koller, D., Friedman, N., (2009) Probabilistic Graphical Models: Principles and Techniques, , MIT Press Cambridge MA; Pearl, J., (1988) Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, , Morgan Kaufmann Publishers Los Altos CA; Russell, S., Norvig, P., (2009) Artificial Intelligence: A Modern Approach, , Pearson Upper Saddle River NJ; Von Neumann, J., Morgenstern, O., (1947) Theory of Games and Economic Behavior, , (Princeton Univ. Press, Princeton, NJ; Tenenbaum, J.B., Kemp, C., Griffiths, T.L., Goodman, N.D., (2011) Science, 331, pp. 1279-1285; Turing, A.M., (1936) Proc. Lond. Math. Soc., 2, pp. 230-265; Turing, A.M., (1950) Mind, 59, pp. 433-460; Von Neumann, J., (1958) The Computer and the Brain, , (Yale Univ. Press, New Haven, CT; Simon, H.A., (1957) Models of Man, , Wiley New York; Good, I.J., (1952) J. R. Stat. Soc. B, 14, pp. 107-114; Horvitz, E., (1987) Proceedings of the 3rd International Conference on Uncertainty in Artificial Intelligence, pp. 429-444. , (Mountain View, CA, July 1987; Russell, S., Wefald, E., (1991) Artif. Intell., 49, pp. 361-395; Horvitz, E., Cooper, G., Heckerman, D., (1989) Proceedings of IJCAI, pp. 1121-1127. , January 1989; Horvitz, E., Rutledge, G., (1991) Proceedings of the 7th International Conference on Uncertainty in Artificial Intelligence, pp. 151-158. , Morgan Kaufmann Publishers San Francisco; Horvitz, E., Ruan, Y., Gomes, G., Kautz, H., Selman, B., Chickering, D.M., (2001) Proceedings of 17th Conference on Uncertainty in Artificial Intelligence, pp. 235-244. , Morgan Kaufmann Publishers San Francisco; Horvitz, E., (2001) Artif. Intell., 126, pp. 159-196; Burns, E., Ruml, W., Do, M.B., (2013) J. Artif. Intell. Res., 47, pp. 697-740; Lin, C.H., Kolobov, A., Kamar, A., Horvitz, E., Metareasoning for planning under uncertainty (2015) Proceedings of IJCAI; Dean, T., Kaelbling, L.P., Kirman, J., Nicholson, A., (1995) Artif. Intell., 76, pp. 35-74; Hay, N., Russell, S., Tolpin, D., Shimony, S., (2012) Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence, pp. 346-355; Heckerman, D., Breese, J.S., Horvitz, E., (1989) Proceedings of the 5th Conference on Uncertainty in Artifical Intelligence, pp. 162-173. , July 1989; Cooper, G., (1990) Artif. Intell., 42, pp. 393-405; Peterson, C.R., Beach, L.R., (1967) Psychol. Bull., 68, pp. 29-46; Tversky, A., Kahneman, D., (1974) Science, 185, pp. 1124-1131; Gigerenzer, G., (2008) Rationality for Mortals: How People Cope with Uncertainty, , (Oxford Univ. Press, Oxford; Anderson, J.R., (1990) The Adaptive Character of Thought, , Lawrence Erlbaum Hillsdale NJ; Oaksford, M., Chater, N., (2007) Bayesian Rationality, , Oxford Univ. Press, Oxford; Griffiths, T.L., Tenenbaum, J.B., (2005) Cognit. Psychol., 51, pp. 334-384; Doya, K., Ishii, S., Pouget, A., Rao, R.P.N., (2007) The Bayesian Brain: Probabilistic Approaches to Neural Coding, , Eds MIT Press, Cambridge, MA; Griffiths, T.L., Lieder, F., Goodman, N.D., (2015) Top. Cogn. Sci., 7, pp. 217-229; Denison, S., Bonawitz, E., Gopnik, A., Griffiths, T.L., (2013) Cognition, 126, pp. 285-300; Vul, E., Frank, M., Alvarez, G., Tenenbaum, J.B., (2009) Adv. Neural Inf. Process. Syst., 29, pp. 1955-1963; Gershman, S.J., Vul, E., Tenenbaum, J.B., (2012) Neural Comput., 24, pp. 1-24; Sanborn, A.N., Griffiths, T.L., Navarro, D.J., (2010) Psychol. Rev., 117, pp. 1144-1167; Buesing, L., Bill, J., Nessler, B., Maass, W., (2011) PLOS Comput Biol., 7, p. e1002211; Isard, M., Blake, A., (1998) Int. J. Comput. Vis., 29, pp. 5-28; Levy, R., Reali, F., Griffiths, T.L., (2009) Adv. Neural Inf. Process. Syst., 21, pp. 937-944; Vul, E., Goodman, N., Griffiths, T.L., Tenenbaum, J.B., (2014) Cogn. Sci., 38, pp. 599-637; Kool, W., McGuire, J.T., Rosen, Z.B., Botvinick, M.M., (2010) J. Exp. Psychol. Gen., 139, pp. 665-682; Kool, W., Botvinick, M., (2014) J. Exp. Psychol. Gen., 143, pp. 131-141; McGuire, J.T., Botvinick, M.M., (2010) Proc. Natl. Acad. Sci. U.S.A., 107, pp. 7922-7926; Lieder, F., (2014) Adv. Neural Inf. Process. Syst., 27, pp. 2870-2878; Lewis, R.L., Howes, A., Singh, S., (2014) Top. Cogn. Sci., 6, pp. 279-311; Payne, J.W., Bettman, J.R., Johnson, E.J., (1988) J. Exp. Psychol. Learn. Mem. Cogn., 14, pp. 534-552; Rieskamp, J., Otto, P.E., (2006) J. Exp. Psychol. Gen., 135, pp. 207-236; Lieder, F., Hsu, M., Griffiths, T.L., (2014) Proc. 36th Ann. Conf. Cognitive Science Society, , (Austin, TX; Daw, N.D., Niv, Y., Dayan, P., (2005) Nat. Neurosci., 8, pp. 1704-1711; Killcross, S., Coutureau, E., (2003) Cereb Cortex, 13, pp. 400-408; Yin, H.H., Knowlton, B.J., Balleine, B.W., (2004) Eur. J. Neurosci., 19, pp. 181-189; Daw, N.D., Gershman, S.J., Seymour, B., Dayan, P., Dolan, R.J., (2011) Neuron, 69, pp. 1204-1215; Keramati, M., Dezfouli, A., Piray, P., (2011) PLOS Comput Biol., 7, p. e1002055; Dickinson, A., (1985) Philos. Trans. R. Soc. London B Biol. Sci., 308, pp. 67-78; Otto, A.R., Gershman, S.J., Markman, A.B., Daw, N.D., (2013) Psychol. Sci., 24, pp. 751-761; Lee, S.W., Shimojo, S., O'Doherty, J.P., (2014) Neuron, 81, pp. 687-699; Gelly, S., (2012) Commun. ACM, 55, pp. 106-113; Johnson, A., Redish, A.D., (2007) J. Neurosci., 27, pp. 12176-12189; Pfeiffer, B.E., Foster, D.J., (2013) Nature, 497, pp. 74-79; Mnih, V., (2015) Nature, 518, pp. 529-533; http://arxiv.org/abs/1412.6564, C. J. Maddison, A. Huang, I. Sutskever, D. Silver; Guo, X., Singh, S., Lee, H., Lewis, R., Wang, X., (2014) Adv. Neural Inf. Process. Syst., 27, pp. 3338-3346; Chaslot, G.M.J.-B., Bakkes, S., Szita, I., Spronck, P., (2008) Proc. Artif. Intell. Interact. Digit. Entertain. Conf., pp. 216-217. , (Stanford, CA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scheier C., Pfeifer R., Kunyioshi Y.",6701368473;7007140164;6504566373;,Embedded neural networks: Exploiting constraints,1998,Neural Networks,10.1016/S0893-6080(98)00084-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032192328&doi=10.1016%2fS0893-6080%2898%2900084-7&partnerID=40&md5=8bc159d5273d6c0d619bd1c46ec00099,"Using concepts and tools of embodied cognitive science, we investigate the implications of embedding neural networks in a physical structure, the body of a robot. Embedding a neural network in a body provides constraints that can be exploited for learning. We show that the constraints are given by the environment and object properties, the agent's morphology, the agent's motor system and specific ways of interacting with the objects. We argue that designing embedded neural networks implies (a) understanding these constraints, and (b) exploiting them, i.e., designing neural networks such that they - one way or other - incorporate the constraints. This in turn results in cheap and simple networks that are suited for the task environment, and have real-time responses. Moreover, this constraint-based approach provides new perspectives on two fundamental problems of cognitive science: focus-of-attention and object constancy. The main arguments are illustrated with a series of case studies with simulated and physical mobile robots that are controlled by hand-designed as well as evolved neural networks.Using concepts and tools of embodied cognitive science, we investigate the implications of embedding neural networks in a physical structure, the body of a robot. Embedding a neural network in a body provides constraints that can be exploited for learning. We show that the constraints are given by the environment and object properties, the agent's morphology, the agent's motor system and specific ways of interacting with the objects. We argue that designing embedded neural networks implies (a) understanding these constraints, and (b) exploiting them, i.e., designing neural networks such that they - one way or other - incorporate the constraints. This in turn results in cheap and simple networks that are suited for the task environment, and have real-time responses. Moreover, this constraint-based approach provides new perspectives on two fundamental problems of cognitive science: focus-of-attention and object constancy. The main arguments are illustrated with a series of case studies with simulated and physical mobile robots that are controlled by hand-designed as well as evolved neural networks.",Adaptive behavior; Constraints; Embodiment; Learning,Real time systems; Robot learning; Robots; Constraints; Neural networks; adaptive behavior; artificial neural network; environment; learning; movement (physiology); priority journal; review; robotics; visuomotor coordination,"Abu-Mustafa, Y.S., Hints and the VC dimension (1992) Neural Computation, 5, pp. 278-288; Almassy, N., Edelman, G.M., Sporns, O., Behavioral constraints in the development of neuronal properties: A cortical model embedded in a real world device (1998) Cerebral Cortex, 8, pp. 346-361; Arkin, R., (1998) Behavior-based Robotics, , Cambridge, MA: MIT Press; Ashby, W.R., (1956) An Introduction to Cybernetics, , London: Chapman and Hall; Ballard, D., Hayhoe, M., Pook, K., Rao, R., Deictic codes for the embodiment of cognition (1997) Behavioral and Brain Sciences, 23, pp. 233-265; Bensinger, D.G., Hayhoe, M., Ballard, D., Visual memory in a natural task (1995) Investigative Ophthalmology and Visual Science, 36, p. 14; Brooks, R.A., Intelligence without representation (1991) Artificial Intelligence, 47, pp. 139-160; Chappell, G.J., Taylor, J.G., The temporal Kohonen map (1993) Neural Networks, 6, pp. 441-445; Chiel, H.J., Beer, R.D., The brain has a body: Adaptive behavior emerges from interactions of nervous system, body and environment (1997) Trends in Neuroscience, 20, pp. 553-557; Clark, A., Thornton, C., Trading spaces: Computation, representation and the limits of uninformed learning (1997) Behaviourial and Brain Sciences, 20, pp. 57-90; Garcia, M., Chatterjee, A., Ruina, A., Coleman, M., The simplest walking model: stability, complexity, and scaling ASME Journal of Biomechanical Engineering, , (in press). (in press); Glenberg, A.M., What memory is for? (1996) Behavioral and Brain Sciences, 20, pp. 1-55; Hertz, J., Krogh, A., Palmer, R.G., (1991) Introduction to the Theory of Neural Computation, , Redwood City, CA: Addison-Wesley; Horswill, I., Characterizing adaptation by constraint (1992) In Proceedings First European Conference Artificial Life, pp. 58-64. , In F. J. Varela, & P. Bourgine (Eds.), Toward a practice of autonomous systems. Cambridge, MA: MIT-Press; Horswill, I., A simple, cheap, and robust visual navigation system (1993) In Proceedings Second International Conference Simulation of Adaptive Behavior, pp. 129-136. , In J.-A. Meyer, H. L. Roitblat, & S. W. Wilson (Eds.), From animals to animats. Cambridge, MA: MIT Press (A Bradford Book); Maris, M., Te Boekhorst, R., Exploiting physical constraints: heap formation through behavioral error in a group of robots (1996) In Proceedings IROS'96, IEEE/RSJ International Conference on Intelligent Robots and Systems; Meier, D., (1997) Generalization and Constraints in Learning Machines, , Unpublished PhD thesis, Department of Computer Science, University of Zurich; Millar, S., (1994) Understanding and Representing Space, , Oxford: Oxford Science Publications; Montello, D.R., Presson, C.C., Movement and orientation in surrounding and imaginal spaces. (Manuscript cited in Glenberg, A. M. (1997)). What memory is for? (1993) Behavioral and Brain Sciences, 20, pp. 1-55; Nolfi, S., (1996) Adaptation As a More Powerful Tool Than Decomposition and Integration. Technical Report 96-03, , Department of Neural Systems and Artificial Life, Institute of Psychology, C.N.R., Rome, Italy; Pfeifer, R., Scheier, C., Sensory-motor coordination: The metaphor and beyond (1997) Robotics and Autonomous Systems, 20, pp. 157-178. , In R. Pfeifer, & R. Brooks (Eds.), (Special Issue on 'Practice and future of autonomous agents'); Pfeifer, R., Scheier, C., Understanding Intelligence, , (in press-a). Cambridge, MA: MIT Press; Pfeifer, R., Scheier, C., Representation in natural and artificial agents: an embodied cognitive science perspective Zeitschrift fuer Naturforschung [Section C, a Journal of Biosciences], , (in press-b); Pfeifer, R., Verschure, P.F.M.J., Distributed adaptive control: A paradigm for designing autonomous agents (1992) In Proceedings First European Conference on Artificial Life, pp. 21-30. , In F. J. Varela, & P. Bourgine (Eds.), Toward a practice of autonomous systems Cambridge, MA: MIT Press; Ruff, H.A., Infants' manipulative exploration of objects: Effects of age and object characteristics (1984) Development Psychology, 20, pp. 9-20; Salinas, E., Romo, R., Conversion of sensory signals into motor commands in primary cortex (1998) J. Neuroscience, 18 (10), pp. 499-511; Salomon, R., Neural networks in the context of autonomous agents: important concepts revisited (1996) Proceedings of the Artificial Neural Networks in Engineering (ANNIE'96), pp. 109-116. , In C. H. Dagli, M. Akay, C. L. P. Chen, B. R. Fernández, & J. Ghosh (Eds.), New York: ASME Press; Scheier, C., Pfeifer, R., Classification as sensory-motor coordination (1995) In Proceedings European Conference on Artificial Life, ECAL-95, pp. 656-667; Simons, D.J., Levin, D.T., Change blindness (1997) Trends in Cognitive Sciences, 1, pp. 261-267; Thelen, E., Smith, L., (1994) A Dynamic Systems Approach to the Development of Cognition and Action, , Cambridge, MA: MIT Press (Bradford Books); Thornton, C., Separability is a learner's best friend (1997) Proceedings Fourth Neural Computation and Psychology Workshop: Connectionist Representations, pp. 40-47. , In J. A. Bullinaria, D. W. Glasspool, & G. Houghton (Eds.), London: Springer; Thorpe, S.J., Imbert, M., Biological constraints on connectionist models (1989) Connectionism in Perspective, pp. 109-116. , In R. Pfeifer, Z. Schreter, & F. Fogelman-Soulie (Eds.), London: Wiley; Vapnik, V.N., Chervonenkis, A., On the uniform convergence of relative frequencies of events to their probabilities (1989) Theory Prob. Appl., 16, pp. 246-280; Wilson, S.W., The animat path to AI (1991) In Proceedings of the First International Conference on Simulation of Adaptive Behavior, pp. 15-21. , In J.-A. Meyer, & S. W. Wilson (Eds.), From animals to animats. Cambridge, MA: MIT Press (A Bradford Book)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,