Authors,Author(s) ID,Title,Year,Source title,DOI,Link,Abstract,Author Keywords,Index Keywords,References,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Lecun Y., Bengio Y., Hinton G.",55666793600;7003958245;7006699573;,Deep learning,2015,Nature,10.1038/nature14539,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930630277&doi=10.1038%2fnature14539&partnerID=40&md5=e324cb9ec992f892ebc74f3e06078083,"Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech. © 2015 Macmillan Publishers Limited. All rights reserved.",,data processing; data set; machine learning; parameterization; automatic speech recognition; classifier; deep learning; human; image processing; language processing; learning; learning algorithm; learning theory; machine learning; nonhuman; pattern recognition; priority journal; recognition; Review; speech discrimination; algorithm; artificial intelligence; artificial neural network; computer; language; trends; Algorithms; Artificial Intelligence; Computers; Language; Neural Networks (Computer),"Krizhevsky, A., Sutskever, I., Hinton, G., ImageNet classification with deep convolutional neural networks (2012) Proc. Advances in Neural Information Processing Systems, 25, pp. 1090-1098; Farabet, C., Couprie, C., Najman, L., Lecun, Y., Learning hierarchical features for scene labeling (2013) IEEE Trans. Pattern Anal. Mach. Intell., 35, pp. 1915-1929; Tompson, J., Jain, A., Lecun, Y., Bregler, C., Joint training of a convolutional network and a graphical model for human pose estimation (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 1799-1807; Szegedy, C., (2014) Going Deeper with Convolutions. Preprint at, , http://arxiv.org/abs/1409.4842; Mikolov, T., Deoras, A., Povey, D., Burget, L., Cernocky, J., Strategies for training large scale neural network language models (2011) Proc. Automatic Speech Recognition and Understanding, pp. 196-201; Hinton, G., Deep neural networks for acoustic modeling in speech recognition (2012) IEEE Signal Processing Magazine, 29, pp. 82-97; Sainath, T., Mohamed, A.-R., Kingsbury, B., Ramabhadran, B., Deep convolutional neural networks for LVCSR (2013) Proc. Acoustics, Speech and Signal Processing, pp. 8614-8618; Ma, J., Sheridan, R.P., Liaw, A., Dahl, G.E., Svetnik, V., Deep neural nets as a method for quantitative structure-activity relationships (2015) J. Chem. Inf. Model., 55, pp. 263-274; Ciodaro, T., Deva, D., De Seixas, J., Damazio, D., Online particle detection with neural networks based on topological calorimetry information (2012) J. Phys. Conf. Series, 368, p. 012030; (2014) Higgs Boson Machine Learning Challenge, , https://www.kaggle.com/c/higgs-boson, Kaggle; Helmstaedter, M., Connectomic reconstruction of the inner plexiform layer in the mouse retina (2013) Nature, 500, pp. 168-174; Leung, M.K., Xiong, H.Y., Lee, L.J., Frey, B.J., Deep learning of the tissue-regulated splicing code (2014) Bioinformatics, 30, pp. i121-i129; Xiong, H.Y., The human splicing code reveals new insights into the genetic determinants of disease (2015) Science, 347, p. 6218; Collobert, R., Natural language processing (almost) from scratch (2011) J. Mach. Learn. Res., 12, pp. 2493-2537; Bordes, A., Chopra, S., Weston, J., Question answering with subgraph embeddings (2014) Proc. Empirical Methods in Natural Language Processing, , http://arxiv.org/abs/1406.3676v3; Jean, S., Cho, K., Memisevic, R., Bengio, Y., On using very large target vocabulary for neural machine translation (2015) Proc. ACL-IJCNLP Http://arxiv. Org/ abs/1412. 2007; Sutskever Vinyals, I.O., Le., Q.V., Sequence to sequence learning with neural networks (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 3104-3112; Bottou, L., Bousquet, O., The tradeoffs of large scale learning (2007) Proc. Advances in Neural Information Processing Systems, 20, pp. 161-168; Duda, R.O., Hart, P.E., (1973) Pattern Classification and Scene Analysis, , Wiley; Schölkopf, B., Smola, A., (2002) Learning with Kernels, , MIT Press; Bengio, Y., Delalleau, O., Le Roux, N., The curse of highly variable functions for local kernel machines (2005) Proc. Advances in Neural Information Processing Systems, 18, pp. 107-114; Selfridge, O.G., Pandemonium: A paradigm for learning in mechanisation of thought processes (1958) Proc. Symposium on Mechanisation of Thought Processes, pp. 513-526; Rosenblatt, F., (1957) The Perceptron-A Perceiving and Recognizing Automaton, , Tech. Rep. 85-460-1 (Cornell Aeronautical Laboratory; Werbos, P., (1974) Beyond Regression: New Tools for Prediction and Analysis in the Behavioral Sciences, , PhD thesis, Harvard Univ; Parker, D.B., (1985) Learning Logic Report TR-47, , MIT Press; Lecun, Y., (1985) Une Procédure d'Apprentissage Pour Réseau À Seuil Assymétrique in Cognitiva 85: A la Frontière de l'Intelligence Artificielle des Sciences de la Connaissance et des Neurosciences, pp. 599-604. , in French; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323, pp. 533-536; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier neural networks (2011) Proc. 14th International Conference on Artificial Intelligence and Statistics, pp. 315-323; Dauphin, Y., Identifying and attacking the saddle point problem in high-dimensional non-convex optimization (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 2933-2941; Choromanska, A., Henaff, M., Mathieu, M., Arous, G.B., Lecun, Y., The loss surface of multilayer networks (2014) Proc. Conference on AI and Statistics, , http://arxiv.org/abs/1412.0233; Hinton, G.E., What kind of graphical model is the brain (2005) Proc. 19th International Joint Conference on Artificial Intelligence, pp. 1765-1775; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Comp., 18, pp. 1527-1554; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2006) Proc. Advances in Neural Information Processing Systems, 19, pp. 153-160; Ranzato, M., Poultney, C., Chopra, S., Lecun, Y., Efficient learning of sparse representations with an energy-based model (2006) Proc. Advances in Neural Information Processing Systems, 19, pp. 1137-1144; Hinton, G.E., Salakhutdinov, R., Reducing the dimensionality of data with neural networks (2006) Science, 313, pp. 504-507; Sermanet, P., Kavukcuoglu, K., Chintala, S., Lecun, Y., Pedestrian detection with unsupervised multi-stage feature learning (2013) Proc. International Conference on Computer Vision and Pattern Recognition, , http://arxiv.org/abs/1212.0142; Raina, R., Madhavan, A., Ng, A.Y., Large-scale deep unsupervised learning using graphics processors (2009) Proc. 26th Annual International Conference on Machine Learning, pp. 873-880; Mohamed, A.-R., Dahl, G.E., Hinton, G., Acoustic modeling using deep belief networks (2012) IEEE Trans. Audio Speech Lang. Process., 20, pp. 14-22; Dahl, G.E., Yu, D., Deng, L., Acero, A., Context-dependent pre-trained deep neural networks for large vocabulary speech recognition (2012) IEEE Trans. Audio Speech Lang. Process., 20, pp. 33-42; Bengio, Y., Courville, A., Vincent, P., Representation learning: A review and new perspectives (2013) IEEE Trans. Pattern Anal. Machine Intell., 35, pp. 1798-1828; Lecun, Y., Handwritten digit recognition with a back-propagation network (1990) Proc. Advances in Neural Information Processing Systems, pp. 396-404; Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE, 86, pp. 2278-2324; Hubel, D.H., Wiesel, T.N., Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex (1962) J. Physiol., 160, pp. 106-154; Felleman, D.J., Essen, D.C.V., Distributed hierarchical processing in the primate cerebral cortex (1991) Cereb. Cortex, 1, pp. 1-47; Cadieu, C.F., Deep neural networks rival the representation of primate it cortex for core visual object recognition (2014) PLoS Comp. Biol., 10, p. e1003963; Fukushima, K., Miyake, S., Neocognitron: A new algorithm for pattern recognition tolerant of deformations and shifts in position (1982) Pattern Recognition, 15, pp. 455-469; Waibel, A., Hanazawa, T., Hinton, G.E., Shikano, K., Lang, K., Phoneme recognition using time-delay neural networks (1989) IEEE Trans. Acoustics Speech Signal Process., 37, pp. 328-339; Bottou, L., Fogelman-Soulié, F., Blanchet, P., Lienard, J., Experiments with time delay networks and dynamic time warping for speaker independent isolated digit recognition (1989) Proc. EuroSpeech, 89, pp. 537-540; Simard, D., Steinkraus, P.Y., Platt, J.C., Best practices for convolutional neural networks (2003) Proc. Document Analysis and Recognition, pp. 958-963; Vaillant, R., Monrocq, C., Lecun, Y., Original approach for the localisation of objects in images (1994) Proc. Vision, Image, and Signal Processing, 141, pp. 245-250; Nowlan, S., Platt, J., (1995) Neural Information Processing Systems, pp. 901-908; Lawrence, S., Giles, C.L., Tsoi, A.C., Back, A.D., Face recognition: A convolutional neural-network approach (1997) IEEE Trans. Neural Networks, 8, pp. 98-113; Ciresan, D., Meier Masci, U.J., Schmidhuber, J., Multi-column deep neural network for traffic sign classification (2012) Neural Networks, 32, pp. 333-338; Ning, F., Toward automatic phenotyping of developing embryos from videos (2005) IEEE Trans. Image Process., 14, pp. 1360-1371; Turaga, S.C., Convolutional networks can learn to generate affinity graphs for image segmentation (2010) Neural Comput., 22, pp. 511-538; Garcia, C., Delakis, M., Convolutional face finder: A neural architecture for fast and robust face detection (2004) IEEE Trans. Pattern Anal. Machine Intell., 26, pp. 1408-1423; Osadchy, M., Lecun, Y., Miller, M., Synergistic face detection and pose estimation with energy-based models (2007) J. Mach. Learn. Res., 8, pp. 1197-1215; Tompson, J., Goroshin, R.R., Jain, A., Lecun, Y.Y., Bregler, C.C., Efficient object localization using convolutional networks (2014) Proc. Conference on Computer Vision and Pattern Recognition, , http://arxiv.org/abs/1411.4280; Taigman, Y., Yang, M., Ranzato, M., Wolf, L., Deepface: Closing the gap to human-level performance in face verification (2014) Proc. Conference on Computer Vision and Pattern Recognition, pp. 1701-1708; Hadsell, R., Learning long-range vision for autonomous off-road driving (2009) J. Field Robot., 26, pp. 120-144; Farabet, C., Couprie, C., Najman, L., Lecun, Y., Scene parsing with multiscale feature learning, purity trees, and optimal covers (2012) Proc. International Conference on Machine Learning, , http://arxiv.org/abs/1202.2160; Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., Salakhutdinov, R., Dropout: A simple way to prevent neural networks from overfitting (2014) J. Machine Learning Res., 15, pp. 1929-1958; Sermanet, P., Overfeat: Integrated recognition, localization and detection using convolutional networks (2014) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1312.6229; Girshick, R., Donahue, J., Darrell, T., Malik, J., Rich feature hierarchies for accurate object detection and semantic segmentation (2014) Proc. Conference on Computer Vision and Pattern Recognition, pp. 580-587; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1409.1556; Boser, B., Sackinger, E., Bromley, J., Lecun, Y., Jackel, L., An analog neural network processor with programmable topology (1991) J. Solid State Circuits, 26, pp. 2017-2025; Farabet, C., Large-scale FPGA-based convolutional networks (2011) Scaling Up Machine Learning: Parallel and Distributed Approaches, pp. 399-419. , eds Bekkerman, R., Bilenko, M. & Langford, J. Cambridge Univ. Press; Bengio, Y., (2009) Learning Deep Architectures for AI (Now; Montufar, G., Morton, J., When does a mixture of products contain a product of mixtures (2014) J. Discrete Math., 29, pp. 321-347; Montufar, G.F., Pascanu, R., Cho, K., Bengio, Y., On the number of linear regions of deep neural networks (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 2924-2932; Bengio, Y., Ducharme, R., Vincent, P., A neural probabilistic language model (2001) Proc. Advances in Neural Information Processing Systems, 13, pp. 932-938; Cho, K., For statistical machine translation learning phrase representations using rnn encoder-decoder (2014) Proc Conference on Empirical Methods in Natural Language Processing, pp. 1724-1734; Schwenk, H., Continuous space language models (2007) Computer Speech Lang., 21, pp. 492-518; Socher, R., Lin, C.C.-Y., Manning, C., Ng, A.Y., Parsing natural scenes and natural language with recursive neural networks (2011) Proc. International Conference on Machine Learning, pp. 129-136; Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J., Distributed representations of words and phrases and their compositionality (2013) Proc. Advances in Neural Information Processing Systems, 26, pp. 3111-3119; Bahdanau, D., Cho, K., Bengio, Y., Neural machine translation by jointly learning to align and translate (2015) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1409.0473; Hochreiter, S., (1991) Untersuchungen zu Dynamischen Neuronalen Netzen, , German] Diploma thesis, T. U. Münich; Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Trans. Neural Networks, 5, pp. 157-166; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Comput., 9, pp. 1735-1780; Elhihi, S., Bengio, Y., Hierarchical recurrent neural networks for long-term dependencies (1995) Proc. Advances in Neural Information Processing Systems, 8. , http://papers.nips.cc/paper/1102-hierarchical-recurrent-neural-networks-for-long-term-dependencies; Sutskever, I., (2012) Training Recurrent Neural Networks, , PhD thesis, Univ. Toronto; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) Proc. 30th International Conference on Machine Learning, pp. 1310-1318; Sutskever, I., Martens, J., Hinton, G.E., Generating text with recurrent neural networks (2011) Proc. 28th International Conference on Machine Learning, pp. 1017-1024; Lakoff, G., Johnson, M., Metaphors We Live by, 2008. , Univ Chicago Press; Rogers, T.T., McClelland, J.L., (2004) Semantic Cognition: A Parallel Distributed Processing Approach, , MIT Press; Xu, K., Show, attend and tell: Neural image caption generation with visual attention (2015) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1502.03044; Graves, A., Mohamed, A.-R., Hinton, G., Speech recognition with deep recurrent neural networks (2013) Proc. International Conference on Acoustics, Speech and Signal Processing, pp. 6645-6649; Graves, A., Wayne, G., Danihelka, I., (2014) Neural Turing Machines, , http://arxiv.org/abs/1410.5401; Weston Chopra, J.S., Bordes, A., (2014) Memory Networks, , http://arxiv.org/abs/1410.3916; Weston, J., Bordes, A., Chopra, S., Mikolov, T., (2015) Towards AI-complete Question Answering: A Set of Prerequisite Toy Tasks, , http://arxiv.org/abs/1502.05698; Hinton, G.E., Dayan, P., Frey, B.J., Neal, R.M., The wake-sleep algorithm for unsupervised neural networks (1995) Science, 268, pp. 1558-1161; Salakhutdinov, R., Hinton, G., Deep Boltzmann machines (2009) Proc. International Conference on Artificial Intelligence and Statistics, pp. 448-455; Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proc. 25th International Conference on Machine Learning, pp. 1096-1103; Kavukcuoglu, K., Learning convolutional feature hierarchies for visual recognition (2010) Proc. Advances in Neural Information Processing Systems, 23, pp. 1090-1098; Gregor, K., Lecun, Y., Learning fast approximations of sparse coding (2010) Proc. International Conference on Machine Learning, pp. 399-406; Ranzato, M., Mnih, V., Susskind, J.M., Hinton, G.E., Modeling natural images using gated MRFs (2013) IEEE Trans. Pattern Anal. Machine Intell., 35, pp. 2206-2222; Bengio, Y., Thibodeau-Laufer, E., Alain, G., Yosinski, J., Deep generative stochastic networks trainable by backprop (2014) Proc. 31st International Conference on Machine Learning, pp. 226-234; Kingma, D., Rezende, D., Mohamed, S., Welling, M., Semi-supervised learning with deep generative models (2014) Proc. Advances in Neural Information Processing Systems, 27, pp. 3581-3589; Ba, J., Mnih, V., Kavukcuoglu, K., Multiple object recognition with visual attention (2014) Proc. International Conference on Learning Representations, , http://arxiv.org/abs/1412.7755; Mnih, V., Human-level control through deep reinforcement learning (2015) Nature, 518, pp. 529-533; Bottou, L., From machine learning to machine reasoning (2014) Mach. Learn., 94, pp. 133-149; Vinyals, O., Toshev, A., Bengio, S., Erhan, D., Show and tell: A neural image caption generator (2014) Proc. International Conference on Machine Learning, , http://arxiv.org/abs/1502.03044; Van Der Maaten, L., Hinton, G.E., Visualizing data using t-SNE (2008) J. Mach. Learn. Research, 9, pp. 2579-2605",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Schmidhuber J.,7003514621;,Deep Learning in neural networks: An overview,2015,Neural Networks,10.1016/j.neunet.2014.09.003,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910651844&doi=10.1016%2fj.neunet.2014.09.003&partnerID=40&md5=1e380e40a7a616540c705ef8a63ce456,"In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning & evolutionary computation, and indirect search for short programs encoding deep and large networks. © 2014.",Deep learning; Evolutionary computation; Reinforcement learning; Supervised learning; Unsupervised learning,Artificial intelligence; Backpropagation; Evolutionary algorithms; Neural networks; Pattern recognition; Recurrent neural networks; Supervised learning; Surveys; Unsupervised learning; Credit assignment; Deep learning; Large networks; Reinforcement learning; artificial intelligence; artificial neural network; automated pattern recognition; back propagation; computer language; deep learning; feedforward neural network; human; information processing; learning algorithm; machine learning; nnsupervised Learning; nonhuman; positive feedback; problem solving; process optimization; recurrent neural network; reinforcement learning; Review; short term memory; supervised learning; visual cortex; classification; standards; trends; Artificial Intelligence,"Aberdeen, D., (2003) Policy-gradient algorithms for partially observable Markov decision processes, , (Ph.D. thesis), Australian National University; Abounadi, J., Bertsekas, D., Borkar, V.S., Learning algorithms for Markov decision processes with average cost (2002) SIAM Journal on Control and Optimization, 40 (3), pp. 681-698; Akaike, H., Statistical predictor identification (1970) Annals of the Institute of Statistical Mathematics, 22, pp. 203-217; Akaike, H., Information theory and an extension of the maximum likelihood principle (1973) Second intl. symposium on information theory, pp. 267-281. , Akademinai Kiado; Akaike, H., A new look at the statistical model identification (1974) IEEE Transactions on Automatic Control, 19 (6), pp. 716-723; Allender, A., Application of time-bounded Kolmogorov complexity in complexity theory (1992) EATCS monographs on theoretical computer science, pp. 6-22. , Springer, O. Watanabe (Ed.) Kolmogorov complexity and computational complexity; Almeida, L.B., A learning rule for asynchronous perceptrons with feedback in a combinatorial environment (1987) IEEE 1st international conference on neural networks, 2, pp. 609-618; Almeida, L.B., Almeida, L.B., Langlois, T., Amaral, J.D., Redol, R.A., (1997) On-line step size adaptation. Technical report, INESC, 9 Rua Alves Redol, 1000; Amari, S., A theory of adaptive pattern classifiers (1967) IEEE Transactions on Electronic Computers, 16 (3), pp. 299-307; Amari, S.-I., Natural gradient works efficiently in learning (1998) Neural Computation, 10 (2), pp. 251-276; Amari, S., Cichocki, A., Yang, H., A new learning algorithm for blind signal separation (1996) Advances in neural information processing systems (NIPS), vol. 8, , The MIT Press, D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.); Amari, S., Murata, N., Statistical theory of learning curves under entropic loss criterion (1993) Neural Computation, 5 (1), pp. 140-153; Amit, D.J., Brunel, N., Dynamics of a recurrent network of spiking neurons before and following learning (1997) Network: Computation in Neural Systems, 8 (4), pp. 373-404; An, G., The effects of adding noise during backpropagation training on a generalization performance (1996) Neural Computation, 8 (3), pp. 643-674; Andrade, M.A., Chacon, P., Merelo, J.J., Moran, F., Evaluation of secondary structure of proteins from UV circular dichroism spectra using an unsupervised learning neural network (1993) Protein Engineering, 6 (4), pp. 383-390; Andrews, R., Diederich, J., Tickle, A.B., Survey and critique of techniques for extracting rules from trained artificial neural networks (1995) Knowledge-Based Systems, 8 (6), pp. 373-389; Anguita, D., Gomes, B.A., Mixing floating- and fixed-point formats for neural network learning on neuroprocessors (1996) Microprocessing and Microprogramming, 41 (10), pp. 757-769; Anguita, D., Parodi, G., Zunino, R., An efficient implementation of BP on RISC-based workstations (1994) Neurocomputing, 6 (1), pp. 57-65; Arel, I., Rose, D.C., Karnowski, T.P., Deep machine learning-a new frontier in artificial intelligence research (2010) IEEE Computational Intelligence Magazine, 5 (4), pp. 13-18; Ash, T., Dynamic node creation in backpropagation neural networks (1989) Connection Science, 1 (4), pp. 365-375; Atick, J.J., Li, Z., Redlich, A.N., Understanding retinal color coding from first principles (1992) Neural Computation, 4, pp. 559-572; Atiya, A.F., Parlos, A.G., New results on recurrent network training: unifying the algorithms and accelerating convergence (2000) IEEE Transactions on Neural Networks, 11 (3), pp. 697-709; Ba, J., Frey, B., Adaptive dropout for training deep neural networks (2013) Advances in neural information processing systems (NIPS), pp. 3084-3092; Baird, H., (1990) Document image defect models, , Proceddings, IAPR workshop on syntactic and structural pattern recognition; Baird, L.C., Residual algorithms: Reinforcement learning with function approximation (1995) International conference on machine learning, pp. 30-37; Baird, L., Moore, A.W., Gradient descent for general reinforcement learning (1999) Advances in neural information processing systems, vol. 12 (NIPS), pp. 968-974. , MIT Press; Bakker, B., Reinforcement learning with long short-term memory (2002) Advances in neural information processing systems, vol. 14, pp. 1475-1482. , MIT Press, Cambridge, MA, T.G. Dietterich, S. Becker, Z. Ghahramani (Eds.); Bakker, B., Schmidhuber, J., Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization (2004) Proc. 8th conference on intelligent autonomous systems IAS-8, pp. 438-445. , IOS Press, Amsterdam, NL, F. Groen (Ed.); Bakker, B., Zhumatiy, V., Gruener, G., Schmidhuber, J., A robot that reinforcement-learns to identify and memorize important previous observations (2003), pp. 430-435. , Proceedings of the 2003 IEEE/RSJ international conference on intelligent robots and systems; Baldi, P., Gradient descent learning algorithms overview: A general dynamical systems perspective (1995) IEEE Transactions on Neural Networks, 6 (1), pp. 182-195; Baldi, P., Autoencoders, unsupervised learning, and deep architectures (2012) Journal of Machine Learning Research, 27, pp. 37-50. , (Proc. 2011 ICML Workshop on Unsupervised and Transfer Learning); Baldi, P., Brunak, S., Frasconi, P., Pollastri, G., Soda, G., Exploiting the past and the future in protein secondary structure prediction (1999) Bioinformatics, 15, pp. 937-946; Baldi, P., Chauvin, Y., Neural networks for fingerprint recognition (1993) Neural Computation, 5 (3), pp. 402-418; Baldi, P., Chauvin, Y., Hybrid modeling, HMM/NN architectures, and protein applications (1996) Neural Computation, 8 (7), pp. 1541-1565; Baldi, P., Hornik, K., Neural networks and principal component analysis: learning from examples without local minima (1989) Neural Networks, 2, pp. 53-58; Baldi, P., Hornik, K., Learning in linear networks: a survey (1995) IEEE Transactions on Neural Networks, 6 (4), pp. 837-858. , 1995; Baldi, P., Pollastri, G., The principled design of large-scale recursive neural network architectures-DAG-RNNs and the protein structure prediction problem (2003) Journal of Machine Learning Research, 4, pp. 575-602; Baldi, P., Sadowski, P., The dropout learning algorithm (2014) Artificial Intelligence, 210 C, pp. 78-122; Ballard, D.H., Modular learning in neural networks (1987) Proc. AAAI, pp. 279-284; Baluja, S., (1994) Population-based incremental learning: A method for integrating genetic search based function optimization and competitive learning. Technical report CMU-CS-94-163, , Carnegie Mellon University; Balzer, R., A 15 year perspective on automatic programming (1985) IEEE Transactions on Software Engineering, 11 (11), pp. 1257-1268; Barlow, H.B., Unsupervised learning (1989) Neural Computation, 1 (3), pp. 295-311; Barlow, H.B., Kaushal, T.P., Mitchison, G.J., Finding minimum entropy codes (1989) Neural Computation, 1 (3), pp. 412-423; Barrow, H.G., Learning receptive fields (1987) Proceedings of the IEEE 1st annual conference on neural networks, vol. IV, pp. 115-121. , IEEE; Barto, A.G., Mahadevan, S., Recent advances in hierarchical reinforcement learning (2003) Discrete Event Dynamic Systems, 13 (4), pp. 341-379; Barto, A.G., Singh, S., Chentanez, N., Intrinsically motivated learning of hierarchical collections of skills (2004) Proceedings of international conference on developmental learning, pp. 112-119. , MIT Press, Cambridge, MA; Barto, A.G., Sutton, R.S., Anderson, C.W., Neuronlike adaptive elements that can solve difficult learning control problems (1983) IEEE Transactions on Systems, Man and Cybernetics, SMC-13, pp. 834-846; Battiti, R., Accelerated backpropagation learning: two optimization methods (1989) Complex Systems, 3 (4), pp. 331-342; Battiti, T., First- and second-order methods for learning: between steepest descent and Newton's method (1992) Neural Computation, 4 (2), pp. 141-166; Baum, E.B., Haussler, D., What size net gives valid generalization? (1989) Neural Computation, 1 (1), pp. 151-160; Baum, L.E., Petrie, T., Statistical inference for probabilistic functions of finite state Markov chains (1966) The Annals of Mathematical Statistics, pp. 1554-1563; Baxter, J., Bartlett, P.L., Infinite-horizon policy-gradient estimation (2001) Journal of Artificial Intelligence Research, 15 (1), pp. 319-350; Bayer, J., Osendorfer, C., (2014) Variational inference of latent state sequences using recurrent networks, , arxiv:1406.1655, ArXiv Preprint ; Bayer, J., Osendorfer, C., Chen, N., Urban, S., van der Smagt, P., (2013) On fast dropout and its applicability to recurrent networks, , arxiv:1311.0701. ArXiv Preprint; Bayer, J., Wierstra, D., Togelius, J., Schmidhuber, J., Evolving memory cell structures for sequence learning (2009) Proc. ICANN, (2), pp. 755-764; Bayes, T., An essay toward solving a problem in the doctrine of chances (1763) Philosophical Transactions of the Royal Society of London, 53, pp. 370-418. , Communicated by R. Price, in a letter to J. Canton; Becker, S., Unsupervised learning procedures for neural networks (1991) International Journal of Neural Systems, 2 (1-2), pp. 17-33; Becker, S., Le Cun, Y., Improving the convergence of back-propagation learning with second order methods (1989) Proc. 1988 connectionist models summer school, 1988, pp. 29-37. , Morgan Kaufmann, San Mateo, D. Touretzky, G. Hinton, T. Sejnowski (Eds.); Behnke, S., Hebbian learning and competition in the neural abstraction pyramid (1999) Proceedings of the international joint conference on neural networks, 2, pp. 1356-1361; Behnke, S., Learning iterative image reconstruction in the neural abstraction pyramid (2001) International Journal of Computational Intelligence and Applications, 1 (4), pp. 427-438; Behnke, S., Learning face localization using hierarchical recurrent networks. (2002) Proceedings of the 12th international conference on artificial neural networks, pp. 1319-1324; Behnke, S., Discovering hierarchical speech features using convolutional non-negative matrix factorization (2003) Proceedings of the international joint conference on neural networks, 4, pp. 2758-2763; Behnke, S., Hierarchical neural networks for image interpretation (2003) LNCS, Lecture notes in computer science, 2766. , Springer; Behnke, S., Face localization and tracking in the neural abstraction pyramid (2005) Neural Computing and Applications, 14 (2), pp. 97-103; Behnke, S., Rojas, R., Neural abstraction pyramid: a hierarchical image understanding architecture (1998) Proceedings of international joint conference on neural networks, 2, pp. 820-825; Bell, A.J., Sejnowski, T.J., An information-maximization approach to blind separation and blind deconvolution (1995) Neural Computation, 7 (6), pp. 1129-1159; Bellman, R., (1957) Dynamic programming, , Princeton University Press, Princeton, NJ, USA; Belouchrani, A., Abed-Meraim, K., Cardoso, J.-F., Moulines, E., A blind source separation technique using second-order statistics (1997) IEEE Transactions on Signal Processing, 45 (2), pp. 434-444; Bengio, Y., (1991) Artificial neural networks and their application to sequence recognition, , (Ph.D. thesis), McGill University, (Computer Science), Montreal, QC, Canada; Bengio, Y., Learning deep architectures for AI (2009) Foundations and trends in machine learning, 2 (1). , Now Publishers; Bengio, Y., Courville, A., Vincent, P., Representation learning: a review and new perspectives (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1798-1828; Bengio, Y., Lamblin, P., Popovici, D., Larochelle, H., Greedy layer-wise training of deep networks (2007) Advances in neural information processing systems, vol. 19 (NIPS), pp. 153-160. , MIT Press, J.D. Cowan, G. Tesauro, J. Alspector (Eds.); Bengio, Y., Simard, P., Frasconi, P., Learning long-term dependencies with gradient descent is difficult (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 157-166; Beringer, N., Graves, A., Schiel, F., Schmidhuber, J., Classifying unprompted speech by retraining LSTM nets (2005) LNCS, 3696, pp. 575-581. , Springer-Verlag, Berlin, Heidelberg, W. Duch, J. Kacprzyk, E. Oja, S. Zadrozny (Eds.) Artificial neural networks: biological inspirations-ICANN 2005; Bertsekas, D.P., (2001) Dynamic programming and optimal control, , Athena Scientific; Bertsekas, D.P., Tsitsiklis, J.N., (1996) Neuro-dynamic programming, , Athena Scientific, Belmont, MA; Bichot, N.P., Rossi, A.F., Desimone, R., Parallel and serial neural mechanisms for visual search in macaque area V4 (2005) Science, 308, pp. 529-534; Biegler-König, F., Bärmann, F., A learning algorithm for multilayered neural networks based on linear least squares problems (1993) Neural Networks, 6 (1), pp. 127-131; Bishop, C.M., Curvature-driven smoothing: A learning algorithm for feed-forward networks (1993) IEEE Transactions on Neural Networks, 4 (5), pp. 882-884; Bishop, C.M., (2006) Pattern recognition and machine learning, , Springer; Blair, A.D., Pollack, J.B., Analysis of dynamical recognizers (1997) Neural Computation, 9 (5), pp. 1127-1142; Blondel, V.D., Tsitsiklis, J.N., A survey of computational complexity results in systems and control (2000) Automatica, 36 (9), pp. 1249-1274; Bluche, T., Louradour, J., Knibbe, M., Moysset, B., Benzeghiba, F., Kermorvant, C., The A2iA Arabic handwritten text recognition system at the OpenHaRT2013 evaluation (2014) International workshop on document analysis systems.; Blum, A.L., Rivest, R.L., Training a 3-node neural network is NP-complete (1992) Neural Networks, 5 (1), pp. 117-127; Blumer, A., Ehrenfeucht, A., Haussler, D., Warmuth, M.K., Occam's razor (1987) Information Processing Letters, 24, pp. 377-380; Bobrowski, L., Learning processes in multilayer threshold nets (1978) Biological Cybernetics, 31, pp. 1-6; Bodén, M., Wiles, J., Context-free and context-sensitive dynamics in recurrent neural networks (2000) Connection Science, 12 (3-4), pp. 197-210; Bodenhausen, U., Waibel, A., The Tempo 2 algorithm: adjusting time-delays by supervised learning (1991) Advances in neural information processing systems, vol. 3, pp. 155-161. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Bohte, S.M., Kok, J.N., La Poutre, H., Error-backpropagation in temporally encoded networks of spiking neurons (2002) Neurocomputing, 48 (1), pp. 17-37; Boltzmann, L., (1909) Wissenschaftliche Abhandlungen, , Barth, Leipzig, (collection of Boltzmann's articles in scientific journals), F. Hasenöhrl (Ed.); Bottou, L., (1991) Une approche théorique de l'apprentissage connexioniste; applications à la reconnaissance de la parole, , (Ph.D. thesis), Université de Paris XI; Bourlard, H., Morgan, N., (1994) Connnectionist speech recognition: a hybrid approach, , Kluwer Academic Publishers; Boutilier, C., Poole, D., Computing optimal policies for partially observable Markov decision processes using compact representations (1996) Proceedings of the AAAI.; Bradtke, S.J., Barto, A.G., Kaelbling, L.P., Linear least-squares algorithms for temporal difference learning (1996) Machine Learning, pp. 22-33; Brafman, R.I., Tennenholtz, M., R-MAX-a general polynomial time algorithm for near-optimal reinforcement learning (2002) Journal of Machine Learning Research, 3, pp. 213-231; Brea, J., Senn, W., Pfister, J.-P., Matching recall and storage in sequence learning with spiking neural networks (2013) The Journal of Neuroscience, 33 (23), pp. 9565-9575; Breiman, L., Bagging predictors (1996) Machine Learning, 24, pp. 123-140; Brette, R., Rudolph, M., Carnevale, T., Hines, M., Beeman, D., Bower, J.M., Simulation of networks of spiking neurons: a review of tools and strategies (2007) Journal of Computational Neuroscience, 23 (3), pp. 349-398; Breuel, T.M., Ul-Hasan, A., Al-Azawi, M.A., Shafait, F., High-performance OCR for printed English and Fraktur using LSTM networks (2013) 12th International conference on document analysis and recognition, pp. 683-687. , IEEE; Bromley, J., Bentz, J.W., Bottou, L., Guyon, I., LeCun, Y., Moore, C., Signature verification using a Siamese time delay neural network (1993) International Journal of Pattern Recognition and Artificial Intelligence, 7 (4), pp. 669-688; Broyden, C.G., A class of methods for solving nonlinear simultaneous equations (1965) Mathematics of Computation, 19 (92), pp. 577-593; Brueckner, R., Schulter, B., Social signal classification using deep BLSTM recurrent neural networks (2014) Proceedings 39th IEEE international conference on acoustics, speech, and signal processing, pp. 4856-4860; Brunel, N., Dynamics of sparsely connected networks of excitatory and inhibitory spiking neurons (2000) Journal of Computational Neuroscience, 8 (3), pp. 183-208; Bryson, A.E., A gradient method for optimizing multi-stage allocation processes (1961) Proc. Harvard Univ. symposium on digital computers and their applications.; Bryson, Jr.A.E., Denham, W.F., (1961) A steepest-ascent method for solving optimum programming problems. Technical report BR-1303, , Raytheon Company, Missle and Space Division; Bryson, A., Ho, Y., (1969) Applied optimal control: optimization, estimation, and control, , Blaisdell Pub. Co; Buhler, J., Efficient large-scale sequence comparison by locality-sensitive hashing (2001) Bioinformatics, 17 (5), pp. 419-428; Buntine, W.L., Weigend, A.S., Bayesian back-propagation (1991) Complex Systems, 5, pp. 603-643; Burgess, N., A constructive algorithm that converges for real-valued input patterns (1994) International Journal of Neural Systems, 5 (1), pp. 59-66; Cardoso, J.-F., On the performance of orthogonal source separation algorithms (1994) Proc. EUSIPCO, pp. 776-779; Carreira-Perpinan, M.A., (2001) Continuous latent variable models for dimensionality reduction and sequential data reconstruction, , (Ph.D. thesis), University of Sheffield, UK; Carter, M.J., Rudolph, F.J., Nucci, A.J., Operational fault tolerance of CMAC networks (1990) Advances in neural information processing systems (NIPS), vol. 2, pp. 340-347. , Morgan Kaufmann, San Mateo, CA, D.S. Touretzky (Ed.); Caruana, R., Multitask learning (1997) Machine Learning, 28 (1), pp. 41-75; Casey, M.P., The dynamics of discrete-time computation, with application to recurrent neural networks and finite state machine extraction (1996) Neural Computation, 8 (6), pp. 1135-1178; Cauwenberghs, G., A fast stochastic error-descent algorithm for supervised learning and optimization (1993) Advances in neural information processing systems, vol. 5, p. 244. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Chaitin, G.J., On the length of programs for computing finite binary sequences (1966) Journal of the ACM, 13, pp. 547-569; Chalup, S.K., Blair, A.D., Incremental training of first order recurrent neural networks to predict a context-sensitive language (2003) Neural Networks, 16 (7), pp. 955-972; Chellapilla, K., Puri, S., Simard, P., High performance convolutional neural networks for document processing. (2006) International workshop on Frontiers in handwriting recognition.; Chen, K., Salman, A., Learning speaker-specific characteristics with a deep neural architecture (2011) IEEE Transactions on Neural Networks, 22 (11), pp. 1744-1756; Cho, K., (2014) Foundations and advances in deep learning, , (Ph.D. thesis), Aalto University School of Science; Cho, K., Ilin, A., Raiko, T., Tikhonov-type regularization for restricted Boltzmann machines (2012) Intl. conf. on artificial neural networks 2012, pp. 81-88. , Springer; Cho, K., Raiko, T., Ilin, A., Enhanced gradient for training restricted Boltzmann machines (2013) Neural Computation, 25 (3), pp. 805-831; Church, A., An unsolvable problem of elementary number theory (1936) The American Journal of Mathematics, 58, pp. 345-363; Ciresan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Deep neural networks segment neuronal membranes in electron microscopy images (2012) Advances in neural information processing systems (NIPS), pp. 2852-2860; Ciresan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J., Mitosis detection in breast cancer histology images with deep neural networks (2013) Proc. MICCAI, 2, pp. 411-418; Ciresan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J., Deep big simple neural nets for handwritten digit recogntion (2010) Neural Computation, 22 (12), pp. 3207-3220; Ciresan, D.C., Meier, U., Masci, J., Gambardella, L.M., Schmidhuber, J., Flexible, high performance convolutional neural networks for image classification (2011) Intl. joint conference on artificial intelligence, pp. 1237-1242; Ciresan, D.C., Meier, U., Masci, J., Schmidhuber, J., A committee of neural networks for traffic sign classification (2011) International joint conference on neural networks, pp. 1918-1921; Ciresan, D.C., Meier, U., Masci, J., Schmidhuber, J., Multi-column deep neural network for traffic sign classification (2012) Neural Networks, 32, pp. 333-338; Ciresan, D.C., Meier, U., Schmidhuber, J., Multi-column deep neural networks for image classification (2012) IEEE Conference on computer vision and pattern recognition, , arxiv:1202.2745v1, Long preprint [cs.CV]; Ciresan, D.C., Meier, U., Schmidhuber, J., Transfer learning for Latin and Chinese characters with deep neural networks (2012) International joint conference on neural networks, pp. 1301-1306; Ciresan, D.C., Schmidhuber, J., (2013) Multi-column deep neural networks for offline handwritten Chinese character classification. Technical report, , arxiv:1309.0261, IDSIA; Cliff, D.T., Husbands, P., Harvey, I., Evolving recurrent dynamical networks for robot control (1993) Artificial neural nets and genetic algorithms, pp. 428-435. , Springer; Clune, J., Mouret, J.-B., Lipson, H., The evolutionary origins of modularity (2013) Proceedings of the Royal Society B: Biological Sciences, 280 (1755), p. 20122863; Clune, J., Stanley, K.O., Pennock, R.T., Ofria, C., On the performance of indirect encoding across the continuum of regularity (2011) IEEE Transactions on Evolutionary Computation, 15 (3), pp. 346-367; Coates, A., Huval, B., Wang, T., Wu, D.J., Ng, A.Y., Catanzaro, B., Deep learning with COTS HPC systems (2013) Proc. international conference on machine learning.; Cochocki, A., Unbehauen, R., (1993) Neural networks for optimization and signal processing, , John Wiley & Sons, Inc; Collobert, R., Weston, J., A unified architecture for natural language processing: deep neural networks with multitask learning (2008) Proceedings of the 25th international conference on machine learning, pp. 160-167. , ACM; Comon, P., Independent component analysis-a new concept? (1994) Signal Processing, 36 (3), pp. 287-314; Connor, C.E., Brincat, S.L., Pasupathy, A., Transformation of shape information in the ventral pathway (2007) Current Opinion in Neurobiology, 17 (2), pp. 140-147; Connor, J., Martin, D.R., Atlas, L.E., Recurrent neural networks and robust time series prediction (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 240-254; Cook, S.A., The complexity of theorem-proving procedures (1971) Proceedings of the 3rd annual ACM symposium on the theory of computing, pp. 151-158. , ACM, New York; Cramer, N.L., A representation for the adaptive generation of simple sequential programs (1985) Proceedings of an international conference on genetic algorithms and their applications, Carnegie-Mellon University, , Lawrence Erlbaum Associates, Hillsdale, NJ, J. Grefenstette (Ed.); Craven, P., Wahba, G., Smoothing noisy data with spline functions: estimating the correct degree of smoothing by the method of generalized cross-validation (1979) Numerische Mathematik, 31, pp. 377-403; Cuccu, G., Luciw, M., Schmidhuber, J., Gomez, F., Intrinsically motivated evolutionary search for vision-based reinforcement learning (2011) Proceedings of the 2011 IEEE conference on development and learning and epigenetic robotics IEEE-ICDL-EPIROB, 2, pp. 1-7. , IEEE; Dahl, G.E., Sainath, T.N., Hinton, G.E., Improving deep neural networks for LVCSR using rectified linear units and dropout (2013) IEEE International conference on acoustics, speech and signal processing, pp. 8609-8613. , IEEE; Dahl, G., Yu, D., Deng, L., Acero, A., Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition (2012) IEEE Transactions on Audio, Speech and Language Processing, 20 (1), pp. 30-42; D'Ambrosio, D.B., Stanley, K.O., A novel generative encoding for exploiting neural network sensor and output geometry (2007) Proceedings of the conference on genetic and evolutionary computation, pp. 974-981; Datar, M., Immorlica, N., Indyk, P., Mirrokni, V.S., Locality-sensitive hashing scheme based on p-stable distributions (2004) Proceedings of the 20th annual symposium on computational geometry, pp. 253-262. , ACM; Dayan, P., Hinton, G., Feudal reinforcement learning (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 271-278. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Dayan, P., Hinton, G.E., Varieties of Helmholtz machine (1996) Neural Networks, 9 (8), pp. 1385-1403; Dayan, P., Hinton, G.E., Neal, R.M., Zemel, R.S., The Helmholtz machine (1995) Neural Computation, 7, pp. 889-904; Dayan, P., Zemel, R., Competition and multiple cause models (1995) Neural Computation, 7, pp. 565-579; Deco, G., Parra, L., Non-linear feature extraction by redundancy reduction in an unsupervised stochastic neural network (1997) Neural Networks, 10 (4), pp. 683-691; Deco, G., Rolls, E.T., Neurodynamics of biased competition and cooperation for attention: a model with spiking neurons (2005) Journal of Neurophysiology, 94 (1), pp. 295-313; De Freitas, J.F.G., (2003) Bayesian methods for neural networks, , (Ph.D. thesis), University of Cambridge; DeJong, G., Mooney, R., Explanation-based learning: an alternative view (1986) Machine Learning, 1 (2), pp. 145-176; DeMers, D., Cottrell, G., Non-linear dimensionality reduction (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 580-587. , Morgan Kaufmann, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Dempster, A.P., Laird, N.M., Rubin, D.B., Maximum likelihood from incomplete data via the EM algorithm (1977) Journal of the Royal Statistical Society B, 39; Deng, L., Yu, D., (2014) Deep learning: methods and applications, , NOW Publishers; Desimone, R., Albright, T.D., Gross, C.G., Bruce, C., Stimulus-selective properties of inferior temporal neurons in the macaque (1984) The Journal of Neuroscience, 4 (8), pp. 2051-2062; de Souto, M.C., Souto, M.C.P.D., Oliveira, W.R.D., The loading problem for pyramidal neural networks (1999) Electronic Journal on Mathematics of Computation; De Valois, R.L., Albrecht, D.G., Thorell, L.G., Spatial frequency selectivity of cells in macaque visual cortex (1982) Vision Research, 22 (5), pp. 545-559; Deville, Y., Lau, K.K., Logic program synthesis (1994) Journal of Logic Programming, 19 (20), pp. 321-350; de Vries, B., Principe, J.C., A theory for neural networks with time delays (1991) Advances in neural information processing systems (NIPS), 3, pp. 162-168. , Morgan Kaufmann, R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.); DiCarlo, J.J., Zoccolan, D., Rust, N.C., How does the brain solve visual object recognition? (2012) Neuron, 73 (3), pp. 415-434; Dickmanns, E.D., Behringer, R., Dickmanns, D., Hildebrandt, T., Maurer, M., Thomanek, F., The seeing passenger car 'VaMoRs-P' (1994) Proc. int. symp. on intelligent vehicles, pp. 68-73; Dickmanns, D., Schmidhuber, J., Winklhofer, A., (1987) Der genetische algorithmus: eine implementierung in prolog. Technical report, , http://www.idsia.ch/~juergen/geneticprogramming.html, Inst. of Informatics, Tech. Univ. Munich; Dietterich, T.G., Ensemble methods in machine learning (2000) Multiple classifier systems, pp. 1-15. , Springer; Dietterich, T.G., Hierarchical reinforcement learning with the MAXQ value function decomposition (2000) Journal of Artificial Intelligence Research (JAIR), 13, pp. 227-303; Di Lena, P., Nagata, K., Baldi, P., Deep architectures for protein contact map prediction (2012) Bioinformatics, 28, pp. 2449-2457; Director, S.W., Rohrer, R.A., Automated network design-the frequency-domain case (1969) IEEE Transactions on Circuit Theory, CT-16, pp. 330-337; Dittenbach, M., Merkl, D., Rauber, A., The growing hierarchical self-organizing map (2000) IEEE-INNS-ENNS International joint conference on neural networks, vol. 6, p. 6015. , IEEE Computer Society; Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., DeCAF: a deep convolutional activation feature for generic visual recognition (2013), ArXiv Preprint. arxiv:1310.1531; Dorffner, G., Neural networks for time series processing (1996) Neural network world.; Doya, K., Samejima, K., Ichi Katagiri, K., Kawato, M., Multiple model-based reinforcement learning (2002) Neural Computation, 14 (6), pp. 1347-1369; Dreyfus, S.E., The numerical solution of variational problems (1962) Journal of Mathematical Analysis and Applications, 5 (1), pp. 30-45; Dreyfus, S.E., The computational solution of optimal control problems with time lag (1973) IEEE Transactions on Automatic Control, 18 (4), pp. 383-385; Duchi, J., Hazan, E., Singer, Y., Adaptive subgradient methods for online learning and stochastic optimization (2011) The Journal of Machine Learning, 12, pp. 2121-2159; Egorova, A., Gloye, A., Göktekin, C., Liers, A., Luft, M., Rojas, R., (2004) FU-fighters small size 2004, team description, , RoboCup 2004 symposium: papers and team description papers. CD edition; Elfwing, S., Otsuka, M., Uchibe, E., Doya, K., Free-energy based reinforcement learning for vision-based navigation with high-dimensional sensory inputs (2010) Neural information processing. theory and algorithms (ICONIP), vol. 1, pp. 215-222. , Springer; Eliasmith, C., (2013) How to build a brain: a neural architecture for biological cognition, , Oxford University Press, New York, NY; Eliasmith, C., Stewart, T.C., Choo, X., Bekolay, T., DeWolf, T., Tang, Y., A large-scale model of the functioning brain (2012) Science, 338 (6111), pp. 1202-1205; Elman, J.L., Finding structure in time (1990) Cognitive Science, 14 (2), pp. 179-211; Erhan, D., Bengio, Y., Courville, A., Manzagol, P.-A., Vincent, P., Bengio, S., Why does unsupervised pre-training help deep learning? (2010) Journal of Machine Learning Research, 11, pp. 625-660; Escalante-B, A.N., Wiskott, L., How to solve classification and regression problems on high-dimensional data with a supervised extension of slow feature analysis (2013) Journal of Machine Learning Research, 14, pp. 3683-3719; Eubank, R.L., Spline smoothing and nonparametric regression (1988) Self-organizing methods in modeling, , Marcel Dekker, New York, S. Farlow (Ed.); Euler, L., (1744), Methodus inveniendi; Eyben, F., Weninger, F., Squartini, S., Schuller, B., Real-life voice activity detection with LSTM recurrent neural networks and an application to Hollywood movies (2013) Proc. 38th IEEE international conference on acoustics, speech, and signal processing, pp. 483-487; Faggin, F., Neural network hardware (1992) International joint conference on neural networks, 1, p. 153; Fahlman, S.E., (1988) An empirical study of learning speed in back-propagation networks. Technical report CMU-CS-88-162, , Carnegie-Mellon Univ; Fahlman, S.E., The recurrent cascade-correlation learning algorithm (1991) Advances in neural information processing systems (NIPS), 3, pp. 190-196. , Morgan Kaufmann, R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.); Falconbridge, M.S., Stamps, R.L., Badcock, D.R., A simple Hebbian/anti-Hebbian network learns the sparse, independent components of natural images (2006) Neural Computation, 18 (2), pp. 415-429; Fan, Y., Qian, Y., Xie, F., Soong, F.K., TTS synthesis with bidirectional LSTM based recurrent neural networks (2014) Proc. Interspeech.; Farabet, C., Couprie, C., Najman, L., LeCun, Y., Learning hierarchical features for scene labeling (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1915-1929; Farlow, S.J., (1984) Self-organizing methods in modeling: GMDH type algorithms, vol. 54, , CRC Press; Feldkamp, L.A., Prokhorov, D.V., Eagen, C.F., Yuan, F., Enhanced multi-stream Kalman filter training for recurrent networks (1998) Nonlinear modeling, pp. 29-53. , Springer; Feldkamp, L.A., Prokhorov, D.V., Feldkamp, T.M., Simple and conditioned adaptive behavior from Kalman filter trained recurrent networks (2003) Neural Networks, 16 (5), pp. 683-689; Feldkamp, L.A., Puskorius, G.V., A signal processing framework based on dynamic neural networks with application to problems in adaptation, filtering, and classification (1998) Proceedings of the IEEE, 86 (11), pp. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
259-2277; Felleman, D.J., Van Essen, D.C., Distributed hierarchical processing in the primate cerebral cortex (1991) Cerebral Cortex, 1 (1), pp. 1-47; Fernández, S., Graves, A., Schmidhuber, J., An application of recurrent neural networks to discriminative keyword spotting (2007) Proc. ICANN,-2, pp. 220-229; Fernandez, S., Graves, A., Schmidhuber, J., Sequence labelling in structured domains with hierarchical recurrent neural networks (2007) Proceedings of the 20th international joint conference on artificial intelligence.; Fernandez, R., Rendel, A., Ramabhadran, B., Hoory, R., Prosody contour prediction with long short-term memory, bi-directional, deep recurrent neural networks (2014) Proc. Interspeech.; Field, D.J., Relations between the statistics of natural images and the response properties of cortical cells (1987) Journal of the Optical Society of America,4, pp. 2379-2394; Field, D.J., What is the goal of sensory coding? (1994) Neural Computation,6, pp. 559-601; Fieres, J., Schemmel, J., Meier, K., Realizing biological spiking network models in a configurable wafer-scale hardware system (2008) IEEE International joint conference on neural networks, pp. 969-976; Fine, S., Singer, Y., Tishby, N., The hierarchical hidden Markov model: analysis and applications (1998) Machine Learning, 32 (1), pp. 41-62; Fischer, A., Igel, C., Training restricted Boltzmann machines: an introduction (2014) Pattern Recognition,47, pp. 25-39; FitzHugh, R., Impulses and physiological states in theoretical models of nerve membrane (1961) Biophysical Journal, 1 (6), pp. 445-466; Fletcher, R., Powell, M.J., A rapidly convergent descent method for minimization (1963) The Computer Journal, 6 (2), pp. 163-168; Floreano, D., Mattiussi, C., Evolution of spiking neural controllers for autonomous vision-based robots (2001) Evolutionary robotics. From intelligent robotics to artificial life, pp. 38-61. , Springer; Fogel, D.B., Fogel, L.J., Porto, V., Evolving neural networks (1990) Biological Cybernetics, 63 (6), pp. 487-493; Fogel, L., Owens, A., Walsh, M., (1966) Artificial intelligence through simulated evolution, , Wiley, New York; Földiák, P., Forming sparse representations by local anti-Hebbian learning (1990) Biological Cybernetics,64, pp. 165-170; Földiák, P., Young, M.P., Sparse coding in the primate cortex (1995) The handbook of brain theory and neural networks, pp. 895-898. , The MIT Press, M.A. Arbib (Ed.); Förster, A., Graves, A., Schmidhuber, J., RNN-based learning of compact maps for efficient robot localization (2007) 15th European symposium on artificial neural networks, pp. 537-542; Franzius, M., Sprekeler, H., Wiskott, L., Slowness and sparseness lead to place, head-direction, and spatial-view cells (2007) PLoS Computational Biology, 3 (8), p. 166; Friedman, J., Hastie, T., Tibshirani, R., Springer series in statistics (2001) The elements of statistical learning,1, New York; Frinken, V., Zamora-Martinez, F., Espana-Boquera, S., Castro-Bleda, M.J., Fischer, A., Bunke, H., Long-short term memory neural networks language modeling for handwriting recognition (2012) 2012 21st International conference on pattern recognition, pp. 701-704. , IEEE; Fritzke, B., A growing neural gas network learns topologies (1994) NIPS, pp. 625-632. , MIT Press, G. Tesauro, D.S. Touretzky, T.K. Leen (Eds.); Fu, K.S., (1977) Syntactic pattern recognition and applications, , Springer, Berlin; Fukada, T., Schuster, M., Sagisaka, Y., Phoneme boundary estimation using bidirectional recurrent neural networks and its applications (1999) Systems and Computers in Japan, 30 (4), pp. 20-30; Fukushima, K., Neural network model for a mechanism of pattern recognition unaffected by shift in position-Neocognitron (1979) Transactions of the IECE, J62-A (10), pp. 658-665; Fukushima, K., Neocognitron: A self-organizing neural network for a mechanism of pattern recognition unaffected by shift in position (1980) Biological Cybernetics, 36 (4), pp. 193-202; Fukushima, K., Increasing robustness against background noise: visual pattern recognition by a neocognitron (2011) Neural Networks, 24 (7), pp. 767-778; Fukushima, K., Artificial vision by multi-layered neural networks: neocognitron and its advances (2013) Neural Networks,37, pp. 103-119; Fukushima, K., Training multi-layered neural network neocognitron (2013) Neural Networks,40, pp. 18-31; Gabor, D., Theory of communication. Part 1: the analysis of information (1946) Electrical Engineers-Part III: Journal of the Institution of Radio and Communication Engineering, 93 (26), pp. 429-441; Gallant, S.I., Connectionist expert systems (1988) Communications of the ACM, 31 (2), pp. 152-169; Gauss, C.F., (1809) Theoria motus corporum coelestium in sectionibus conicis solem ambientium.; Gauss, C.F., (1821) Theoria combinationis observationum erroribus minimis obnoxiae, , (Theory of the combination of observations least subject to error); Ge, S., Hang, C.C., Lee, T.H., Zhang, T., (2010) Stable adaptive neural network control, , Springer; Geiger, J.T., Zhang, Z., Weninger, F., Schuller, B., Rigoll, G., Robust speech recognition using long short-term memory recurrent neural networks for hybrid acoustic modelling (2014) Proc. interspeech.; Geman, S., Bienenstock, E., Doursat, R., Neural networks and the bias/variance dilemma (1992) Neural Computation,4, pp. 1-58; Gers, F.A., Schmidhuber, J., Recurrent nets that time and count (2000) Proceedings of the IEEE-INNS-ENNS international joint conference on neural networks,2000, vol. 3, pp. 189-194. , IEEE; Gers, F.A., Schmidhuber, J., LSTM recurrent networks learn simple context free and context sensitive languages (2001) IEEE Transactions on Neural Networks, 12 (6), pp. 1333-1340; Gers, F.A., Schmidhuber, J., Cummins, F., Learning to forget: continual prediction with LSTM (2000) Neural Computation, 12 (10), pp. 2451-2471; Gers, F.A., Schraudolph, N., Schmidhuber, J., Learning precise timing with LSTM recurrent networks (2002) Journal of Machine Learning Research,3, pp. 115-143; Gerstner, W., Kistler, W.K., (2002) Spiking neuron models, , Cambridge University Press; Gerstner, W., van Hemmen, J.L., Associative memory in a network of spiking neurons (1992) Network: Computation in Neural Systems, 3 (2), pp. 139-164; Ghavamzadeh, M., Mahadevan, S., Hierarchical policy gradient algorithms (2003) Proceedings of the twentieth conference on machine learning, pp. 226-233; Gherrity, M., A learning algorithm for analog fully recurrent neural networks (1989) IEEE/INNS International joint conference on neural networks,1, pp. 643-644. , San Diego; Girshick, R., Donahue, J., Darrell, T., Malik, J., (2013) Rich feature hierarchies for accurate object detection and semantic segmentation. Technical report, , arxiv:arxiv.org/abs/1311.2524, UC Berkeley and ICSI; Gisslen, L., Luciw, M., Graziano, V., Schmidhuber, J., Sequential constant size compressor for reinforcement learning (2011) Proc. fourth conference on artificial general intelligence, pp. 31-40. , Springer; Giusti, A., Ciresan, D.C., Masci, J., Gambardella, L.M., Schmidhuber, J., Fast image scanning with deep max-pooling convolutional neural networks (2013) Proc. ICIP.; Glackin, B., McGinnity, T.M., Maguire, L.P., Wu, Q., Belatreche, A., A novel approach for the implementation of large scale spiking neural networks on FPGA hardware (2005) Computational intelligence and bioinspired systems, pp. 552-563. , Springer; Glasmachers, T., Schaul, T., Sun, Y., Wierstra, D., Schmidhuber, J., Exponential natural evolution strategies (2010) Proceedings of the genetic and evolutionary computation conference, pp. 393-400. , ACM; Glorot, X., Bordes, A., Bengio, Y., Deep sparse rectifier networks (2011) AISTATS,15, pp. 315-323; Gloye, A., Wiesel, F., Tenchio, O., Simon, M., Reinforcing the driving quality of soccer playing robots by anticipation (2005) IT-Information Technology, 47 (5); Gödel, K., Über formal unentscheidbare Sätze der Principia Mathematica und verwandter Systeme I (1931) Monatshefte für Mathematik und Physik,38, pp. 173-198; Goldberg, D.E., (1989) Genetic algorithms in search, optimization and machine learning, , Addison-Wesley, Reading, MA; Goldfarb, D., A family of variable-metric methods derived by variational means (1970) Mathematics of Computation, 24 (109), pp. 23-26; Golub, G., Heath, H., Wahba, G., Generalized cross-validation as a method for choosing a good ridge parameter (1979) Technometrics,21, pp. 215-224; Gomez, F.J., (2003) Robust nonlinear control through neuroevolution, , (Ph.D. thesis), Department of Computer Sciences, University of Texas at Austin; Gomez, F.J., Miikkulainen, R., Active guidance for a finless rocket using neuroevolution (2003) Proc. GECCO 2003.; Gomez, F.J., Schmidhuber, J., Co-evolving recurrent neurons learn deep memory POMDPs (2005) Proc. of the 2005 conference on genetic and evolutionary computation, , ACM Press, New York, NY, USA; Gomez, F.J., Schmidhuber, J., Miikkulainen, R., Accelerated neural evolution through cooperatively coevolved synapses (2008) Journal of Machine Learning Research, 9 (MAY), pp. 937-965; Gomi, H., Kawato, M., Neural network control for a closed-loop system using feedback-error-learning (1993) Neural Networks, 6 (7), pp. 933-946; Gonzalez-Dominguez, J., Lopez-Moreno, I., Sak, H., Gonzalez-Rodriguez, J., Moreno, P.J., Automatic language identification using long short-term memory recurrent neural networks (2014) Proc. Interspeech.; Goodfellow, I.J., Bulatov, Y., Ibarz, J., Arnoud, S., Shet, V., (2014) Multi-digit number recognition from street view imagery using deep convolutional neural networks, , arxiv:1312.6082v4, ArXiv Preprint ; Goodfellow, I.J., Courville, A., Bengio, Y., Spike-and-slab sparse coding for unsupervised feature discovery (2011) NIPS Workshop on challenges in learning hierarchical models.; Goodfellow, I.J., Courville, A.C., Bengio, Y., Large-scale feature learning with spike-and-slab sparse coding (2012) Proceedings of the 29th international conference on machine learning.; Goodfellow, I., Mirza, M., Da, X., Courville, A., Bengio, Y., (2014) An empirical investigation of catastrophic forgetting in gradient-based neural networks. TR, , arxiv:1312.6211v2; Goodfellow, I.J., Warde-Farley, D., Mirza, M., Courville, A., Bengio, Y., Maxout networks (2013) International conference on machine learning.; Graves, A., Practical variational inference for neural networks (2011) Advances in neural information processing systems (NIPS), pp. 2348-2356; Graves, A., Eck, D., Beringer, N., Schmidhuber, J., Isolated digit recognition with LSTM recurrent networks (2003) First international workshop on biologically inspired approaches to advanced information technology.; Graves, A., Fernandez, S., Gomez, F.J., Schmidhuber, J., Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural nets (2006) ICML'06: Proceedings of the 23rd international conference on machine learning, pp. 369-376; Graves, A., Fernandez, S., Liwicki, M., Bunke, H., Schmidhuber, J., Unconstrained on-line handwriting recognition with recurrent neural networks (2008) Advances in neural information processing systems (NIPS), vol. 20, pp. 577-584. , MIT Press, Cambridge, MA, J. Platt, D. Koller, Y. Singer, S. Roweis (Eds.); Graves, A., Jaitly, N., Towards end-to-end speech recognition with recurrent neural networks (2014) Proc. 31st International conference on machine learning, pp. 1764-1772; Graves, A., Liwicki, M., Fernandez, S., Bertolami, R., Bunke, H., Schmidhuber, J., A novel connectionist system for improved unconstrained handwriting recognition (2009) IEEE Transactions on Pattern Analysis and Machine Intelligence, 31 (5); Graves, A., Mohamed, A.-R., Hinton, G.E., Speech recognition with deep recurrent neural networks (2013) IEEE International conference on acoustics, speech and signal processing, pp. 6645-6649. , IEEE; Graves, A., Schmidhuber, J., Framewise phoneme classification with bidirectional LSTM and other neural network architectures (2005) Neural Networks, 18 (5-6), pp. 602-610; Graves, A., Schmidhuber, J., Offline handwriting recognition with multidimensional recurrent neural networks (2009) Advances in neural information processing systems (NIPS), vol. 21, pp. 545-552. , MIT Press, Cambridge, MA; Graziano, M., (2009) The intelligent movement machine: an ethological perspective on the primate motor system, , Oxford University Press, USA; Griewank, A., Documenta Mathematica-Extra Volume ISMP (2012), pp. 389-400; Grondman, I., Busoniu, L., Lopes, G.A.D., Babuska, R., A survey of actor-critic reinforcement learning: standard and natural policy gradients (2012) IEEE Transactions on Systems, Man, and Cybernetics Part C: Applications and Reviews, 42 (6), pp. 1291-1307; Grossberg, S., Some networks that can learn, remember, and reproduce any number of complicated space-time patterns, I (1969) Journal of Mathematics and Mechanics,19, pp. 53-91; Grossberg, S., Adaptive pattern classification and universal recoding, 1: parallel development and coding of neural feature detectors (1976) Biological Cybernetics,23, pp. 187-202; Grossberg, S., Adaptive pattern classification and universal recoding, 2: feedback, expectation, olfaction, and illusions (1976) Biological Cybernetics, 23; Gruau, F., Whitley, D., Pyeatt, L., (1996) A comparison between cellular encoding and direct encoding for genetic neural networks. NeuroCOLT Technical report NC-TR-96-048, ESPRIT Working Group in Neural and Computational Learning, NeuroCOLT 8556; Grünwald, P.D., Myung, I.J., Pitt, M.A., (2005) Advances in minimum description length: theory and applications, , MIT Press; Grüttner, M., Sehnke, F., Schaul, T., Schmidhuber, J., Multi-dimensional deep memory atari-go players for parameter exploring policy gradients (2010) Proceedings of the international conference on artificial neural networks ICANN, pp. 114-123. , Springer; Guo, X., Singh, S., Lee, H., Lewis, R., Wang, X., Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning (2014) Advances in neural information processing systems, vol. 27 (NIPS); Guyon, I., Vapnik, V., Boser, B., Bottou, L., Solla, S.A., Structural risk minimization for character recognition (1992) Advances in neural information processing systems (NIPS), vol. 4, pp. 471-479. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Hadamard, J., (1908) Mémoire sur le problème d'analyse relatif à l'équilibre des plaques élastiques encastrées. Mémoires présentés par divers savants à l'Acadtho, , Imprimerie nationale; Hadsell, R., Chopra, S., LeCun, Y., Dimensionality reduction by learning an invariant mapping (2006) Proc. computer vision and pattern recognition conference, , IEEE Press; Hagras, H., Pounds-Cornish, A., Colley, M., Callaghan, V., Clarke, G., Evolving spiking neural network controllers for autonomous robots (2004) IEEE International conference on robotics and automation,5, pp. 4620-4626; Hansen, N., Müller, S.D., Koumoutsakos, P., Reducing the time complexity of the derandomized evolution strategy with covariance matrix adaptation (CMA-ES) (2003) Evolutionary Computation, 11 (1), pp. 1-18; Hansen, N., Ostermeier, A., Completely derandomized self-adaptation in evolution strategies (2001) Evolutionary Computation, 9 (2), pp. 159-195; Hanson, S.J., A stochastic version of the delta rule (1990) Physica D: Nonlinear Phenomena, 42 (1), pp. 265-272; Hanson, S.J., Pratt, L.Y., Comparing biases for minimal network construction with back-propagation (1989) Advances in neural information processing systems (NIPS), vol. 1, pp. 177-185. , Morgan Kaufmann, San Mateo, CA, D.S. Touretzky (Ed.); Happel, B.L., Murre, J.M., Design and evolution of modular neural network architectures (1994) Neural Networks, 7 (6), pp. 985-1004; Hashem, S., Schmeiser, B., Improving model accuracy using optimal linear combinations of trained neural networks (1992) IEEE Transactions on Neural Networks,6, pp. 792-794; Hassibi, B., Stork, D.G., Second order derivatives for network pruning: optimal brain surgeon (1993) Advances in neural information processing systems, vol. 5, pp. 164-171. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Hastie, T.J., Tibshirani, R.J., Generalized additive models (1990) Monographs on statisics and applied probability, 43; Hastie, T., Tibshirani, R., Friedman, J., The elements of statistical learning (2009) Springer series in statistics; Hawkins, J., George, D., (2006) Hierarchical temporal memory-concepts, theory, and terminology, , Numenta Inc; Haykin, S.S., (2001) Kalman filtering and neural networks, , Wiley Online Library; Hebb, D.O., (1949) The organization of behavior, , Wiley, New York; Hecht-Nielsen, R., Theory of the backpropagation neural network (1989) International joint conference on neural networks, pp. 593-605. , IEEE; Heemskerk, J.N., Overview of neural hardware (1995) Neurocomputers for brain-style processing. Design, implementation and application; Heess, N., Silver, D., Teh, Y.W., Actor-critic reinforcement learning with energy-based policies (2012) Proc. European workshop on reinforcement learning, pp. 43-57; Heidrich-Meisner, V., Igel, C., Neuroevolution strategies for episodic reinforcement learning (2009) Journal of Algorithms, 64 (4), pp. 152-168; Herrero, J., Valencia, A., Dopazo, J., A hierarchical unsupervised growing neural network for clustering gene expression patterns (2001) Bioinformatics, 17 (2), pp. 126-136; Hertz, J., Krogh, A., Palmer, R., (1991) Introduction to the theory of neural computation, , Addison-Wesley, Redwood City; Hestenes, M.R., Stiefel, E., Methods of conjugate gradients for solving linear systems (1952) Journal of Research of the National Bureau of Standards,49, pp. 409-436; Hihi, S.E., Bengio, Y., Hierarchical recurrent neural networks for long-term dependencies (1996) Advances in neural information processing systems, vol. 8, pp. 493-499. , MIT Press, D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.); Hinton, G.E., Connectionist learning procedures (1989) Artificial Intelligence, 40 (1), pp. 185-234; Hinton, G.E., Training products of experts by minimizing contrastive divergence (2002) Neural Computation, 14 (8), pp. 1771-1800; Hinton, G.E., Dayan, P., Frey, B.J., Neal, R.M., The wake-sleep algorithm for unsupervised neural networks (1995) Science,268, pp. 1158-1160; Hinton, G.E., Deng, L., Yu, D., Dahl, G.E., Mohamed, A., Jaitly, N., Deep neural networks for acoustic modeling in speech recognition: the shared views of four research groups (2012) IEEE Signal Processing Magazine, 29 (6), pp. 82-97; Hinton, G.E., Ghahramani, Z., Generative models for discovering sparse distributed representations (1997) Philosophical Transactions of the Royal Society B,352, pp. 1177-1190; Hinton, G.E., Osindero, S., Teh, Y.-W., A fast learning algorithm for deep belief nets (2006) Neural Computation, 18 (7), pp. 1527-1554; Hinton, G., Salakhutdinov, R., Reducing the dimensionality of data with neural networks (2006) Science, 313 (5786), pp. 504-507; Hinton, G.E., Sejnowski, T.E., Learning and relearning in Boltzmann machines (1986) Parallel distributed processing, vol. 1, pp. 282-317. , MIT Press; Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R., (2012) Improving neural networks by preventing co-adaptation of feature detectors. Technical report, , arxiv:1207.0580; Hinton, G.E., van Camp, D., Keeping neural networks simple (1993) Proceedings of the international conference on artificial neural networks, Amsterdam, pp. 11-18. , Springer; Hochreiter, S., (1991) Untersuchungen zu dynamischen neuronalen Netzen, , (Diploma thesis), Institut für Informatik, Lehrstuhl Prof. Brauer, Technische Universität München, Advisor: J. Schmidhuber; Hochreiter, S., Bengio, Y., Frasconi, P., Schmidhuber, J., Gradient flow in recurrent nets: the difficulty of learning long-term dependencies (2001) A field guide to dynamical recurrent neural networks, , IEEE Press, S.C. Kremer, J.F. Kolen (Eds.); Hochreiter, S., Obermayer, K., Sequence classification for protein analysis (2005), In Snowbird workshop, Snowbird: Utah. Computational and Biological Learning Society; Hochreiter, S., Schmidhuber, J., Bridging long time lags by weight guessing and Long Short-Term Memory (1996) Frontiers in artificial intelligence and applications,37, pp. 65-72. , IOS Press, Amsterdam, Netherlands, F.L. Silva, J.C. Principe, L.B. Almeida (Eds.) Spatiotemporal models in biological and artificial systems; Hochreiter, S., Schmidhuber, J., Flat minima (1997) Neural Computation, 9 (1), pp. 1-42; Hochreiter, S., Schmidhuber, J., Long short-term memory (1997) Neural Computation, 9 (8), pp. 1735-1780. , Based on TR FKI-207-95, TUM (1995); Hochreiter, S., Schmidhuber, J., Feature extraction through LOCOCODE (1999) Neural Computation, 11 (3), pp. 679-714; Hochreiter, S., Younger, A.S., Conwell, P.R., Learning to learn using gradient descent (2001) Lecture notes on comp. sci.,2130, pp. 87-94. , Springer, Berlin, Heidelberg, Proc. intl. conf. on artificial neural networks; Hodgkin, A.L., Huxley, A.F., A quantitative description of membrane current and its application to conduction and excitation in nerve (1952) The Journal of Physiology, 117 (4), p. 500; Hoerzer, G.M., Legenstein, R., Maass, W., Emergence of complex computational structures from chaotic neural networks through reward-modulated Hebbian learning (2014) Cerebral Cortex,24, pp. 677-690; Holden, S.B., (1994) On the theory of generalization and self-structuring in linearly weighted connectionist networks, , (Ph.D. thesis), Cambridge University, Engineering Department; Holland, J.H., (1975) Adaptation in natural and artificial systems, , University of Michigan Press, Ann Arbor; Honavar, V., Uhr, L.M., A network of neuron-like units that learns to perceive by generation as well as reweighting of its links (1988) Proc. of the 1988 connectionist models summer school, pp. 472-484. , Morgan Kaufman, San Mateo, D. Touretzky, G.E. Hinton, T. Sejnowski (Eds.); Honavar, V., Uhr, L., Generative learning structures and processes for generalized connectionist networks (1993) Information Sciences, 70 (1), pp. 75-108; Hopfield, J.J., Neural networks and physical systems with emergent collective computational abilities (1982) Proceedings of the National Academy of Sciences,79, pp. 2554-2558; Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Networks, 2 (5), pp. 359-366; Hubel, D.H., Wiesel, T., Receptive fields, binocular interaction, and functional architecture in the cat's visual cortex (1962) Journal of Physiology (London),160, pp. 106-154; Hubel, D.H., Wiesel, T.N., Receptive fields and functional architecture of monkey striate cortex (1968) The Journal of Physiology, 195 (1), pp. 215-243; Huffman, D.A., A method for construction of minimum-redundancy codes (1952) Proceedings IRE,40, pp. 1098-1101; Hung, C.P., Kreiman, G., Poggio, T., DiCarlo, J.J., Fast readout of object identity from macaque inferior temporal cortex (2005) Science, 310 (5749), pp. 863-866; Hutter, M., The fastest and shortest algorithm for all well-defined problems (2002) International Journal of Foundations of Computer Science, 13 (3), pp. 431-443. , (On J. Schmidhuber's SNF grant 20-61847); Hutter, M., (2005) Universal artificial intelligence: sequential decisions based on algorithmic probability, , Springer, Berlin, (On J. Schmidhuber's SNF grant 20-61847); Hyvärinen, A., Hoyer, P., Oja, E., Sparse code shrinkage: denoising by maximum likelihood estimation (1999) Advances in neural information processing systems (NIPS), vol. 12, , MIT Press, M. Kearns, S.A. Solla, D. Cohn (Eds.); Hyvärinen, A., Karhunen, J., Oja, E., (2001) Independent component analysis, , John Wiley & Sons; Contest on Mitosis Detection in Breast Cancer Histological Images (2012) (2012), http://ipal.cnrs.fr/ICPR2012/, IPAL laboratory and TRIBVN company and pitie-salpetriere hospital and CIALAB of Ohio State Univ; Igel, C., Neuroevolution for reinforcement learning using evolution strategies (2003) Congress on evolutionary computation, vol. 4, pp. 2588-2595. , IEEE, R. Reynolds, H. Abbass, K.C. Tan, B. Mckay, D. Essam, T. Gedeon (Eds.); Igel, C., Hüsken, M., Empirical evaluation of the improved Rprop learning algorithm (2003) Neurocomputing, 50 (C), pp. 105-123; Ikeda, S., Ochiai, M., Sawaragi, Y., Sequential GMDH algorithm and its application to river flow prediction (1976) IEEE Transactions on Systems, Man and Cybernetics,-7, pp. 473-479; Indermuhle, E., Frinken, V., Bunke, H., Mode detection in online handwritten documents using BLSTM neural networks (2012) Frontiers in handwriting recognition (ICFHR), 2012 international conference on, pp. 302-307. , IEEE; Indermuhle, E., Frinken, V., Fischer, A., Bunke, H., Keyword spotting in online handwritten documents containing text and non-text using BLSTM neural networks (2011) Document analysis and recognition (ICDAR), 2011 international conference on, pp. 73-77. , IEEE; Indiveri, G., Linares-Barranco, B., Hamilton, T.J., Van Schaik, A., Etienne-Cummings, R., Delbruck, T., Neuromorphic silicon neuron circuits (2011) Frontiers in Neuroscience, 5 (73); Ivakhnenko, A.G., The group method of data handling-a rival of the method of stochastic approximation (1968) Soviet Automatic Control, 13 (3), pp. 43-55; Ivakhnenko, A.G., Polynomial theory of complex systems (1971) IEEE Transactions on Systems, Man and Cybernetics,-4, pp. 364-378; Ivakhnenko, A.G., The review of problems solvable by algorithms of the group method of data handling (GMDH) (1995) Pattern Recognition and Image Analysis/Raspoznavaniye Obrazov I Analiz Izobrazhenii,5, pp. 527-535; Ivakhnenko, A.G., Lapa, V.G., (1965) Cybernetic predicting devices, , CCM Information Corporation; Ivakhnenko, A.G., Lapa, V.G., McDonough, R.N., (1967) Cybernetics and forecasting techniques, , American Elsevier, NY; Izhikevich, E.M., Simple model of spiking neurons (2003) IEEE Transactions on Neural Networks, 14 (6), pp. 1569-1572; Jaakkola, T., Singh, S.P., Jordan, M.I., Reinforcement learning algorithm for partially observable Markov decision problems (1995) Advances in neural information processing systems, vol. 7, pp. 345-352. , MIT Press, G. Tesauro, D.S. Touretzky, T.K. Leen (Eds.); Jackel, L., Boser, B., Graf, H.-P., Denker, J., LeCun, Y., Henderson, D., VLSI implementation of electronic neural networks: and example in character recognition (1990), pp. 320-322. , In IEEE (Ed.), IEEE international conference on systems, man, and cybernetics; Jacob, C., Lindenmayer, A., Rozenberg, G., Genetic L-system programming (1994) Lecture notes in computer science, , Parallel problem solving from nature III; Jacobs, R.A., Increased rates of convergence through learning rate adaptation (1988) Neural Networks, 1 (4), pp. 295-307; Jaeger, H.," (2001) The """"echo state"""" approach to analysing and training recurrent neural networks. Technical report GMD Report 148", , German National Research Center for Information Technology; Jaeger, H., Harnessing nonlinearity: Predicting chaotic systems and saving energy in wireless communication (2004) Science,304, pp. 78-80; Jain, V., Seung, S., Natural image denoising with convolutional networks (2009) Advances in neural information processing systems (NIPS), vol. 21, pp. 769-776. , Curran Associates, Inc, D. Koller, D. Schuurmans, Y. Bengio, L. Bottou (Eds.); Jameson, J., Delayed reinforcement learning with multiple time scale hierarchical backpropagated adaptive critics (1991) Neural networks for control; Ji, S., Xu, W., Yang, M., Yu, K., 3D convolutional neural networks for human action recognition (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (1), pp. 221-231; Jim, K., Giles, C.L., Horne, B.G., Effects of noise on convergence and generalization in recurrent networks (1995) Advances in neural information processing systems (NIPS), vol. 7, p. 649. , Morgan Kaufmann, San Mateo, CA, G. Tesauro, D. Touretzky, T. Leen (Eds.); Jin, X., Lujan, M., Plana, L.A., Davies, S., Temple, S., Furber, S.B., Modeling spiking neural networks on SpiNNaker (2010) Computing in Science and Engineering, 12 (5), pp. 91-97; Jodogne, S.R., Piater, J.H., Closed-loop learning of visual control policies (2007) Journal of Artificial Intelligence Research,28, pp. 349-391; Jones, J.P., Palmer, L.A., An evaluation of the two-dimensional Gabor filter model of simple receptive fields in cat striate cortex (1987) Journal of Neurophysiology, 58 (6), pp. 1233-1258; Jordan, M.I., (1986) Serial order: a parallel distributed processing approach. Technical report ICS report 8604, , Institute for Cognitive Science, University of California, San Diego; Jordan, M.I., (1988) Supervised learning and systems with excess degrees of freedom. Technical report COINS TR 88-27, , Massachusetts Institute of Technology; Jordan, M.I., Serial order: a parallel distributed processing approach (1997) Advances in Psychology,121, pp. 471-495; Jordan, M.I., Rumelhart, D.E., (1990) Supervised learning with a distal teacher. Technical report Occasional Paper #40, , Center for Cog. Sci., Massachusetts Institute of Technology; Jordan, M.I., Sejnowski, T.J., (2001) Graphical models: foundations of neural computation, , MIT Press; Joseph, R.D., (1961) Contributions to perceptron theory, , (Ph.D. thesis), Cornell Univ; Juang, C.-F., A hybrid of genetic algorithm and particle swarm optimization for recurrent network design (2004) IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 34 (2), pp. 997-1006; Judd, J.S., Neural network design and the complexity of learning (1990) Neural network modeling and connectionism, , MIT Press; Jutten, C., Herault, J., Blind separation of sources, part I: an adaptive algorithm based on neuromimetic architecture (1991) Signal Processing, 24 (1), pp. 1-10; Kaelbling, L.P., Littman, M.L., Cassandra, A.R., (1995) Planning and acting in partially observable stochastic domains. Technical report, , Brown University, Providence RI; Kaelbling, L.P., Littman, M.L., Moore, A.W., Reinforcement learning: A survey (1996) Journal of AI Research,4, pp. 237-285; Kak, S., Chen, Y., Wang, L., Data mining using surface and deep agents based on neural networks (2010) In AMCIS 2010 proceedings.; Kalinke, Y., Lehmann, H., Computation in recurrent neural networks: from counters to iterated function systems (1998) LNAI,1502, Springer, Berlin, Heidelberg, G. Antoniou, J. Slaney (Eds.) Advanced topics in artificial intelligence, Proceedings of the 11th Australian joint conference on artificial intelligence; Kalman, R.E., A new approach to linear filtering and prediction problems (1960) Journal of Basic Engineering, 82 (1), pp. 35-45; Karhunen, J., Joutsensalo, J., Generalizations of principal component analysis, optimization problems, and neural networks (1995) Neural Networks, 8 (4), pp. 549-562; Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L., Large-scale video classification with convolutional neural networks (2014) IEEE conference on computer vision and pattern recognition.; Kasabov, N.K., Neucube: a spiking neural network architecture for mapping, learning and understanding of spatio-temporal brain data (2014) Neural Networks; Kelley, H.J., Gradient theory of optimal flight paths (1960) ARS Journal, 30 (10), pp. 947-954; Kempter, R., Gerstner, W., Van Hemmen, J.L., Hebbian learning and spiking neurons (1999) Physical Review E, 59 (4), p. 4498; Kerlirzin, P., Vallet, F., Robustness in multilayer perceptrons (1993) Neural Computation, 5 (1), pp. 473-482; Khan, S.H., Bennamoun, M., Sohel, F., Togneri, R., Automatic feature learning for robust shadow detection (2014) IEEE conference on computer vision and pattern recognition.; Khan, M. M., Khan, G. M., & Miller, J. F. (2010). Evolution of neural networks using Cartesian Genetic Programming. In IEEE congress on evolutionary computation (pp. 1-8); Khan, M.M., Lester, D.R., Plana, L.A., Rast, A., Jin, X., Painkras, E., SpiNNaker: mapping neural networks onto a massively-parallel chip multiprocessor (2008) International joint conference on neural networks, pp. 2849-2856. , IEEE; Kimura, H., Miyazaki, K., Kobayashi, S., Reinforcement learning in POMDPs with function approximation (1997) ICML,97, pp. 152-160; Kistler, W.M., Gerstner, W., van Hemmen, J.L., Reduction of the Hodgkin-Huxley equations to a single-variable threshold model (1997) Neural Computation, 9 (5), pp. 1015-1045; Kitano, H., Designing neural networks using genetic algorithms with graph generation system (1990) Complex Systems,4, pp. 461-476; Klampfl, S., Maass, W., Emergence of dynamic memory traces in cortical microcircuit models through STDP (2013) The Journal of Neuroscience, 33 (28), pp. 11515-11529; Klapper-Rybicka, M., Schraudolph, N.N., Schmidhuber, J., Unsupervised learning in LSTM recurrent neural networks (2001) Lecture Notes on Comp. Sci.,2130, pp. 684-691. , Springer, Berlin, Heidelberg, Proc. intl. conf. on artificial neural networks; Kobatake, E., Tanaka, K., Neuronal selectivities to complex object features in the ventral visual pathway of the macaque cerebral cortex (1994) Journal of Neurophysiology,71, pp. 856-867; Kohl, N., Stone, P., Policy gradient reinforcement learning for fast quadrupedal locomotion (2004) Robotics and automation, 2004. Proceedings. ICRA'04. 2004 IEEE international conference on, vol. 3, pp. 2619-2624. , IEEE; Kohonen, T., Correlation matrix memories (1972) IEEE Transactions on Computers, 100 (4), pp. 353-359; Kohonen, T., Self-organized formation of topologically correct feature maps (1982) Biological Cybernetics, 43 (1), pp. 59-69; Kohonen, T., (1988) Self-organization and associative memory, , Springer; Koikkalainen, P., Oja, E., Self-organizing hierarchical feature maps (1990) International joint conference on neural networks, pp. 279-284. , IEEE; Kolmogorov, A.N., On the representation of continuous functions of several variables by superposition of continuous functions of one variable and addition (1965) Doklady Akademii Nauk SSSR,114, pp. 679-681; Kolmogorov, A.N., Three approaches to the quantitative definition of information (1965) Problems of Information Transmission,1, pp. 1-11; Kompella, V.R., Luciw, M.D., Schmidhuber, J., Incremental slow feature analysis: Adaptive low-complexity slow feature updating from high-dimensional input streams (2012) Neural Computation, 24 (11), pp. 2994-3024; Kondo, T., GMDH neural network algorithm using the heuristic self-organization method and its application to the pattern identification problem (1998) Proceedings of the 37th SICE annual conference, pp. 1143-1148. , IEEE; Kondo, T., Ueno, J., Multi-layered GMDH-type neural network self-selecting optimum neural network architecture and its application to 3-dimensional medical image recognition of blood vessels (2008) International Journal of Innovative Computing, Information and Control, 4 (1), pp. 175-187; Kordík, P., Náplava, P., Snorek, M., Genyk-Berezovskyj, M., Modified GMDH method and models quality evaluation by visualization (2003) Control Systems and Computers,2, pp. 68-75; Korkin, M., De Garis, H., Gers, F., Hemmi, H., CBM (CAM-Brain Machine)-a hardware tool which evolves a neural net module in a fraction of a second and runs a million neuron artificial brain in real time. (1997); Kosko, B., Unsupervised learning in noise (1990) IEEE Transactions on Neural Networks, 1 (1), pp. 44-57; Koutník, J., Cuccu, G., Schmidhuber, J., Gomez, F., Evolving large-scale neural networks for vision-based reinforcement learning (2013) Proceedings of the genetic and evolutionary computation conference, pp. 1061-1068. , ACM, Amsterdam; Koutník, J., Gomez, F., Schmidhuber, J., Evolving neural networks in compressed weight space (2010) Proceedings of the 12th annual conference on genetic and evolutionary computation, pp. 619-626; Koutník, J., Greff, K., Gomez, F., Schmidhuber, J., A clockwork RNN. In Proceedings of the 31th international conference on machine learning (2014),32, pp. 1845-1853. , arxiv:1402.3511, [cs.NE]; Koza, J.R., (1992) Genetic programming-on the programming of computers by means of natural selection, , MIT Press; Kramer, M., Nonlinear principal component analysis using autoassociative neural networks (1991) AIChE Journal,37, pp. 233-243; Kremer, S.C., Kolen, J.F., (2001) Field guide to dynamical recurrent networks, , Wiley-IEEE Press; Kriegeskorte, N., Mur, M., Ruff, D.A., Kiani, R., Bodurka, J., Esteky, H., Matching categorical object representations in inferior temporal cortex of man and monkey (2008) Neuron, 60 (6), pp. 1126-1141; Krizhevsky, A., Sutskever, I., Hinton, G.E., Imagenet classification with deep convolutional neural networks (2012) Advances in neural information processing systems, p. 4; Krogh, A., Hertz, J.A., A simple weight decay can improve generalization (1992) Advances in neural information processing systems, vol. 4, pp. 950-957. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Kruger, N., Janssen, P., Kalkan, S., Lappe, M., Leonardis, A., Piater, J., Deep hierarchies in the primate visual cortex: what can we learn for computer vision? (2013) IEEE Transactions on Pattern Analysis and Machine Intelligence, 35 (8), pp. 1847-1871; Kullback, S., Leibler, R.A., On information and sufficiency (1951) The Annals of Mathematical Statistics, pp. 79-86; Kurzweil, R., (2012) How to create a mind: the secret of human thought revealed; Lagoudakis, M.G., Parr, R., Least-squares policy iteration (2003) Journal of Machine Learning Research,4, pp. 1107-1149; Lampinen, J., Oja, E., Clustering properties of hierarchical self-organizing maps (1992) Journal of Mathematical Imaging and Vision, 2 (2-3), pp. 261-272; Lang, K., Waibel, A., Hinton, G.E., A time-delay neural network architecture for isolated word recognition (1990) Neural Networks,3, pp. 23-43; Lange, S., Riedmiller, M., Deep auto-encoder neural networks in reinforcement learning (2010) Neural networks, The 2010 international joint conference on, pp. 1-8; Lapedes, A., Farber, R., A self-optimizing, nonsymmetrical neural net for content addressable memory and pattern recognition (1986) Physica D,22, pp. 247-259; Laplace, P., Mémoire sur la probabilité des causes par les évènements (1774) Mémoires de l'Academie Royale des Sciences Presentés par Divers Savan,6, pp. 621-656; Larraanaga, P., Lozano, J.A., (2001) Estimation of distribution algorithms: a new tool for evolutionary computation, , Kluwer Academic Publishers, Norwell, MA, USA; Le, Q.V., Ranzato, M., Monga, R., Devin, M., Corrado, G., Chen, K., Building high-level features using large scale unsupervised learning (2012) Proc. ICML'12.; LeCun, Y., Une procédure d'apprentissage pour réseau à seuil asymétrique (1985) Proceedings of cognitiva,85, pp. 599-604; LeCun, Y., A theoretical framework for back-propagation (1988) Proceedings of the 1988 connectionist models summer school, pp. 21-28. , Morgan Kaufmann, CMU, Pittsburgh, Pa, D. Touretzky, G. Hinton, T. Sejnowski (Eds.); LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Back-propagation applied to handwritten zip code recognition (1989) Neural Computation, 1 (4), pp. 541-551; LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Handwritten digit recognition with a back-propagation network (1990) Advances in neural information processing systems, vol. 2, pp. 396-404. , Morgan Kaufmann, D.S. Touretzky (Ed.); LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proceedings of the IEEE, 86 (11), pp. 2278-2324; LeCun, Y., Denker, J.S., Solla, S.A., Optimal brain damage (1990) Advances in neural information processing systems, vol. 2, pp. 598-605. , Morgan Kaufmann, D.S. Touretzky (Ed.); LeCun, Y., Muller, U., Cosatto, E., Flepp, B., Off-road obstacle avoidance through end-to-end learning (2006) Advances in neural information processing systems (NIPS 2005); LeCun, Y., Simard, P., Pearlmutter, B., Automatic learning rate maximization by on-line estimation of the Hessian's eigenvectors (1993) Advances in neural information processing systems, vol. 5 (NIPS 1992), , Morgan Kaufmann Publishers, San Mateo, CA, S. Hanson, J. Cowan, L. Giles (Eds.); Lee, L., (1996) Learning of context-free languages: a survey of the literature. Technical report TR-12-96, , Center for Research in Computing Technology, Harvard University, Cambridge, Massachusetts; Lee, H., Battle, A., Raina, R., Ng, A.Y., Efficient sparse coding algorithms (2007) Advances in neural information processing systems (NIPS), vol. 19, pp. 801-808; Lee, H., Ekanadham, C., Ng, A.Y., Sparse deep belief net model for visual area V2 (2007) Advances in neural information processing systems (NIPS), vol. 7, pp. 873-880; Lee, H., Grosse, R., Ranganath, R., Ng, A.Y., Convolutional deep belief networks for scalable unsupervised learning of hierarchical representations (2009) Proceedings of the 26th international conference on machine learning, pp. 609-616; Lee, S., Kil, R.M., A Gaussian potential function network with hierarchically self-organizing learning (1991) Neural Networks, 4 (2), pp. 207-224; Lee, H., Pham, P.T., Largman, Y., Ng, A.Y., Unsupervised feature learning for audio classification using convolutional deep belief networks (2009) Proc. NIPS,9, pp. 1096-1104; Legendre, A.M., (1805) Nouvelles méthodes pour la détermination des orbites des cometes, , F. Didot; Legenstein, R.A., Maass, W., Neural circuits for pattern recognition with small total wire length (2002) Theoretical Computer Science, 287 (1), pp. 239-249; Legenstein, R., Wilbert, N., Wiskott, L., Reinforcement learning on slow features of high-dimensional input streams (2010) PLoS Computational Biology, 6 (8); 1676). Memoir using the chain rule (cited in TMME 7:2&3 (2010), pp. 321-332. , Leibniz G.W; Leibniz, G.W., Nova methodus pro maximis et minimis, itemque tangentibus, quae nec fractas, nec irrationales quantitates moratur, et singulare pro illis calculi genus (1684) Acta Eruditorum, pp. 467-473; Lenat, D.B., Theory formation by heuristic search (1983) Machine Learning, 21; Lenat, D.B., Brown, J.S., Why AM an EURISKO appear to work (1984) Artificial Intelligence, 23 (3), pp. 269-294; Lennie, P., Movshon, J.A., Coding of color and form in the geniculostriate visual pathway (2005) Journal of the Optical Society of America A, 22 (10), pp. 2013-2033; Levenberg, K., A method for the solution of certain problems in least squares (1944) Quarterly of Applied Mathematics,2, pp. 164-168; Levin, L.A., On the notion of a random sequence (1973) Soviet Mathematics Doklady, 14 (5), pp. 1413-1416; Levin, L.A., Universal sequential search problems (1973) Problems of Information Transmission, 9 (3), pp. 265-266; Levin, A.U., Leen, T.K., Moody, J.E., Fast pruning using principal components (1994) Advances in neural information processing systems (NIPS), vol. 6, p. 35. , Morgan Kaufmann; Levin, A.U., Narendra, K.S., Control of nonlinear dynamical systems using neural networks. II. Observability, identification, and control (1995) IEEE Transactions on Neural Networks, 7 (1), pp. 30-42; Lewicki, M.S., Olshausen, B.A., Inferring sparse, overcomplete image codes using an efficient coding framework (1998) Advances in neural information processing systems (NIPS), vol. 10, pp. 815-821. , M.I. Jordan, M.J. Kearns, S.A. Solla (Eds.); L'HÔpital, G.F.A., (1696) Analyse des infiniment petits, pour l'intelligence des lignes courbes, , L'Imprimerie Royale, Paris; Li, M., Vitányi, P.M.B., (1997) An introduction to Kolmogorov complexity and its applications, , Springer; Li, R., Zhang, W., Suk, H.-I., Wang, L., Li, J., Shen, D., Deep learning based imaging data completion for improved brain disease diagnosis (2014) Proc. MICCAI, , Springer; Lin, L., (1993) Reinforcement learning for robots using neural networks, , (Ph.D. thesis), Carnegie Mellon University, Pittsburgh; Lin, T., Horne, B., Tino, P., Giles, C., Learning long-term dependencies in NARX recurrent neural networks (1996) IEEE Transactions on Neural Networks, 7 (6), pp. 1329-1338; Lindenmayer, A., Mathematical models for cellular interaction in development (1968) Journal of Theoretical Biology,18, pp. 280-315; Lindstädt, S., Comparison of two unsupervised neural network models for redundancy reduction (1993) Proc. of the 1993 connectionist models summer school, pp. 308-315. , Erlbaum Associates, Hillsdale, NJ, M.C. Mozer, P. Smolensky, D.S. Touretzky, J.L. Elman, A.S. Weigend (Eds.); Linnainmaa, S., (1970) The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors, , (Master's thesis), Univ. Helsinki; Linnainmaa, S., Taylor expansion of the accumulated rounding error (1976) BIT Numerical Mathematics, 16 (2), pp. 146-160; Linsker, R., Self-organization in a perceptual network (1988) IEEE Computer,21, pp. 105-117; Littman, M.L., Cassandra, A.R., Kaelbling, L.P., Learning policies for partially observable environments: scaling up (1995) Machine learning: proceedings of the twelfth international conference, pp. 362-370. , Morgan Kaufmann Publishers, San Francisco, CA, A. Prieditis, S. Russell (Eds.); Liu, S.-C., Kramer, J., Indiveri, G., Delbrück, T., Burg, T., Douglas, R., Orientation-selective aVLSI spiking neurons (2001) Neural Networks, 14 (6-7), pp. 629-643; Ljung, L., (1998) System identification, , Springer; Logothetis, N.K., Pauls, J., Poggio, T., Shape representation in the inferior temporal cortex of monkeys (1995) Current Biology, 5 (5), pp. 552-563; Loiacono, D., Cardamone, L., Lanzi, P.L., (2011) Simulated car racing championship competition software manual. Technical report, , Dipartimento di Elettronica e Informazione, Politecnico di Milano, Italy; Loiacono, D., Lanzi, P.L., Togelius, J., Onieva, E., Pelta, D.A., Butz, M.V., The 2009 simulated car racing championship. (2009); Lowe, D., Object recognition from local scale-invariant features (1999) The Proceedings of the seventh IEEE international conference on computer vision,2, pp. 1150-1157; Lowe, D., Distinctive image features from scale-invariant key-points (2004) International Journal of Computer Vision,60, pp. 91-110; Luciw, M., Kompella, V.R., Kazerounian, S., Schmidhuber, J., An intrinsic value system for developing multiple invariant representations with incremental slowness learning (2013) Frontiers in Neurorobotics, 7 (9); Lusci, A., Pollastri, G., Baldi, P., Deep architectures and deep learning in chemoinformatics: the prediction of aqueous solubility for drug-like molecules (2013) Journal of Chemical Information and Modeling, 53 (7), pp. 1563-1575; Maas, A.L., Hannun, A.Y., Ng, A.Y., Rectifier nonlinearities improve neural network acoustic models (2013) International conference on machine learning.; Maass, W., Lower bounds for the computational power of networks of spiking neurons (1996) Neural Computation, 8 (1), pp. 1-40; Maass, W., Networks of spiking neurons: the third generation of neural network models (1997) Neural Networks, 10 (9), pp. 1659-1671; Maass, W., On the computational power of winner-take-all (2000) Neural Computation,12, pp. 2519-2535; Maass, W., Natschläger, T., Markram, H., Real-time computing without stable states: A new framework for neural computation based on perturbations (2002) Neural Computation, 14 (11), pp. 2531-2560; MacKay, D.J.C., A practical Bayesian framework for backprop networks (1992) Neural Computation,4, pp. 448-472; MacKay, D.J.C., Miller, K.D., Analysis of Linsker's simulation of Hebbian rules (1990) Neural Computation,2, pp. 173-187; Maclin, R., Shavlik, J.W., Using knowledge-based neural networks to improve algorithms: Refining the Chou-Fasman algorithm for protein folding (1993) Machine Learning, 11 (2-3), pp. 195-215; Maclin, R., Shavlik, J.W., Combining the predictions of multiple classifiers: Using competitive learning to initialize neural networks (1995) Proc. IJCAI, pp. 524-531; Madala, H.R., Ivakhnenko, A.G., (1994) Inductive learning algorithms for complex systems modeling, , CRC Press, Boca Raton; Madani, O., Hanks, S., Condon, A., On the undecidability of probabilistic planning and related stochastic optimization problems (2003) Artificial Intelligence, 147 (1), pp. 5-34; Maei, H.R., Sutton, R.S., GQ(λ): A general gradient algorithm for temporal-difference prediction learning with eligibility traces (2010) Proceedings of the third conference on artificial general intelligence,1, pp. 91-96; Maex, R., Orban, G., Model circuit of spiking neurons generating directional selectivity in simple cells (1996) Journal of Neurophysiology, 75 (4), pp. 1515-1545; Mahadevan, S., Average reward reinforcement learning: Foundations, algorithms, and empirical results (1996) Machine Learning,22, p. 159; Malik, J., Perona, P., Preattentive texture discrimination with early vision mechanisms (1990) Journal of the Optical Society of America A, 7 (5), pp. 923-932; Maniezzo, V., Genetic evolution of the topology and weight distribution of neural networks (1994) IEEE Transactions on Neural Networks, 5 (1), pp. 39-53; Manolios, P., Fanelli, R., First-order recurrent neural networks and deterministic finite state automata (1994) Neural Computation,6, pp. 1155-1173; Marchi, E., Ferroni, G., Eyben, F., Gabrielli, L., Squartini, S., Schuller, B., Multi-resolution linear prediction based features for audio onset detection with bidirectional LSTM neural networks (2014) Proc. 39th IEEE international conference on acoustics, speech, and signal processing, pp. 2183-2187; Markram, H., The human brain project (2012) Scientific American, 306 (6), pp. 50-55; Marquardt, D.W., An algorithm for least-squares estimation of nonlinear parameters (1963) Journal of the Society for Industrial & Applied Mathematics, 11 (2), pp. 431-441; Martens, J., Deep learning via Hessian-free optimization (2010) Proceedings of the 27th international conference on machine learning, pp. 735-742. , OmniPress, Haifa, Israel, J. Fürnkranz, T. Joachims (Eds.); Martens, J., Sutskever, I., Learning recurrent neural networks with Hessian-free optimization (2011) Proceedings of the 28th international conference on machine learning, pp. 1033-1040; Martinetz, T.M., Ritter, H.J., Schulten, K.J., Three-dimensional neural net for learning visuomotor coordination of a robot arm (1990) IEEE Transactions on Neural Networks, 1 (1), pp. 131-136; Masci, J., Giusti, A., Ciresan, D.C., Fricout, G., Schmidhuber, J., A fast learning algorithm for image segmentation with max-pooling convolutional networks (2013) International conference on image processing, pp. 2713-2717; Matsuoka, K., Noise injection into inputs in back-propagation learning (1992) IEEE Transactions on Systems, Man and Cybernetics, 22 (3), pp. 436-440; Mayer, H., Gomez, F., Wierstra, D., Nagy, I., Knoll, A., Schmidhuber, J., A system for robotic heart surgery that learns to tie knots using recurrent neural networks (2008) Advanced Robotics, 22 (13-14), pp. 1521-1537; McCallum, R.A., Learning to use selective attention and short-term memory in sequential tasks (1996) From animals to animats 4: proceedings of the fourth international conference on simulation of adaptive behavior, pp. 315-324. , MIT Press, Bradford Books, P. Maes, M. Mataric, J.-A. Meyer, J. Pollack, S.W. Wilson (Eds.); McCulloch, W., Pitts, W., A logical calculus of the ideas immanent in nervous activity (1943) Bulletin of Mathematical Biophysics,7, pp. 115-133; Melnik, O., Levy, S.D., Pollack, J.B., RAAM for infinite context-free languages (2000) Proc. IJCNN,-5, pp. 585-590; Memisevic, R., Hinton, G.E., Learning to represent spatial transformations with factored higher-order Boltzmann machines (2010) Neural Computation, 22 (6), pp. 1473-1492; Menache, I., Mannor, S., Shimkin, N., Q-cut-dynamic discovery of sub-goals in reinforcement learning (2002) Proc. ECML'02, pp. 295-306; Merolla, P.A., Arthur, J.V., Alvarez-Icaza, R., Cassidy, A.S., Sawada, J., Akopyan, F., A million spiking-neuron integrated circuit with a scalable communication network and interface (2014) Science, 345 (6197), pp. 668-673; Mesnil, G., Dauphin, Y., Glorot, X., Rifai, S., Bengio, Y., Goodfellow, I., Unsupervised and transfer learning challenge: a deep learning approach (2011) JMLR W&CP: proc. unsupervised and transfer learning, 7; Meuleau, N., Peshkin, L., Kim, K.E., Kaelbling, L.P., Learning finite state controllers for partially observable environments (1999) 15th international conference of uncertainty in AI, pp. 427-436; Miglino, O., Lund, H., Nolfi, S., Evolving mobile robots in simulated and real environments (1995) Artificial Life, 2 (4), pp. 417-434; Miller, K.D., A model for the development of simple cell receptive fields and the ordered arrangement of orientation columns through activity-dependent competition between on- and off-center inputs (1994) Journal of Neuroscience, 14 (1), pp. 409-441; Miller, J.F., Harding, S.L., Cartesian genetic programming (2009) Proceedings of the 11th annual conference companion on genetic and evolutionary computation conference: late breaking papers, pp. 3489-3512. , ACM; Miller, J.F., Thomson, P., Cartesian genetic programming (2000) Genetic programming, pp. 121-132. , Springer; Miller, G., Todd, P., Hedge, S., Designing neural networks using genetic algorithms (1989) Proceedings of the 3rd international conference on genetic algorithms, pp. 379-384. , Morgan Kauffman; Miller, W.T., Werbos, P.J., Sutton, R.S., (1995) Neural networks for control, , MIT Press; Minai, A.A., Williams, R.D., Perturbation response in feedforward networks (1994) Neural Networks, 7 (5), pp. 783-796; Minsky, M., Steps toward artificial intelligence (1963) Computers and thought, pp. 406-450. , McGraw-Hill, New York, E. Feigenbaum, J. Feldman (Eds.); Minsky, M., Papert, S., (1969) Perceptrons, , MIT Press, Cambridge, MA; Minton, S., Carbonell, J.G., Knoblock, C.A., Kuokka, D.R., Etzioni, O., Gil, Y., Explanation-based learning: A problem solving perspective (1989) Artificial Intelligence, 40 (1), pp. 63-118; Mitchell, T., (1997) Machine learning, , McGraw Hill; Mitchell, T.M., Keller, R.M., Kedar-Cabelli, S.T., Explanation-based generalization: A unifying view (1986) Machine Learning, 1 (1), pp. 47-80; Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., (2013) Playing Atari with deep reinforcement learning. Technical report, , Deepmind Technologies, arXiv:1312.5602 [cs.LG]; Mohamed, A., Hinton, G.E., Phone recognition using restricted Boltzmann machines (2010) IEEE international conference on acoustics, speech and signal processing, pp. 4354-4357; Molgedey, L., Schuster, H.G., Separation of independent signals using time-delayed correlations (1994) Physical Review Letters, 72 (23), pp. 3634-3637; Møller, M.F., (1993) Exact calculation of the product of the Hessian matrix of feed-forward network error functions and a vector in O(N) time. Technical report PB-432, , Computer Science Department, Aarhus University, Denmark; Montana, D.J., Davis, L., Training feedforward neural networks using genetic algorithms (1989) Proceedings of the 11th international joint conference on artificial intelligence-vol. 1, pp. 762-767. , Morgan Kaufmann Publishers Inc, San Francisco, CA, USA; Montavon, G., Orr, G., Müller, K., Neural networks: tricks of the trade (2012) Lecture Notes in Computer Science Series. LNCS,7700, Springer Verlag; Moody, J.E., Fast learning in multi-resolution hierarchies (1989) Advances in neural information processing systems (NIPS), vol. 1, pp. 29-39. , Morgan Kaufmann, D.S. Touretzky (Ed.); Moody, J.E., The effective number of parameters: An analysis of generalization and regularization in nonlinear learning systems (1992) Advances in neural information processing systems (NIPS), vol. 4, pp. 847-854. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Moody, J.E., Utans, J., Architecture selection strategies for neural networks: Application to corporate bond rating prediction (1994) Neural networks in the capital markets, , John Wiley & Sons, A.N. Refenes (Ed.); Moore, A., Atkeson, C.G., Prioritized sweeping: Reinforcement learning with less data and less time (1993) Machine Learning,13, pp. 103-130; Moore, A., Atkeson, C., The parti-game algorithm for variable resolution reinforcement learning in multidimensional state-spaces (1995) Machine Learning, 21 (3), pp. 199-233; Moriarty, D.E., (1997) Symbiotic evolution of neural networks in sequential decision tasks, , (Ph.D. thesis), Department of Computer Sciences, The University of Texas at Austin; Moriarty, D.E., Miikkulainen, R., Efficient reinforcement learning through symbiotic evolution (1996) Machine Learning,22, pp. 11-32; Morimoto, J., Doya, K., Robust reinforcement learning (2000) Advances in neural information processing systems (NIPS), vol. 13, pp. 1061-1067. , MIT Press, T.K. Leen, T.G. Dietterich, V. Tresp (Eds.); Mosteller, F., Tukey, J.W., Data analysis, including statistics (1968) Handbook of social psychology, vol. 2, , Addison-Wesley, G. Lindzey, E. Aronson (Eds.); Mozer, M.C., A focused back-propagation algorithm for temporal sequence recognition (1989) Complex Systems,3, pp. 349-381; Mozer, M.C., Discovering discrete distributed representations with iterative competitive learning (1991) Advances in neural information processing systems, vol. 3, pp. 627-634. , Morgan Kaufmann, R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.); Mozer, M.C., Induction of multiscale temporal structure (1992) Advances in neural information processing systems (NIPS), vol. 4, pp. 275-282. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Mozer, M.C., Smolensky, P., Skeletonization: A technique for trimming the fat from a network via relevance assessment (1989) Advances in neural information processing systems (NIPS), vol. 1, pp. 107-115. , Morgan Kaufmann, D.S. Touretzky (Ed.); Muller, U.A., Gunzinger, A., Guggenbühl, W., Fast neural net simulation with a DSP processor array (1995) IEEE Transactions on Neural Networks, 6 (1), pp. 203-213; Munro, P.W., A dual back-propagation scheme for scalar reinforcement learning (1987) Proceedings of the ninth annual conference of the cognitive science society, pp. 165-176; Murray, A.F., Edwards, P.J., Synaptic weight noise during MLP learning enhances fault-tolerance, generalisation and learning trajectory (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 491-498. , Morgan Kaufmann, San Mateo, CA, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Nadal, J.-P., Parga, N., Non-linear neurons in the low noise limit: a factorial code maximises information transfer (1994) Networks,5, pp. 565-581; Nagumo, J., Arimoto, S., Yoshizawa, S., An active pulse transmission line simulating nerve axon (1962) Proceedings of the IRE, 50 (10), pp. 2061-2070; Nair, V., Hinton, G.E., Rectified linear units improve restricted Boltzmann machines (2010) International conference on machine learning.; Narendra, K.S., Parthasarathy, K., Identification and control of dynamical systems using neural networks (1990) IEEE Transactions on Neural Networks, 1 (1), pp. 4-27; Narendra, K.S., Thathatchar, M.A.L., Learning automata-a survey (1974) IEEE Transactions on Systems, Man and Cybernetics,4, pp. 323-334; Neal, R.M., (1995) Bayesian learning for neural networks, , (Ph.D. thesis), University of Toronto; Neal, R.M., Classification with Bayesian neural networks (2006) Lecture notes in computer science,3944, pp. 28-32. , Springer, J. Quinonero-Candela, B. Magnini, I. Dagan, F. D'Alche-Buc (Eds.) Machine learning challenges. Evaluating predictive uncertainty, visual object classification, and recognising textual entailment; Neal, R.M., Zhang, J., High dimensional classification with Bayesian neural networks and Dirichlet diffusion trees (2006) Studies in fuzziness and soft computing, pp. 265-295. , Springer, I. Guyon, S. Gunn, M. Nikravesh, L.A. Zadeh (Eds.) Feature extraction: foundations and applications; Neftci, E., Das, S., Pedroni, B., Kreutz-Delgado, K., Cauwenberghs, G., Event-driven contrastive divergence for spiking neuromorphic systems (2014) Frontiers in Neuroscience, 7 (272); Neil, D., Liu, S.-C., Minitaur, an event-driven FPGA-based spiking network accelerator (2014) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, PP (99), pp. 1-8; Nessler, B., Pfeiffer, M., Buesing, L., Maass, W., Bayesian computation emerges in generic cortical microcircuits through spike-timing-dependent plasticity (2013) PLoS Computational Biology, 9 (4), p. e1003037; Neti, C., Schneider, M.H., Young, E.D., Maximally fault tolerant neural networks (1992) IEEE Transactions on Neural Networks,3, pp. 14-23; Neuneier, R., Zimmermann, H.-G., How to train neural networks (1996) Lecture notes in computer science,1524, pp. 373-423. , Springer, G.B. Orr, K.-R. Müller (Eds.) Neural networks: tricks of the trade; Newton, I., (1687) Philosophiae naturalis principia mathematica, , William Dawson & Sons Ltd, London; Nguyen, N., Widrow, B., The truck backer-upper: An example of self learning in neural networks (1989) Proceedings of the international joint conference on neural networks, pp. 357-363. , IEEE Press; Nilsson, N.J., (1980) Principles of artificial intelligence, , Morgan Kaufmann, San Francisco, CA, USA; Nolfi, S., Floreano, D., Miglino, O., Mondada, F., How to evolve autonomous robots: Different approaches in evolutionary robotics (1994) Fourth international workshop on the synthesis and simulation of living systems (artificial life IV), pp. 190-197. , MIT, R.A. Brooks, P. Maes (Eds.); Nolfi, S., Parisi, D., Elman, J.L., Learning and evolution in neural networks (1994) Adaptive Behavior, 3 (1), pp. 5-28; Nowak, E., Jurie, F., Triggs, B., Sampling strategies for bag-of-features image classification (2006) Proc. ECCV 2006, pp. 490-503. , Springer; Nowlan, S.J., Hinton, G.E., Simplifying neural networks by soft weight sharing (1992) Neural Computation,4, pp. 173-193; O'Connor, P., Neil, D., Liu, S.-C., Delbruck, T., Pfeiffer, M., Real-time classification and sensor fusion with a spiking deep belief network (2013) Frontiers in Neuroscience, 7 (178); Oh, K.-S., Jung, K., GPU implementation of neural networks (2004) Pattern Recognition, 37 (6), pp. 1311-1314; Oja, E., Neural networks, principal components, and subspaces (1989) International Journal of Neural Systems, 1 (1), pp. 61-68; Oja, E., Data compression, feature extraction, and autoassociation in feedforward neural networks (1991) Artificial neural networks, vol. 1, pp. 737-745. , Elsevier Science Publishers BV, North-Holland, T. Kohonen, K. Mäkisara, O. Simula, J. Kangas (Eds.); Olshausen, B.A., Field, D.J., Emergence of simple-cell receptive field properties by learning a sparse code for natural images (1996) Nature, 381 (6583), pp. 607-609; Omlin, C., Giles, C.L., Extraction of rules from discrete-time recurrent neural networks (1996) Neural Networks, 9 (1), pp. 41-52; Oquab, M., Bottou, L., Laptev, I., Sivic, J., (2013) Learning and transferring mid-level image representations using convolutional neural networks. Technical report hal-00911179; O'Reilly, R.C., Biologically plausible error-driven learning using local activation differences: The generalized recirculation algorithm (1996) Neural Computation, 8 (5), pp. 895-938; O'Reilly, R., (2003) Making working memory work: A computational model of learning in the prefrontal cortex and basal ganglia. Technical report ICS-03-03, , ICS; O'Reilly, R.C., Wyatte, D., Herd, S., Mingus, B., Jilk, D.J., Recurrent processing during object recognition (2013) Frontiers in Psychology,4, p. 124; Orr, G., Müller, K., Neural networks: tricks of the trade (1998) Lecture Notes in Computer Science Series. LNCS,1524, Springer Verlag; Ostrovskii, G.M., Volin, Y.M., Borisov, W.W., Über die Berechnung von Ableitungen (1971) Wissenschaftliche Zeitschrift der Technischen Hochschule für Chemie,13, pp. 382-384; Otsuka, M., (2010) Goal-oriented representation of the external world: a free-energy-based approach, , (Ph.D. thesis), Nara Institute of Science and Technology; Otsuka, M., Yoshimoto, J., Doya, K., Free-energy-based reinforcement learning in a partially observable environment (2010) Proc. ESANN.; Otte, S., Krechel, D., Liwicki, M., Dengel, A., Local feature based online mode detection with recurrent neural networks (2012) Proceedings of the 2012 international conference on Frontiers in handwriting recognition, pp. 533-537. , IEEE Computer Society; Oudeyer, P.-Y., Baranes, A., Kaplan, F., Intrinsically motivated learning of real world sensorimotor skills with developmental constraints (2013) Intrinsically motivated learning in natural and artificial systems, , Springer, G. Baldassarre, M. Mirolli (Eds.); Pachitariu, M., Sahani, M., Regularization and nonlinearities for neural language models: when are they needed? (2013), arxiv:1301.5650, arXiv Preprint ; Palm, G., On associative memory (1980) Biological Cybernetics, 36; Palm, G., On the information storage capacity of local learning rules (1992) Neural Computation, 4 (2), pp. 703-711; Pan, S.J., Yang, Q., A survey on transfer learning (2010) The IEEE Transactions on Knowledge and Data Engineering, 22 (10), pp. 1345-1359; Parekh, R., Yang, J., Honavar, V., Constructive neural network learning algorithms for multi-category pattern classification (2000) IEEE Transactions on Neural Networks, 11 (2), pp. 436-451; Parker, D.B., (1985) Learning-logic. Technical report TR-47, , Center for Comp. Research in Economics and Management Sci., MIT; Pascanu, R., Gulcehre, C., Cho, K., Bengio, Y., How to construct deep recurrent neural networks (2013), arxiv:1312.6026, arXiv Preprint ; Pascanu, R., Mikolov, T., Bengio, Y., On the difficulty of training recurrent neural networks (2013) ICML'13: JMLR: W&CP, 28; Pasemann, F., Steinmetz, U., Dieckman, U., Evolving structure and function of neurocontrollers (1999) Proceedings of the congress on evolutionary computation, vol. 3, pp. 1973-1978. , IEEE Press, Mayflower Hotel, Washington, DC, USA, P.J. Angeline, Z. Michalewicz, M. Schoenauer, X. Yao, A. Zalzala (Eds.); Pearlmutter, B.A., Learning state space trajectories in recurrent neural networks (1989) Neural Computation, 1 (2), pp. 263-269; Pearlmutter, B.A., Fast exact multiplication by the Hessian (1994) Neural Computation, 6 (1), pp. 147-160; Pearlmutter, B.A., Gradient calculations for dynamic recurrent neural networks: A survey (1995) IEEE Transactions on Neural Networks, 6 (5), pp. 1212-1228; Pearlmutter, B.A., Hinton, G.E., G-maximization: An unsupervised learning procedure for discovering regularities (1986) Neural networks for computing: American institute of physics conference proceedings 151,2, pp. 333-338. , In Denker, J.S., (Ed.); Peng, J., Williams, R.J., Incremental multi-step Q-learning (1996) Machine Learning,22, pp. 283-290; Pérez-Ortiz, J.A., Gers, F.A., Eck, D., Schmidhuber, J., Kalman filters improve LSTM network performance in problems unsolvable by traditional recurrent nets (2003) Neural Networks,-16, pp. 241-250; Perrett, D., Hietanen, J., Oram, M., Benson, P., Rolls, E., Organization and functions of cells responsive to faces in the temporal cortex [and discussion] (1992) Philosophical Transactions of the Royal Society of London. Series B: Biological Sciences, 335 (1273), pp. 23-30; Perrett, D., Rolls, E., Caan, W., Visual neurones responsive to faces in the monkey temporal cortex (1982) Experimental Brain Research, 47 (3), pp. 329-342; Peters, J., Policy gradient methods (2010) Scholarpedia, 5 (11), p. 3698; Peters, J., Schaal, S., Natural actor-critic (2008) Neurocomputing,71, pp. 1180-1190; Peters, J., Schaal, S., Reinforcement learning of motor skills with policy gradients (2008) Neural Networks, 21 (4), pp. 682-697; Pham, V., Kermorvant, C., Louradour, J., Dropout improves recurrent neural networks for handwriting recognition (2013), arxiv:1312.4569, arXiv Preprint ; Pineda, F.J., Generalization of back-propagation to recurrent neural networks (1987) Physical Review Letters, 19 (59), pp. 2229-2232; Plate, T.A., Holographic recurrent networks (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 34-41. , Morgan Kaufmann, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Plumbley, M.D., (1991) On information theory and unsupervised neural networks. Dissertation, published as Technical report CUED/F-INFENG/TR.78, , Engineering Department, Cambridge University; Pollack, J.B., Implications of recursive distributed representations (1988) Proc. NIPS, pp. 527-536; Pollack, J.B., Recursive distributed representation (1990) Artificial Intelligence,46, pp. 77-105; Pontryagin, L.S., Boltyanskii, V.G., Gamrelidze, R.V., Mishchenko, E.F., (1961) The mathematical theory of optimal processes; Poon, H., Domingos, P., Sum-product networks: A new deep architecture (2011) IEEE International conference on computer vision workshops, pp. 689-690. , IEEE; Post, E.L., Finite combinatory processes-formulation 1 (1936) The Journal of Symbolic Logic, 1 (3), pp. 103-105; Prasoon, A., Petersen, K., Igel, C., Lauze, F., Dam, E., Nielsen, M., Voxel classification based on triplanar convolutional neural networks applied to cartilage segmentation in knee MRI (2013) LNCS,8150, pp. 246-253. , Springer, Medical image computing and computer assisted intervention (MICCAI); Precup, D., Sutton, R.S., Singh, S., Multi-time models for temporally abstract planning (1998) Advances in neural information processing systems (NIPS), pp. 1050-1056. , Morgan Kaufmann; Prokhorov, D., A convolutional learning system for object classification in 3-D LIDAR data (2010) IEEE Transactions on Neural Networks, 21 (5), pp. 858-863; Prokhorov, D.V., Feldkamp, L.A., Tyukin, I.Y., Adaptive behavior with fixed weights in RNN: an overview (2002) Proceedings of the IEEE international joint conference on neural networks, pp. 2018-2023; Prokhorov, D., Puskorius, G., Feldkamp, L., Dynamical neural networks for control (2001) A field guide to dynamical recurrent networks, pp. 23-78. , IEEE Press, J. Kolen, S. Kremer (Eds.); Prokhorov, D., Wunsch, D., Adaptive critic design (1997) IEEE Transactions on Neural Networks, 8 (5), pp. 997-1007; Puskorius, G.V., Feldkamp, L.A., Neurocontrol of nonlinear dynamical systems with Kalman filter trained recurrent networks (1994) IEEE Transactions on Neural Networks, 5 (2), pp. 279-297; Raiko, T., Valpola, H., LeCun, Y., Deep learning made easier by linear transformations in perceptrons (2012) International conference on artificial intelligence and statistics, pp. 924-932; Raina, R., Madhavan, A., Ng, A., Large-scale deep unsupervised learning using graphics processors (2009) Proceedings of the 26th annual International conference on machine learning, pp. 873-880. , ACM; Ramacher, U., Raab, W., Anlauf, J., Hachmann, U., Beichter, J., Bruels, N., Multiprocessor and memory architecture of the neurocomputer SYNAPSE-1 (1993) International Journal of Neural Systems, 4 (4), pp. 333-336; Ranzato, M.A., Huang, F., Boureau, Y., LeCun, Y., Unsupervised learning of invariant feature hierarchies with applications to object recognition (2007) Proc. computer vision and pattern recognition conference, pp. 1-8. , IEEE Press; Ranzato, M., Poultney, C., Chopra, S., LeCun, Y., Efficient learning of sparse representations with an energy-based model (2006) Advances in neural information processing systems (NIPS 2006), , MIT Press, J. Platt (Ed.); Rauber, A., Merkl, D., Dittenbach, M., The growing hierarchical self-organizing map: exploratory analysis of high-dimensional data (2002) IEEE Transactions on Neural Networks, 13 (6), pp. 1331-1341; Razavian, A.S., Azizpour, H., Sullivan, J., Carlsson, S., CNN features off-the-shelf: an astounding baseline for recognition (2014), arxiv:1403.6382, ArXiv Preprint ; Rechenberg, I., (1971) Evolutionsstrategie-optimierung technischer systeme nach prinzipien der biologischen evolution, , (Dissertation), Published 1973 by Fromman-Holzboog; Redlich, A.N., Redundancy reduction as a strategy for unsupervised learning (1993) Neural Computation,5, pp. 289-304; Refenes, N.A., Zapranis, A., Francis, G., Stock performance modeling using neural networks: a comparative study with regression models (1994) Neural Networks, 7 (2), pp. 375-388; Rezende, D.J., Gerstner, W., Stochastic variational learning in recurrent spiking networks (2014) Frontiers in Computational Neuroscience,8, p. 38; Riedmiller, M., Neural fitted Q iteration-first experiences with a data efficient neural reinforcement learning method (2005) Proc. ECML-2005, pp. 317-328. , Springer-Verlag, Berlin, Heidelberg; Riedmiller, M., Braun, H., A direct adaptive method for faster backpropagation learning: The Rprop algorithm (1993) Proc. IJCNN, pp. 586-591. , IEEE Press; Riedmiller, M., Lange, S., Voigtlaender, A., Autonomous reinforcement learning on raw visual input data in a real world application (2012) International joint conference on neural networks, pp. 1-8; Riesenhuber, M., Poggio, T., Hierarchical models of object recognition in cortex (1999) Nature Neuroscience, 2 (11), pp. 1019-1025; Rifai, S., Vincent, P., Muller, X., Glorot, X., Bengio, Y., Contractive auto-encoders: Explicit invariance during feature extraction (2011) Proceedings of the 28th international conference on machine learning, pp. 833-840; Ring, M.B., Incremental development of complex behaviors through automatic construction of sensory-motor hierarchies (1991) Machine learning: proceedings of the eighth international workshop, pp. 343-347. , Morgan Kaufmann, L. Birnbaum, G. Collins (Eds.); Ring, M.B., Learning sequential tasks by incrementally adding higher orders (1993) Advances in neural information processing systems, vol. 5, pp. 115-122. , Morgan Kaufmann, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Ring, M.B., (1994) Continual learning in reinforcement environments, , (Ph.D. thesis), University of Texas at Austin, Austin, Texas 78712; Ring, M., Schaul, T., Schmidhuber, J., The two-dimensional organization of behavior (2011) Proceedings of the first joint conference on development learning and on epigenetic robotics.; Risi, S., Stanley, K.O., A unified approach to evolving plasticity and neural geometry (2012) International joint conference on neural networks, pp. 1-8. , IEEE; Rissanen, J., Stochastic complexity and modeling (1986) The Annals of Statistics, 14 (3), pp. 1080-1100; Ritter, H., Kohonen, T., Self-organizing semantic maps (1989) Biological Cybernetics, 61 (4), pp. 241-254; Robinson, A.J., Fallside, F., (1987) The utility driven dynamic error propagation network. Technical report CUED/F-INFENG/TR.1, , Cambridge University Engineering Department; Robinson, T., Fallside, F., Dynamic reinforcement driven error propagation networks with application to game playing (1989) Proceedings of the 11th conference of the cognitive science society, pp. 836-843; Rodriguez, P., Wiles, J., Recurrent neural networks can learn to implement symbol-sensitive counting (1998) Advances in neural information processing systems (NIPS), vol. 10, pp. 87-93. , The MIT Press; Rodriguez, P., Wiles, J., Elman, J., A recurrent neural network that learns to count (1999) Connection Science, 11 (1), pp. 5-40; Roggen, D., Hofmann, S., Thoma, Y., Floreano, D., Hardware spiking neural network with run-time reconfigurable connectivity in an autonomous robot (2003) Proc. NASA/DoD conference on evolvable hardware, pp. 189-198. , IEEE; Rohwer, R., The 'moving targets' training method (1989) Proceedings of 'distributed adaptive neural information processing', , Oldenbourg, J. Kindermann, A. Linden (Eds.); Rosenblatt, F., The perceptron: a probabilistic model for information storage and organization in the brain (1958) Psychological Review, 65 (6), p. 386; Rosenblatt, F., (1962) Principles of neurodynamics, , Spartan, New York; Roux, L., Racoceanu, D., Lomenie, N., Kulikova, M., Irshad, H., Klossa, J., Mitosis detection in breast cancer histological images-an ICPR 2012 contest (2013) Journal of Pathology Informatics,4, p. 8; Rubner, J., Schulten, K., Development of feature detectors by self-organization: A network model (1990) Biological Cybernetics,62, pp. 193-199; Rückstieß, T., Felder, M., Schmidhuber, J., State-dependent exploration for policy gradient methods (2008) LNAI,5212, pp. 234-249. , W. Daelemans (Ed.) European conference on machine learning (ECML) and principles and practice of knowledge discovery in databases 2008, part II; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning internal representations by error propagation (1986) Parallel distributed processing, vol. 1, pp. 318-362. , MIT Press, D.E. Rumelhart, J.L. McClelland (Eds.); Rumelhart, D.E., Zipser, D., Feature discovery by competitive learning (1986) Parallel distributed processing, pp. 151-193. , MIT Press; Rummery, G., Niranjan, M., (1994) On-line Q-learning using connectionist sytems. Technical report CUED/F-INFENG-TR 166, , Cambridge University, UK; Russell, S.J., Norvig, P., Canny, J.F., Malik, J.M., Edwards, D.D., (1995) Artificial intelligence: a modern approach, vol. 2, , Prentice Hall, Englewood Cliffs; Saito, K., Nakano, R., Partial BFGS update and efficient step-length calculation for three-layer neural networks (1997) Neural Computation, 9 (1), pp. 123-141; Sak, H., Senior, A., Beaufays, F., Long short-term memory recurrent neural network architectures for large scale acoustic modeling (2014) Proc. interspeech.; Sak, H., Vinyals, O., Heigold, G., Senior, A., McDermott, E., Monga, R., Sequence discriminative distributed training of long short-term memory recurrent neural networks (2014) Proc. Interspeech.; Salakhutdinov, R., Hinton, G., Semantic hashing (2009) International Journal of Approximate Reasoning, 50 (7), pp. 969-978; Sallans, B., Hinton, G., Reinforcement learning with factored states and actions (2004) Journal of Machine Learning Research,5, pp. 1063-1088; Sałustowicz, R.P., Schmidhuber, J., Probabilistic incremental program evolution (1997) Evolutionary Computation, 5 (2), pp. 123-141; Samejima, K., Doya, K., Kawato, M., Inter-module credit assignment in modular reinforcement learning (2003) Neural Networks, 16 (7), pp. 985-994; Samuel, A.L., Some studies in machine learning using the game of checkers (1959) IBM Journal of Research and Development,3, pp. 210-229; Sanger, T.D., An optimality principle for unsupervised learning (1989) Advances in neural information processing systems (NIPS), vol. 1, pp. 11-19. , Morgan Kaufmann, D.S. Touretzky (Ed.); Santamaría, J.C., Sutton, R.S., Ram, A., Experiments with reinforcement learning in problems with continuous state and action spaces (1997) Adaptive Behavior, 6 (2), pp. 163-217; Saravanan, N., Fogel, D.B., Evolving neural control systems (1995) IEEE Expert, pp. 23-27; Saund, E., Unsupervised learning of mixtures of multiple causes in binary data (1994) Advances in neural information processing systems (NIPS), vol. 6, pp. 27-34. , Morgan Kaufmann, J.D. Cowan, G. Tesauro, J. Alspector (Eds.); Schaback, R., Werner, H., (1992) Numerische mathematik, vol. 4, , Springer; Schäfer, A.M., Udluft, S., Zimmermann, H.-G., Learning long term dependencies with recurrent neural networks (2006) Lecture notes in computer science,4131, pp. 71-80. , Springer, S.D. Kollias, A. Stafylopatis, W. Duch, E. Oja (Eds.) ICANN (1); Schapire, R.E., The strength of weak learnability (1990) Machine Learning,5, pp. 197-227; Schaul, T., Schmidhuber, J., Metalearning (2010) Scholarpedia, 6 (5), p. 4650; Schaul, T., Zhang, S., LeCun, Y., No more pesky learning rates (2013) Proc. 30th International conference on machine learning.; Schemmel, J., Grubl, A., Meier, K., Mueller, E., Implementing synaptic plasticity in a VLSI spiking neural network model (2006) International joint conference on neural networks, pp. 1-6. , IEEE; Scherer, D., Müller, A., Behnke, S., Evaluation of pooling operations in convolutional architectures for object recognition (2010) Proc. International conference on artificial neural networks, pp. 92-101; Schmidhuber, J., (1987) Evolutionary principles in self-referential learning, or on learning how to learn: the meta-meta-... hook, , http://www.idsia.ch/~juergen/diploma.html, (Diploma thesis), Inst. f. Inf., Tech. Univ. Munich; Schmidhuber, J., Accelerated learning in back-propagation nets (1989) Connectionism in perspective, pp. 429-438. , Elsevier, North-Holland, Amsterdam, R. Pfeifer, Z. Schreter, Z. Fogelman, L. Steels (Eds.); Schmidhuber, J., A local learning algorithm for dynamic feedforward and recurrent networks (1989) Connection Science, 1 (4), pp. 403-412; Schmidhuber, J., (1990) Dynamische neuronale Netze und das fundamentale raumzeitliche Lernproblem. (Dynamic neural nets and the fundamental spatio-temporal credit assignment problem.), , (Dissertation), Inst. f. Inf., Tech. Univ. Munich; Schmidhuber, J., Learning algorithms for networks with internal and external feedback (1990) Proc. of the 1990 connectionist models summer school, pp. 52-61. , Morgan Kaufmann, D.S. Touretzky, J.L. Elman, T.J. Sejnowski, G.E. Hinton (Eds.); Schmidhuber, J., The neural heat exchanger. Talks at TU Munich (1990) (1990) Also published at the Intl. conference on neural information processing 1996.,1, pp. 194-197. , University of Colorado at Boulder (1992), and Z. Li's NIPS*94 workshop on unsupervised learning; Schmidhuber, J. (1990d). An on-line algorithm for dynamic reinforcement learning and planning in reactive environments. In Proc. IEEE/INNS international joint conference on neural networks, vol. 2 (pp. 253-258); Schmidhuber, J., Curious model-building control systems (1991) Proceedings of the international joint conference on neural networks, vol. 2, pp. 1458-1463. , IEEE Press; Schmidhuber, J., Learning to generate sub-goals for action sequences (1991) Artificial neural networks, pp. 967-972. , Elsevier Science Publishers BV, North-Holland, T. Kohonen, K. Mäkisara, O. Simula, J. Kangas (Eds.); Schmidhuber, J., Reinforcement learning in Markovian and non-Markovian environments (1991) Advances in neural information processing systems, vol. 3 (NIPS 3), pp. 500-506. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Schmidhuber, J., A fixed size storage O(n3) time complexity learning algorithm for fully recurrent continually running networks (1992) Neural Computation, 4 (2), pp. 243-248; Schmidhuber, J., Learning complex, extended sequences using the principle of history compression (1992) Neural Computation, 4 (2), pp. 234-242. , Based on TR FKI-148-91, TUM, 1991; Schmidhuber, J., Learning factorial codes by predictability minimization (1992) Neural Computation, 4 (6), pp. 863-879; Schmidhuber, J., An introspective network that can learn to run its own weight change algorithm (1993) Proc. of the intl. conf. on artificial neural networks, Brighton, pp. 191-195. , IEE; Schmidhuber, J., (1993) Netzwerkarchitekturen, Zielfunktionen und Kettenregel. (Network architectures, objective functions, and chain rule.), , (Habilitation thesis), Inst. f. Inf., Tech. Univ. Munich; Schmidhuber, J., Discovering neural nets with low Kolmogorov complexity and high generalization capability (1997) Neural Networks, 10 (5), pp. 857-873; Schmidhuber, J., The speed prior: a new simplicity measure yielding near-optimal computable predictions (2002) Lecture notes in artificial intelligence, pp. 216-228. , Springer, Sydney, Australia, J. Kivinen, R.H. Sloan (Eds.) Proceedings of the 15th annual conference on computational learning theory; Schmidhuber, J., Optimal ordered problem solver (2004) Machine Learning,54, pp. 211-254; Schmidhuber, J., Developmental robotics, optimal artificial curiosity, creativity, music, and the fine arts (2006) Connection Science, 18 (2), pp. 173-187; Schmidhuber, J., Gödel machines: Fully self-referential optimal universal self-improvers (2006) Artificial general intelligence, pp. 199-226. , Springer Verlag, Variant available as arXiv:cs.LO/0309048, B. Goertzel, C. Pennachin (Eds.); Schmidhuber, J., Prototype resilient, self-modeling robots (2007) Science, 316 (5825), p. 688; Schmidhuber, J., (2012) Self-delimiting neural networks. Technical report IDSIA-08-12, , The Swiss AI Lab IDSIA, arXiv:1210.0118v1 [cs.NE]; Schmidhuber, J., (2013) My first deep learning system of 1991 + deep learning timeline 1962-2013. Technical report, , The Swiss AI Lab IDSIA, arXiv:1312.5548v1 [cs.NE]; Schmidhuber, J., PowerPlay: training an increasingly general problem solver by continually searching for the simplest still unsolvable problem (2013) Frontiers in Psychology; Schmidhuber, J., Ciresan, D., Meier, U., Masci, J., Graves, A., On fast deep nets for AGI vision (2011) Proc. fourth conference on artificial general intelligence, pp. 243-246; Schmidhuber, J., Eldracher, M., Foltin, B., Semilinear predictability minimization produces well-known feature detectors (1996) Neural Computation, 8 (4), pp. 773-786; Schmidhuber, J., Huber, R., Learning to generate artificial fovea trajectories for target detection (1991) International Journal of Neural Systems, 2 (1-2), pp. 135-141; Schmidhuber, J., Mozer, M.C., Prelinger, D., Continuous history compression (1993) Proc. of intl. workshop on neural networks, pp. 87-95. , RWTH Aachen, Augustinus, H. Hüning, S. Neuhauser, M. Raus, W. Ritschel (Eds.); Schmidhuber, J., Prelinger, D., (1992) Discovering predictable classifications. Technical report CU-CS-626-92, , Dept. of Comp. Sci., University of Colorado at Boulder, Published in Neural Computation 5 (4) (1993) 625-635; Schmidhuber, J., Wahnsiedler, R., Planning simple trajectories using neural subgoal generators (1992) Proc. of the 2nd international conference on simulation of adaptive behavior, pp. 196-202. , MIT Press, J.A. Meyer, H.L. Roitblat, S.W. Wilson (Eds.); Schmidhuber, J., Wierstra, D., Gagliolo, M., Gomez, F.J., Training recurrent networks by Evolino (2007) Neural Computation, 19 (3), pp. 757-779; Schmidhuber, J., Zhao, J., Schraudolph, N., Reinforcement learning with self-modifying policies (1997) Learning to learn, pp. 293-309. , Kluwer, S. Thrun, L. Pratt (Eds.); Schmidhuber, J., Zhao, J., Wiering, M., Shifting inductive bias with success-story algorithm, adaptive Levin search, and incremental self-improvement (1997) Machine Learning,28, pp. 105-130; (1998) Advances in kernel methods-support vector learning, , MIT Press, Cambridge, MA, B. Schölkopf, C.J.C. Burges, A.J. Smola (Eds.); Schraudolph, N.N., Fast curvature matrix-vector products for second-order gradient descent (2002) Neural Computation, 14 (7), pp. 1723-1738; Schraudolph, N., Sejnowski, T.J., Unsupervised discrimination of clustered data via optimization of binary information gain (1993) Advances in neural information processing systems, vol. 5, pp. 499-506. , Morgan Kaufmann, San Mateo, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Schraudolph, N.N., Sejnowski, T.J., Tempering backpropagation networks: not all weights are created equal (1996) Advances in neural information processing systems (NIPS), vol. 8, pp. 563-569. , The MIT Press, Cambridge, MA, D.S. Touretzky, M.C. Mozer, M.E. Hasselmo (Eds.); Schrauwen, B., Verstraeten, D., Van Campenhout, J., An overview of reservoir computing: theory, applications and implementations (2007) Proceedings of the 15th European symposium on artificial neural networks, pp. 471-482; Schuster, H.G.," Learning by maximization the information transfer through nonlinear noisy neurons and """"noise breakdown"""" (1992) Physical Review A", 46 (4), pp. 2131-2138; Schuster, M., (1999) On supervised learning from sequential data with applications for speech recognition, , (Ph.D. thesis), Nara Institute of Science and Technolog, Kyoto, Japan; Schuster, M., Paliwal, K.K., Bidirectional recurrent neural networks (1997) IEEE Transactions on Signal Processing,45, pp. 2673-2681; Schwartz, A., A reinforcement learning method for maximizing undiscounted rewards (1993) Proc. ICML, pp. 298-305; Schwefel, H.P., (1974) Numerische optimierung von computer-modellen, , (Dissertation), Published 1977 by Birkhäuser, Basel; (2012), http://tinyurl.com/d2fgh7g, IEEE International symposium on biomedical imaging; Sehnke, F., Osendorfer, C., Rückstieß, T., Graves, A., Peters, J., Schmidhuber, J., Parameter-exploring policy gradients (2010) Neural Networks, 23 (4), pp. 551-559; Sermanet, P., Eigen, D., Zhang, X., Mathieu, M., Fergus, R., LeCun, Y., OverFeat: integrated recognition, localization and detection using convolutional networks (2013), arxiv:1312.6229, ArXiv Preprint ; Sermanet, P., LeCun, Y., Traffic sign recognition with multi-scale convolutional networks (2011) Proceedings of international joint conference on neural networks, pp. 2809-2813; Serrano-Gotarredona, R., Oster, M., Lichtsteiner, P., Linares-Barranco, A., Paz-Vicente, R., Gómez-Rodríguez, F., Caviar: A 45 k neuron, 5 m synapse, 12 g connects/s AER hardware sensory-processing-learning-actuating system for high-speed visual object recognition and tracking (2009) IEEE Transactions on Neural Networks, 20 (9), pp. 1417-1438; Serre, T., Riesenhuber, M., Louie, J., Poggio, T., On the role of object-specific features for real world object recognition in biological vision (2002) Biologically motivated computer vision, pp. 387-397; Seung, H.S., Learning in spiking neural networks by reinforcement of stochastic synaptic transmission (2003) Neuron, 40 (6), pp. 1063-1073; Shan, H., Cottrell, G., Efficient visual coding: From retina to V2 (2014) Proc. international conference on learning representations, , arxiv:1312.6077, ArXiv Preprint ; Shan, H., Zhang, L., Cottrell, G.W., Recursive ICA (2007) Advances in neural information processing systems (NIPS), vol. 19, p. 1273; Shanno, D.F., Conditioning of quasi-Newton methods for function minimization (1970) Mathematics of Computation, 24 (111), pp. 647-656; Shannon, C.E., A mathematical theory of communication (parts I and II) (1948) Bell System Technical Journal, XXVII, pp. 379-423; Shao, L., Wu, D., Li, X., Learning deep and wide: A spectral method for learning deep networks (2014) IEEE Transactions on Neural Networks and Learning Systems; Shavlik, J.W., Combining symbolic and neural learning (1994) Machine Learning, 14 (3), pp. 321-331; Shavlik, J.W., Towell, G.G., Combining explanation-based and neural learning: An algorithm and empirical results (1989) Connection Science, 1 (3), pp. 233-255; Siegelmann, H., (1992) Theoretical foundations of recurrent neural networks, , (Ph.D. thesis), Rutgers, New Brunswick Rutgers, The State of New Jersey; Siegelmann, H.T., Sontag, E.D., Turing computability with neural nets (1991) Applied Mathematics Letters, 4 (6), pp. 77-80; Silva, F.M., Almeida, L.B., Speeding up back-propagation (1990) Advanced neural computers, pp. 151-158. , Elsevier, Amsterdam, R. Eckmiller (Ed.); Síma, J., Loading deep networks is hard (1994) Neural Computation, 6 (5), pp. 842-850; Síma, J., Training a single sigmoidal neuron is hard (2002) Neural Computation, 14 (11), pp. 2709-2728; Simard, P., Steinkraus, D., Platt, J., Best practices for convolutional neural networks applied to visual document analysis (2003) Seventh international conference on document analysis and recognition, pp. 958-963; Sims, K., Evolving virtual creatures (1994) ACM SIGGRAPH, pp. 15-22. , ACM Press, A. Glassner (Ed.) Proceedings of SIGGRAPH '94, computer graphics proceedings, annual conference; Simsek, Ö., Barto, A.G., Skill characterization based on betweenness (2008), pp. 1497-1504. , In NIPS'08; Singh, S.P., Reinforcement learning algorithms for average-payoff Markovian decision processes (1994) National conference on artificial intelligence, pp. 700-705; Singh, S., Barto, A.G., Chentanez, N., Intrinsically motivated reinforcement learning (2005) Advances in neural information processing systems, vol. 17 (NIPS), , MIT Press, Cambridge, MA; Smith, S.F., (1980) A learning system based on genetic adaptive algorithms, , (Ph.D. thesis), Univ. Pittsburgh; Smolensky, P., Parallel distributed processing: Explorations in the microstructure of cognition (1986) Information processing in dynamical systems: foundations of harmony theory, vol. 1, pp. 194-281. , MIT Press, Cambridge, MA, USA, (Chapter); Solla, S.A., Accelerated learning in layered neural networks (1988) Complex Systems,2, pp. 625-640; Solomonoff, R.J., A formal theory of inductive inference. Part I (1964) Information and Control,7, pp. 1-22; Solomonoff, R.J., Complexity-based induction systems (1978) IEEE Transactions on Information Theory, IT-24 (5), pp. 422-432; Soloway, E., Learning to program = learning to construct mechanisms and explanations (1986) Communications of the ACM, 29 (9), pp. 850-858; Song, S., Miller, K.D., Abbott, L.F., Competitive Hebbian learning through spike-timing-dependent synaptic plasticity (2000) Nature Neuroscience, 3 (9), pp. 919-926; Speelpenning, B., (1980) Compiling fast partial derivatives of functions given by algorithms, , (Ph.D. thesis), Department of Computer Science, University of Illinois, Urbana-Champaign; Srivastava, R.K., Masci, J., Kazerounian, S., Gomez, F., Schmidhuber, J., Compete to compute (2013) Advances in neural information processing systems (NIPS), pp. 2310-2318; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., The German traffic sign recognition benchmark: A multi-class classification competition (2011) International joint conference on neural networks, pp. 1453-1460. , IEEE Press; Stallkamp, J., Schlipsing, M., Salmen, J., Igel, C., Man vs. computer: benchmarking machine learning algorithms for traffic sign recognition (2012) Neural Networks,32, pp. 323-332; Stanley, K.O., D'Ambrosio, D.B., Gauci, J., A hypercube-based encoding for evolving large-scale neural networks (2009) Artificial Life, 15 (2), pp. 185-212; Stanley, K.O., Miikkulainen, R., Evolving neural networks through augmenting topologies (2002) Evolutionary Computation,10, pp. 99-127; Steijvers, M., Grunwald, P., A recurrent network that performs a contextsensitive prediction task (1996) Proceedings of the 18th annual conference of the cognitive science society, , Erlbaum; Steil, J.J., Online reservoir adaptation by intrinsic plasticity for backpropagation-decorrelation and echo state learning (2007) Neural Networks, 20 (3), pp. 353-364; Stemmler, M., A single spike suffices: the simplest form of stochastic resonance in model neurons (1996) Network: Computation in Neural Systems, 7 (4), pp. 687-716; Stoianov, I., Zorzi, M., Emergence of a 'visual number sense' in hierarchical generative models (2012) Nature Neuroscience, 15 (2), pp. 194-196; Stone, M., Cross-validatory choice and assessment of statistical predictions (1974) Journal of the Royal Statistical Society B,36, pp. 111-147; Stoop, R., Schindler, K., Bunimovich, L., When pyramidal neurons lock, when they respond chaotically, and when they like to synchronize (2000) Neuroscience Research, 36 (1), pp. 81-91; Stratonovich, R., Conditional Markov processes (1960) Theory of Probability and Its Applications, 5 (2), pp. 156-178; Sun, G., Chen, H., Lee, Y., Time warping invariant neural networks (1993) Advances in neural information processing systems (NIPS), vol. 5, pp. 180-187. , Morgan Kaufmann, S.J. Hanson, J.D. Cowan, C.L. Giles (Eds.); Sun, G.Z., Giles, C.L., Chen, H.H., Lee, Y.C., (1993) The neural network pushdown automaton: Model, stack and learning simulations. Technical report CS-TR-3118, , University of Maryland, College Park; Sun, Y., Gomez, F., Schaul, T., Schmidhuber, J., A linear time natural evolution strategy for non-separable functions (2013) Proceedings of the genetic and evolutionary computation conference, p. 61. , ACM, Amsterdam, NL; Sun, Y., Wierstra, D., Schaul, T., Schmidhuber, J., Efficient natural evolution strategies (2009) Proc. 11th genetic and evolutionary computation conference, pp. 539-546; Sutskever, I., Hinton, G.E., Taylor, G.W., The recurrent temporal restricted Boltzmann machine (2008),21, p. 2008. , In NIPS; Sutskever, I., Vinyals, O., Le, Q.V., (2014) Sequence to sequence learning with neural networks. Technical report, , arXiv:1409.3215 [cs.CL] Google. NIPS'2014; Sutton, R., Barto, A., (1998) Reinforcement learning: An introduction, , MIT Press, Cambridge, MA; Sutton, R.S., McAllester, D.A., Singh, S.P., Mansour, Y., Policy gradient methods for reinforcement learning with function approximation (1999) Advances in neural information processing systems (NIPS), vol. 12, pp. 1057-1063; Sutton, R.S., Precup, D., Singh, S.P., Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning (1999) Artificial Intelligence, 112 (1-2), pp. 181-211; Sutton, R.S., Szepesvári, C., Maei, H.R., A convergent O(n) algorithm for off-policy temporal-difference learning with linear function approximation (2008) Advances in neural information processing systems (NIPS'08), vol. 21, pp. 1609-1616; Szabó, Z., Póczos, B., Lorincz, A., Cross-entropy optimization for independent process analysis (2006) Independent component analysis and blind signal separation, pp. 909-916. , Springer; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., (2014) Going deeper with convolutions. Technical report, , arXiv:1409.4842 [cs.CV], Google; Szegedy, C., Toshev, A., Erhan, D., Deep neural networks for object detection (2013), pp. 2553-2561; Taylor, G.W., Spiro, I., Bregler, C., Fergus, R., Learning invariance through imitation (2011) Conference on computer vision and pattern recognition, pp. 2729-2736. , IEEE; Tegge, A.N., Wang, Z., Eickholt, J., Cheng, J., NNcon: improved protein contact map prediction using 2D-recursive neural networks (2009) Nucleic Acids Research,37, pp. W515-W518; Teichmann, M., Wiltschut, J., Hamker, F., Learning invariance from natural images inspired by observations in the primary visual cortex (2012) Neural Computation, 24 (5), pp. 1271-1296; Teller, A., The evolution of mental models (1994) Advances in genetic programming, pp. 199-219. , MIT Press, E. Kenneth, J. Kinnear (Eds.); Tenenberg, J., Karlsson, J., Whitehead, S., Learning via task decomposition (1993) From animals to animats 2: proceedings of the second international conference on simulation of adaptive behavior, pp. 337-343. , MIT Press, J.A. Meyer, H. Roitblat, S. Wilson (Eds.); Tesauro, G., TD-gammon, a self-teaching backgammon program, achieves master-level play (1994) Neural Computation, 6 (2), pp. 215-219; Tieleman, T., Hinton, G., Lecture 6.5-RmsProp: Divide the gradient by a running average of its recent magnitude (2012) COURSERA: Neural Networks for Machine Learning; Tikhonov, A.N., Arsenin, V.I., John, F., (1977) Solutions of ill-posed problems, , Winston; Ting, K.M., Witten, I.H., Stacked generalization: when does it work? (1997) Proc. international joint conference on artificial intelligence.; Tiňo, P., Hammer, B., Architectural bias in recurrent neural networks: Fractal analysis (2004) Neural Computation, 15 (8), pp. 1931-1957; Tonkes, B., Wiles, J., Learning a context-free task with a recurrent neural network: An analysis of stability (1997) Proceedings of the fourth Biennial conference of the Australasian cognitive science society.; Towell, G.G., Shavlik, J.W., Knowledge-based artificial neural networks (1994) Artificial Intelligence, 70 (1), pp. 119-165; Tsitsiklis, J.N., van Roy, B., Feature-based methods for large scale dynamic programming (1996) Machine Learning, 22 (1-3), pp. 59-94; Tsodyks, M., Pawelzik, K., Markram, H., Neural networks with dynamic synapses (1998) Neural Computation, 10 (4), pp. 821-835; Tsodyks, M.V., Skaggs, W.E., Sejnowski, T.J., McNaughton, B.L., Population dynamics and theta rhythm phase precession of hippocampal place cell firing: a spiking neuron model (1996) Hippocampus, 6 (3), pp. 271-280; Turaga, S.C., Murray, J.F., Jain, V., Roth, F., Helmstaedter, M., Briggman, K., Convolutional networks can learn to generate affinity graphs for image segmentation (2010) Neural Computation, 22 (2), pp. 511-538; Turing, A.M., On computable numbers, with an application to the Entscheidungsproblem (1936) Proceedings of the London Mathematical Society, Series 2,41, pp. 230-267; Turner, A.J., Miller, J.F., Cartesian genetic programming encoded artificial neural networks: A comparison using three benchmarks (2013) Proceedings of the conference on genetic and evolutionary computation, pp. 1005-1012. , GECCO; Ueda, N., Optimal linear combination of neural networks for improving classification performance (2000) IEEE Transactions on Pattern Analysis and Machine Intelligence, 22 (2), pp. 207-215; Urlbe, A.P., (1999) Structure-adaptable digital neural networks, , (Ph.D. thesis), Universidad del Valle; Utgoff, P.E., Stracuzzi, D.J., Many-layered learning (2002) Neural Computation, 14 (10), pp. 2497-2529; Vahed, A., Omlin, C.W., A machine learning method for extracting symbolic knowledge from recurrent neural networks (2004) Neural Computation, 16 (1), pp. 59-71; Vaillant, R., Monrocq, C., LeCun, Y., Original approach for the localisation of objects in images (1994) IEE Proceedings Vision, Image, and Signal Processing, 141 (4), pp. 245-250; van den Berg, T., Whiteson, S., Critical factors in the performance of HyperNEAT (2013) GECCO 2013: proceedings of the genetic and evolutionary computation conference, pp. 759-766; van Hasselt, H., Reinforcement learning in continuous state and action spaces (2012) Reinforcement learning, pp. 207-251. , Springer, M. Wiering, M. van Otterlo (Eds.); Vapnik, V., Principles of risk minimization for learning theory (1992) Advances in neural information processing systems (NIPS), vol. 4, pp. 831-838. , Morgan Kaufmann, D.S. Lippman, J.E. Moody, D.S. Touretzky (Eds.); Vapnik, V., (1995) The nature of statistical learning theory, , Springer, New York; Versino, C., Gambardella, L.M., Learning fine motion by using the hierarchical extended Kohonen map (1996) Proc. intl. conf. on artificial neural networks, pp. 221-226. , Springer; Veta, M., Viergever, M., Pluim, J., Stathonikos, N., van Diest, P.J.,-2013, MICCAI 2013 grand challenge on mitosis detection; Vieira, A., Barradas, N., A training algorithm for classification of high-dimensional data (2003) Neurocomputing,50, pp. 461-472; Viglione, S., Applications of pattern recognition technology (1970) Adaptive, learning, and pattern recognition systems, , Academic Press, J.M. Mendel, K.S. Fu (Eds.); Vincent, P., Hugo, L., Bengio, Y., Manzagol, P.-A., Extracting and composing robust features with denoising autoencoders (2008) Proceedings of the 25th international conference on Machine learning, pp. 1096-1103. , ACM, New York, NY, USA; Vlassis, N., Littman, M.L., Barber, D., On the computational complexity of stochastic controller optimization in POMDPs (2012) ACM Transactions on Computation Theory, 4 (4), p. 12; Vogl, T., Mangis, J., Rigler, A., Zink, W., Alkon, D., Accelerating the convergence of the back-propagation method (1988) Biological Cybernetics,59, pp. 257-263; von der Malsburg, C., Self-organization of orientation sensitive cells in the striate cortex (1973) Kybernetik, 14 (2), pp. 85-100; Waldinger, R.J., Lee, R.C.T., PROW: a step toward automatic program writing (1969) Proceedings of the 1st international joint conference on artificial intelligence, pp. 241-252. , Morgan Kaufmann, D.E. Walker, L.M. Norton (Eds.); Wallace, C.S., Boulton, D.M., An information theoretic measure for classification (1968) The Computer Journal, 11 (2), pp. 185-194; Wan, E.A., Time series prediction by using a connectionist network with internal delay lines (1994) Time series prediction: forecasting the future and understanding the past, pp. 265-295. , Addison-Wesley, A.S. Weigend, N.A. Gershenfeld (Eds.); Wang, S., Manning, C., Fast dropout training (2013) Proceedings of the 30th international conference on machine learning, pp. 118-126; Wang, C., Venkatesh, S.S., Judd, J.S., Optimal stopping and effective machine complexity in learning (1994) Advances in neural information processing systems (NIPS'6), pp. 303-310. , Morgan Kaufmann; Watanabe, S., (1985) Pattern recognition: human and mechanical, , Wiley, New York; Watanabe, O., Kolmogorov complexity and computational complexity (1992) EATCS monographs on theoretical computer science, , Springer; Watkins, C.J.C.H., (1989) Learning from delayed rewards, , (Ph.D. thesis), King's College, Oxford; Watkins, C.J.C.H., Dayan, P., Q-learning (1992) Machine Learning,8, pp. 279-292; Watrous, R.L., Kuhn, G.M., Induction of finite-state automata using second-order recurrent networks (1992) Advances in neural information processing systems, vol. 4, pp. 309-316. , Morgan Kaufmann, J.E. Moody, S.J. Hanson, R.P. Lippman (Eds.); Waydo, S., Koch, C., Unsupervised learning of individuals and categories from images (2008) Neural Computation, 20 (5), pp. 1165-1178; Weigend, A.S., Gershenfeld, N.A., Results of the time series prediction competition at the Santa Fe Institute (1993) Neural networks,1993, IEEE international conference on, pp. 1786-1793. , IEEE; Weigend, A.S., Rumelhart, D.E., Huberman, B.A., Generalization by weight-elimination with application to forecasting (1991) Advances in neural information processing systems (NIPS), vol. 3, pp. 875-882. , Morgan Kaufmann, San Mateo, CA, R.P. Lippmann, J.E. Moody, D.S. Touretzky (Eds.); Weiss, G., Hierarchical chunking in classifier systems (1994) Proceedings of the 12th national conference on artificial intelligence, vol. 2, pp. 1335-1340. , AAAI Press/The MIT Press; Weng, J., Ahuja, N., Huang, T.S., Cresceptron: a self-organizing neural network which grows adaptively (1992) International joint conference on neural networks, vol. 1, pp. 576-581. , IEEE; Weng, J.J., Ahuja, N., Huang, T.S., Learning recognition and segmentation using the cresceptron (1997) International Journal of Computer Vision, 25 (2), pp. 109-143; Werbos, P.J., (1974) Beyond regression: new tools for prediction and analysis in the behavioral sciences, , (Ph.D. thesis), Harvard University; Werbos, P.J., Applications of advances in nonlinear sensitivity analysis (1981) Proceedings of the 10th IFIP conference, pp. 762-770. , 31.8-4.9, NYC; Werbos, P.J., Building and understanding adaptive systems: A statistical/numerical approach to factory automation and brain research (1987) IEEE Transactions on Systems, Man and Cybernetics, 17; Werbos, P.J., Generalization of backpropagation with application to a recurrent gas market model (1988) Neural Networks, 1; Werbos, P.J., Backpropagation and neurocontrol: A review and prospectus (1989) IEEE/INNS International joint conference on neural networks,1, pp. 209-216; Werbos, P.J., Neural networks for control and system identification (1989) Proceedings of IEEE/CDC Tampa.; Werbos, P.J., Neural networks, system identification, and control in the chemical industries (1992) Handbook of intelligent control: neural, fuzzy, and adaptive approaches, pp. 283-356. , Thomson Learning, D.A. White, D.A. Sofge (Eds.); Werbos, P.J., Backwards differentiation in AD and neural nets: Past links and new opportunities (2006) Automatic differentiation: applications, theory, and implementations, pp. 15-34. , Springer; West, A.H.L., Saad, D., Adaptive back-propagation in on-line learning of multilayer networks (1995) NIPS, pp. 323-329. , MIT Press, D.S. Touretzky, M. Mozer, M.E. Hasselmo (Eds.); White, H., Learning in artificial neural networks: A statistical perspective (1989) Neural Computation, 1 (4), pp. 425-464; Whitehead, S., (1992) Reinforcement learning for the adaptive control of perception and action, , (Ph.D. thesis), University of Rochester; Whiteson, S., Evolutionary computation for reinforcement learning (2012) Reinforcement learning, pp. 325-355. , Springer, Berlin, Germany, M. Wiering, M. van Otterlo (Eds.); Whiteson, S., Kohl, N., Miikkulainen, R., Stone, P., Evolving keepaway soccer players through task decomposition (2005) Machine Learning, 59 (1), pp. 5-30; Whiteson, S., Stone, P., Evolutionary function approximation for reinforcement learning (2006) Journal of Machine Learning Research,7, pp. 877-917; Widrow, B., Hoff, M., Associative storage and retrieval of digital information in networks of adaptive neurons (1962) Biological Prototypes and Synthetic Systems,1, p. 160; Widrow, B., Rumelhart, D.E., Lehr, M.A., Neural networks: Applications in industry, business and science (1994) Communications of the ACM, 37 (3), pp. 93-105; Wieland, A.P., Evolving neural network controllers for unstable systems (1991) International joint conference on neural networks, vol. 2, pp. 667-673. , IEEE; Wiering, M., Schmidhuber, J., Solving POMDPs with Levin search and EIRA (1996) Machine learning: proceedings of the thirteenth international conference, pp. 534-542. , Morgan Kaufmann Publishers, San Francisco, CA, L. Saitta (Ed.); Wiering, M., Schmidhuber, J., HQ-learning (1998) Adaptive Behavior, 6 (2), pp. 219-246; Wiering, M.A., Schmidhuber, J., Fast online Q(λ) (1998) Machine Learning, 33 (1), pp. 105-116; Wiering, M., van Otterlo, M., (2012) Reinforcement learning, , Springer; Wierstra, D., Foerster, A., Peters, J., Schmidhuber, J., Recurrent policy gradients (2010) Logic Journal of IGPL, 18 (2), pp. 620-634; Wierstra, D., Schaul, T., Peters, J., Schmidhuber, J., Natural evolution strategies (2008) Congress of evolutionary computation.; Wiesel, D.H., Hubel, T.N., Receptive fields of single neurones in the cat's striate cortex (1959) Journal of Physiology,148, pp. 574-591; Wiles, J., Elman, J., Learning to count without a counter: A case study of dynamics and activation landscapes in recurrent networks (1995) Proceedings of the seventeenth annual conference of the cognitive science society, pp. 482-487. , Cambridge, MA, MIT Press; (1965) The algebraic eigenvalue problem, , Oxford University Press, Inc, New York, NY, USA, J.H. Wilkinson (Ed.); Williams, R.J., (1986) Reinforcement-learning in connectionist networks: A mathematical analysis. Technical report 8605, , Institute for Cognitive Science, University of California, San Diego; Williams, R.J., (1988) Toward a theory of reinforcement-learning connectionist systems. Technical report NU-CCS-88-3, , College of Comp. Sci., Northeastern University, Boston, MA; Williams, R.J., (1989) Complexity of exact gradient computation algorithms for recurrent neural networks. Technical report NU-CCS-89-27, , Northeastern University, College of Computer Science, Boston; Williams, R.J., Simple statistical gradient-following algorithms for connectionist reinforcement learning (1992) Machine Learning,8, pp. 229-256; Williams, R.J., Training recurrent networks using the extended Kalman filter (1992) International joint conference on neural networks, vol. 4, pp. 241-246. , IEEE; Williams, R.J., Peng, J., An efficient gradient-based algorithm for on-line training of recurrent network trajectories (1990) Neural Computation,4, pp. 491-501; Williams, R.J., Zipser, D., (1988) A learning algorithm for continually running fully recurrent networks. Technical report ICS report 8805, , Univ. of California, San Diego, La Jolla; Williams, R.J., Zipser, D., Experimental analysis of the real-time recurrent learning algorithm (1989) Connection Science, 1 (1), pp. 87-111; Williams, R.J., Zipser, D., A learning algorithm for continually running fully recurrent networks (1989) Neural Computation, 1 (2), pp. 270-280; Willshaw, D.J., von der Malsburg, C., How patterned neural connections can be set up by self-organization (1976) Proceedings of the Royal Society of London. Series B,194, pp. 431-445; Windisch, D., Loading deep networks is hard: The pyramidal case (2005) Neural Computation, 17 (2), pp. 487-502; Wiskott, L., Sejnowski, T., Slow feature analysis: Unsupervised learning of invariances (2002) Neural Computation, 14 (4), pp. 715-770; Witczak, M., Korbicz, J., Mrugalski, M., Patton, R.J., A GMDH neural network-based approach to robust fault diagnosis: Application to the DAMADICS benchmark problem (2006) Control Engineering Practice, 14 (6), pp. 671-683; Wöllmer, M., Blaschke, C., Schindl, T., Schuller, B., Färber, B., Mayer, S., On-line driver distraction detection using long short-term memory (2011) IEEE Transactions on Intelligent Transportation Systems (TITS), 12 (2), pp. 574-582; Wöllmer, M., Schuller, B., Rigoll, G., Keyword spotting exploiting long short-term memory (2013) Speech Communication, 55 (2), pp. 252-265; Wolpert, D.H., Stacked generalization (1992) Neural Networks, 5 (2), pp. 241-259; Wolpert, D.H., Bayesian backpropagation over i-o functions rather than weights (1994) Advances in neural information processing systems (NIPS), vol. 6, pp. 200-207. , Morgan Kaufmann, J.D. Cowan, G. Tesauro, J. Alspector (Eds.); Wu, L., Baldi, P., Learning to play go using recursive neural networks (2008) Neural Networks, 21 (9), pp. 1392-1400; Wu, D., Shao, L., Leveraging hierarchical parametric networks for skeletal joints based action segmentation and recognition (2014) Proc. conference on computer vision and pattern recognition.; Wyatte, D., Curran, T., O'Reilly, R., The limits of feedforward vision: Recurrent processing promotes robust object recognition when objects are degraded (2012) Journal of Cognitive Neuroscience, 24 (11), pp. 2248-2261; Wysoski, S.G., Benuskova, L., Kasabov, N., Evolving spiking neural networks for audiovisual information processing (2010) Neural Networks, 23 (7), pp. 819-835; Yamauchi, B.M., Beer, R.D., Sequential behavior and learning in evolved dynamical neural networks (1994) Adaptive Behavior, 2 (3), pp. 219-246; Yamins, D., Hong, H., Cadieu, C., DiCarlo, J.J., Hierarchical modular optimization of convolutional networks achieves representations similar to macaque IT and human ventral stream (2013) Advances in neural information processing systems (NIPS), pp. 1-9; Yang, M., Ji, S., Xu, W., Wang, J., Lv, F., Yu, K., Detecting human actions in surveillance videos (2009) TREC video retrieval evaluation workshop.; Yao, X., A review of evolutionary artificial neural networks (1993) International Journal of Intelligent Systems,4, pp. 203-222; Yin, J., Meng, Y., Jin, Y., A developmental approach to structural self-organization in reservoir computing (2012) IEEE Transactions on Autonomous Mental Development, 4 (4), pp. 273-289; Yin, F., Wang, Q.-F., Zhang, X.-Y., Liu, C.-L., ICDAR 2013 Chinese handwriting recognition competition (2013) 12th international conference on document analysis and recognition, pp. 1464-1470; Young, S., Davis, A., Mishtal, A., Arel, I., Hierarchical spatiotemporal feature extraction using recurrent online clustering (2014) Pattern Recognition Letters,37, pp. 115-123; Yu, X.-H., Chen, G.-A., Cheng, S.-X., Dynamic learning rate optimization of the backpropagation algorithm (1995) IEEE Transactions on Neural Networks, 6 (3), pp. 669-677; Zamora-Martínez, F., Frinken, V., España-Boquera, S., Castro-Bleda, M., Fischer, A., Bunke, H., Neural network language models for off-line handwriting recognition (2014) Pattern Recognition, 47 (4), pp. 1642-1652; Zeiler, M.D., (2012) ADADELTA: an adaptive learning rate method, , CoRR, abs/1212.5701; Zeiler, M.D., Fergus, R., (2013) Visualizing and understanding convolutional networks. Technical report, , NYU, arXiv:1311.2901 [cs.CV]; Zemel, R.S., (1993) A minimum description length framework for unsupervised learning, , (Ph.D. thesis), University of Toronto; Zemel, R.S., Hinton, G.E., Developing population codes by minimizing description length (1994) Advances in neural information processing systems vol. 6, pp. 11-18. , Morgan Kaufmann, J.D. Cowan, G. Tesauro, J. Alspector (Eds.); Zeng, Z., Goodman, R., Smyth, P., Discrete recurrent neural networks for grammatical inference (1994) IEEE Transactions on Neural Networks, 5 (2); Zimmermann, H.-G., Tietz, C., Grothmann, R., Forecasting with recurrent neural networks: 12 tricks (2012) Lecture notes in computer science,7700, pp. 687-707. , Springer, G. Montavon, G.B. Orr, K.-R. Müller (Eds.) Neural networks: tricks of the trade; Zipser, D., Kehoe, B., Littlewort, G., Fuster, J., A spiking network model of short-term active memory (1993) The Journal of Neuroscience, 13 (8)," pp. 3406-3420"""
"Huang G., Huang G.-B., Song S., You K.",7403425368;7403425167;13310063000;24923959400;,Trends in extreme learning machines: A review,2015,Neural Networks,10.1016/j.neunet.2014.10.001,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84908682236&doi=10.1016%2fj.neunet.2014.10.001&partnerID=40&md5=1e4b0d1ed4ec9aa4317d0d9d19129474,"Extreme learning machine (ELM) has gained increasing interest from various research fields recently. In this review, we aim to report the current state of the theoretical research and practical advances on this subject. We first give an overview of ELM from the theoretical perspective, including the interpolation theory, universal approximation capability, and generalization ability. Then we focus on the various improvements made to ELM which further improve its stability, sparsity and accuracy under general or specific conditions. Apart from classification and regression, ELM has recently been extended for clustering, feature selection, representational learning and many other learning tasks. These newly emerging algorithms greatly expand the applications of ELM. From implementation aspect, hardware implementation and parallel computation techniques have substantially sped up the training of ELM, making it feasible for big data processing and real-time reasoning. Due to its remarkable efficiency, simplicity, and impressive generalization performance, ELM have been applied in a variety of domains, such as biomedical engineering, computer vision, system identification, and control and robotics. In this review, we try to provide a comprehensive view of these advances in ELM together with its future perspectives. © 2014 Elsevier Ltd.",Classification; Clustering; Extreme learning machine; Feature learning; Regression,Big data; Biomedical engineering; Classification (of information); Computation theory; Computer control systems; Data handling; Hardware; Knowledge acquisition; Learning systems; Robotics; Clustering; Extreme learning machine; Feature learning; Generalization performance; Hardware implementations; Implementation aspects; Regression; Universal approximation; Computer vision; accuracy; classification algorithm; computer model; computer prediction; extreme learning machine; image processing; intermethod comparison; kernel method; learning algorithm; machine learning; regression analysis; Review; support vector machine; trend study; algorithm; artificial intelligence; classification; standards; trends; Algorithms; Artificial Intelligence,"Adamos, D.A., Laskaris, N.A., Kosmidis, E.K., Theophilidis, G., Nass: An empirical approach to spike sorting with overlap resolution based on a hybrid noise-assisted methodology (2010) Journal of Neuroscience Methods, 190 (1), pp. 129-142; An, L., Bhanu, B., Image super-resolution by extreme learning machine (2012) 2012 19th IEEE international conference on image processing, pp. 2209-2212. , IEEE; Avci, E., A new method for expert target recognition system: Genetic wavelet extreme learning machine (GAWELM) (2013) Expert Systems with Applications, 40 (10), pp. 3984-3993; Avci, E., Coteli, R., A new automatic target recognition system based on wavelet extreme learning machine (2012) Expert Systems with Applications, 39 (16), pp. 12340-12348; Bai, Z., Huang, G.-B., Wang, D., Wang, H., Westover, M.B., Sparse extreme learning machine for classification (2014) IEEE Transactions on Cybernetics; Balbay, A., Avci, E., Sahin, O., Coteli, R., Modeling of drying process of bittim nuts (Pistacia terebinthus) in a fixed bed dryer system by using extreme learning machine (2012) International Journal of Food Engineering, 8 (4); Balbay, A., Kaya, Y., Sahin, O., Drying of black cumin (Nigella sativa) in a microwave assisted drying system and modeling using extreme learning machine (2012) Energy, 44 (1), pp. 352-357; Baradarani, A., Wu, Q.M.J., Ahmadi, M., An efficient illumination invariant face recognition framework via illumination enhancement and dd-dtcwt filtering (2013) Pattern Recognition, 46 (1), pp. 57-72; Barea, R., Boquete, L., Ortega, S., Lopez, E., Rodriguez-Ascariz, J.M., Eog-based eye movements codification for human computer interaction (2012) Expert Systems with Applications, 39 (3), pp. 2677-2683; Basu, A., Shuo, S., Zhou, H.M., Lim, M.H., Huang, G.B., Silicon spiking neurons for hardware implementation of extreme learning machines (2013) Neurocomputing, 102, pp. 125-134; Bazi, Y., Alajlan, N., Melgani, F., AlHichri, H., Malek, S., Yager, R.R., Differential evolution extreme learning machine for the classification of hyperspectral images (2014) IEEE Geoscience and Remote Sensing Letters, 11 (6), pp. 1066-1070; Belkin, M., Niyogi, P., Laplacian eigenmaps for dimensionality reduction and data representation (2003) Neural Computation, 15 (6), pp. 1373-1396; Belkin, M., Niyogi, P., Sindhwani, V., Manifold regularization: A geometric framework for learning from labeled and unlabeled examples (2006) The Journal of Machine Learning Research, 7, pp. 2399-2434; Bengio, Y., Learning deep architectures for AI (2009) Foundations and Trends in Machine Learning, 2 (1), pp. 1-127; Benoit, F., van Heeswijk, M., Miche, Y., Verleysen, M., Lendasse, A., Feature selection for nonlinear models with extreme learning machines (2013) Neurocomputing, 102, pp. 111-124; Block, H.D., The perceptron: A model for brain function. I (1962) Reviewers of Modern Physics, 34 (1), pp. 123-135; Block, H.D., Knight, J.B.W., Rosenblatt, F., Analysis of a four-layer series-coupled perceptron. II (1962) Reviewers of Modern Physics, 34 (1), pp. 135-142; Boquete, L., Miguel-Jimenez, J.M., Ortega, S., Rodriguez-Ascariz, J.M., Perez-Rico, C., Blanco, R., Multifocal electroretinogram diagnosis of glaucoma applying neural networks and structural pattern analysis (2012) Expert Systems with Applications, 39 (1), pp. 234-238; Branke, J., (1995) Evolutionary algorithms for neural network design and training, , Proceedings of the first nordic workshop on genetic algorithms and its applications; Butcher, J.B., Verstraeten, D., Schrauwen, B., Day, C.R., Haycock, P.W., Reservoir computing and extreme learning machines for non-linear time-series data analysis (2013) Neural Networks, 38, pp. 76-89; Cambria, E., Gastaldo, P., Bisio, F., Zunino, R., An ELM-based model for affective analogical reasoning (2014) Neurocomputing, , in press; Cao, J.W., Lin, Z.P., Huang, G.B., Composite function wavelet neural networks with extreme learning machine (2010) Neurocomputing, 73 (7-9), pp. 1405-1416; Cao, J.W., Lin, Z.P., Huang, G.B., Self-adaptive evolutionary extreme learning machine (2012) Neural Processing Letters, 36 (3), pp. 285-305; Cao, J.W., Lin, Z.P., Huang, G.B., Liu, N., Voting based extreme learning machine (2012) Information Sciences, 185 (1), pp. 66-77; Cao, F.L., Liu, B., Park, D.S., Image classification based on effective extreme learning machine (2013) Neurocomputing, 102, pp. 90-97; Chang, N.B., Han, M., Yao, W., Chen, L.C., Xu, S.G., Change detection of land use and land cover in an urban region with spot-5 images and partial lanczos extreme learning machine (2010) Journal of Applied Remote Sensing, 4; Chen, S., Cowan, C., Grant, P., Orthogonal least squares learning algorithm for radial basis function networks (1991) IEEE Transactions on Neural Networks, 2 (2), pp. 302-309; Chen, Q.S., Ding, J., Cai, J.R., Zhao, J.W., Rapid measurement of total acid content (TAC) in vinegar using near infrared spectroscopy based on efficient variables selection algorithm and nonlinear regression tools (2012) Food Chemistry, 135 (2), pp. 590-595; Chen, X., Dong, Z.Y., Meng, K., Ku, Y., Wong, K.P., Ngan, H.W., Electricity price forecasting with extreme learning machine and bootstrapping (2012) IEEE Transactions on Power Systems, 27 (4), pp. 2055-2062; Chen, F.L., Ou, T.Y., Sales forecasting system based on gray extreme learning machine with taguchi method in retail industry (2011) Expert Systems with Applications, 38 (3), pp. 1336-1345; Chen, H., Peng, J., Zhou, Y., Li, L., Pan, Z., Extreme learning machine for ranking: Generalization analysis and applications (2014) Neural Networks, 53, pp. 119-126; Cheng, C., Tay, W.P., Huang, G.-B., Extreme learning machines for intrusion detection (2012) The 2012 International Joint Conference on Neural Networks (IJCNN), pp. 1-8. , IEEE; Chen, Y.Q., Zhao, Z.T., Wang, S.Q., Chen, Z.Y., Extreme learning machine-based device displacement free activity recognition model (2012) Soft Computing, 16 (9), pp. 1617-1625; Chen, Z.X.X., Zhu, H.Y.Y., Wang, Y.G.G., A modified extreme learning machine with sigmoidal activation functions (2013) Neural Computing & Applications, 22 (3-4), pp. 541-550; Choi, K., Toh, K.A., Byun, H., Incremental face recognition for large-scale social network services (2012) Pattern Recognition, 45 (8), pp. 2868-2883; Cortes, C., Vapnik, V., Support vector machine (1995) Machine learning, 20 (3), pp. 273-297; Creech, G., Jiang, F., The application of extreme learning machines to the network intrusion detection problem (2012) International conference of numerical analysis and applied mathematics, 1479, pp. 1506-1511. , AIP Publishing; Daliri, M.R., A hybrid automatic system for the diagnosis of lung cancer based on genetic algorithm and fuzzy extreme learning machines (2012) Journal of Medical Systems, 36 (2), pp. 1001-1005; Decherchi, S., Gastaldo, P., Dahiya, R.S., Valle, M., Zunino, R., Tactile-data classification of contact materials using computational intelligence (2011) IEEE Transactions on Robotics, 27 (3), pp. 635-639; Decherchi, S., Gastaldo, P., Leoncini, A., Zunino, R., Efficient digital implementation of extreme learning machines for classification (2012) IEEE Transactions on Circuits and Systems II-Express Briefs, 59 (8), pp. 496-500; Decherchi, S., Gastaldo, P., Zunino, R., Cambria, E., Redi, J., Circular-ELM for the reduced-reference assessment of perceived image quality (2013) Neurocomputing, 102, pp. 78-89; Deng, J., Li, K., Irwin, G.W., Fast automatic two-stage nonlinear model identification based on the extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2422-2429; Deng, W.-Y., Zheng, Q.-H., Wang, Z.-M., Projection vector machine (2013) Neurocomputing, 120, pp. 490-498; Du, D.J., Li, K., Irwin, G.W., Deng, J., A novel automatic two-stage locally regularized classifier construction method using the extreme learning machine (2013) Neurocomputing, 102, pp. 10-22; Feng, G.R., Huang, G.B., Lin, Q.P., Gay, R., Error minimized extreme learning machine with growth of hidden nodes and incremental learning (2009) IEEE Transactions on Neural Networks, 20 (8), pp. 1352-1357; Feng, G.R., Qian, Z.X., Zhang, X.P., Evolutionary selection extreme learning machine optimization for regression (2012) Soft Computing, 16 (9), pp. 1485-1491; Feng, Y., Wang, Y.N., Yang, Y.M., Inverse kinematics solution for robot manipulator based on neural network under joint subspace (2012) International Journal of Computers Communications & Control, 7 (3), pp. 459-472; Fernández-Delgado, M., Cernadas, E., Barro, S., Ribeiro, J., Neves, J., Direct kernel perceptron (DKP): Ultra-fast kernel ELM-based classification with non-iterative closed-form weight calculation (2014) Neural Networks, 50, pp. 60-71; Frenay, B., Verleysen, M., Parameter-insensitive kernel in extreme learning for non-linear support vector regression (2011) Neurocomputing, 74 (16), pp. 2526-2531; Gao, J.F., Wang, Z., Yang, Y., Zhang, W.J., Tao, C.Y., Guan, J.A., A novel approach for lie detection based on f-score and extreme learning machine (2013) Plos One, 8 (6); Gastaldo, P., Zunino, R., Cambria, E., Decherchi, S., Combining ELM with random projections (2013) IEEE Intelligent Systems, 28 (5), pp. 18-20; Hagan, M.T., Menhaj, M.B., Training feedforward networks with the marquardt algorithm (1994) IEEE Transactions on Neural Networks, 5 (6), pp. 989-993; He, Q., Du, C.Y., Wang, Q., Zhuang, F.Z., Shi, Z.Z., A parallel incremental extreme svm classifier (2011) Neurocomputing, 74 (16), pp. 2532-2540; He, Q., Shang, T.F., Zhuang, F.Z., Shi, Z.Z., Parallel extreme learning machine for regression based on mapreduce (2013) Neurocomputing, 102, pp. 52-58; He, B., Xu, D., Nian, R., van Heeswijk, M., Yu, Q., Miche, Y., Fast face recognition via sparse coding and extreme learning machine (2014) Cognitive Computation, 6, pp. 264-277; Horata, P., Chiewchanwattana, S., Sunat, K., Robust extreme learning machine (2013) Neurocomputing, 102, pp. 31-44; Huang, G.-B., (2014) An insight to extreme learning machines: Random neurons, random features and kernels, , http://dx.doi.org/10.1007/s12559-014-9255-2, Cognitive Computation (Online); Huang, G.-B., Chen, L., Convex incremental extreme learning machine (2007) Neurocomputing, 70 (16), pp. 3056-3062; Huang, G.-B., Chen, L., Enhanced random search based incremental extreme learning machine (2008) Neurocomputing, 71 (16), pp. 3460-3468; Huang, G.-B., Chen, L., Siew, C.-K., Universal approximation using incremental constructive feedforward networks with random hidden nodes (2006) IEEE Transactions on Neural Networks, 17 (4), pp. 879-892; Huang, G.-B., Ding, X.J., Zhou, H.M., Optimization method based extreme learning machine for classification (2010) Neurocomputing, 74 (1-3), pp. 155-163; Huang, G.-B., Li, M.-B., Chen, L., Siew, C.-K., Incremental extreme learning machine with fully complex hidden nodes (2008) Neurocomputing, 71 (4), pp. 576-583; Huang, G., Song, S., Gupta, J., Wu, C., Semi-supervised and unsupervised extreme learning machines (2014) IEEE Transactions on Cybernetics; Huang, G., Song, S., Wu, C., Orthogonal least squares algorithm for training cascade neural networks (2012) IEEE Transactions on Circuits and Systems I: Regular Papers, 59 (11), pp. 2629-2637; Huang, W., Tan, Z.M., Lin, Z., Huang, G.B., Zhou, J., Chui, C.K., (2012) A semi-automatic approach to the segmentation of liver parenchyma from 3D CT images with extreme learning machine, , IEEE; Huang, G.-B., Wang, D.H., Lan, Y., Extreme learning machines: a survey (2011) International Journal of Machine Learning and Cybernetics, 2 (2), pp. 107-122; Huang, G.-B., Zhou, H., Ding, X., Zhang, R., Extreme learning machine for regression and multiclass classification (2012) IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 42 (2), pp. 513-529; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: theory and applications (2006) Neurocomputing, 70 (1), pp. 489-501; Huang, G.-B., Zhu, Q.-Y., Siew, C.-K., Extreme learning machine: a new learning scheme of feedforward neural networks (2004), 2, pp. 985-990. , IEEE International Joint Conference on Neural Networks, 2004; Kan, E.M., Lim, M.H., Ong, Y.S., Tan, A.H., Yeo, S.P., Extreme learning machine terrain-based navigation for unmanned aerial vehicles (2013) Neural Computing & Applications, 22 (3-4), pp. 469-477; Karpagachelvi, S., Arthanari, M., Sivakumar, M., Classification of electrocardiogram signals with support vector machines and extreme learning machine (2012) Neural Computing & Applications, 21 (6), pp. 1331-1339; Kasun, L.L.C., Zhou, H., Huang, G.-B., Representational learning with ELMs for big data (2013) IEEE Intelligent Systems, 28 (5), pp. 31-34; Kaya, Y., Uyar, M., A hybrid decision support system based on rough set and extreme learning machine for diagnosis of hepatitis disease (2013) Applied Soft Computing, 13 (8), pp. 3429-3438; Kim, J., Shin, H.S., Shin, K., Lee, M., Robust algorithm for arrhythmia classification in ecg using extreme learning machine (2009) Biomedical Engineering Online, 8; Kong, W.W., Zhang, C., Liu, F., Gong, A.P., He, Y., Irradiation dose detection of irradiated milk powder using visible and near-infrared spectroscopy and chemometrics (2013) Journal of Dairy Science, 96 (8), pp. 4921-4927; Kosmatopoulos, E.B., Kouvelas, A., Large scale nonlinear control system fine-tuning through learning (2009) IEEE Transactions on Neural Networks, 20 (6), pp. 1009-1023; Kosmatopoulos, E.B., Kouvelas, A., Large scale nonlinear control system fine-tuning through learning (2009) IEEE Transactions on Neural Networks, 20 (6), pp. 1009-1023; Kwok, T.-Y., Yeung, D.-Y., Constructive algorithms for structure learning in feedforward neural networks for regression problems (1997) IEEE Transactions on Neural Networks, 8 (3), pp. 630-645; Lahoz, D., Lacruz, B., Mateo, P.M., A multi-objective micro genetic ELM algorithm (2013) Neurocomputing, 111, pp. 90-103; Lan, Y., Soh, Y.C., Huang, G.B., Ensemble of online sequential extreme learning machine (2009) Neurocomputing, 72 (13-15), pp. 3391-3395; Landa-Torres, I., Ortiz-Garcia, E.G., Salcedo-Sanz, S., Segovia-Vargas, M.J., Gil-Lopez, S., Miranda, M., Evaluating the internationalization success of companies through a hybrid grouping harmony search-extreme learning machine approach (2012) IEEE Journal of Selected Topics in Signal Processing, 6 (4), pp. 388-398; Lemme, A., Freire, A., Barreto, G., Steil, J., Kinesthetic teaching of visuomotor coordination for pointing by the humanoid robot icub (2013) Neurocomputing, 112, pp. 179-188; Le, Q., Sarlos, T., Smola, A., (2013) Fastfood-approximating kernel expansions in loglinear time, , Proceedings of the international conference on machine learning; Liang, N.-Y., Huang, G.-B., Saratchandran, P., Sundararajan, N., A fast and accurate online sequential learning algorithm for feedforward networks (2006) IEEE Transactions on Neural Networks, 17 (6), pp. 1411-1423; Li, B., Li, Y.B., Rong, X.W., The extreme learning machine learning algorithm with tunable activation function (2013) Neural Computing & Applications, 22 (3-4), pp. 531-539; Li, L., Liu, D., Ouyang, J., A new regularization classification method based on extreme learning machine in network data (2012) Journal of Information & Computational Science, 9 (12), pp. 3351-3363; Li, Y.J., Li, Y., Zhai, J.H., Shiu, S., Rts game strategy evaluation using extreme learning machine (2012) Soft Computing, 16 (9), pp. 1627-1637; Lin, S.J., Chang, C.H., Hsu, M.F., Multiple extreme learning machines for a two-class imbalance corporate life cycle prediction (2013) Knowledge-Based Systems, 39, pp. 214-223; Li, G.Q., Niu, P.F., Liu, C., Zhang, W.P., Enhanced combination modeling method for combustion efficiency in coal-fired boilers (2012) Applied Soft Computing, 12 (10), pp. 3132-3140; Lin, S., Liu, X., Fang, J., Xu, Z., Is extreme learning machine feasible? a theoretical assessment (part II) (2014) IEEE Transactions on Neural Networks nd Learning Systems; Lin, J., Yin, J., Cai, Z., Liu, Q., Li, K., A secure and practical mechanism of outsourcing extreme learning machine in cloud computing (2013) IEEE Intelligent Systems, 28 (5), pp. 35-38; Li, L.N., Ouyang, J.H., Chen, H.L., Liu, D.Y., A computer aided diagnosis system for thyroid disease using extreme learning machine (2012) Journal of Medical Systems, 36 (5), pp. 3327-3337; Li, K., Peng, J.-X., Irwin, G.W., A fast nonlinear model identification method (2005) IEEE Transactions on Automatic Control, 50 (8), pp. 1211-1216; Liu, J.F., Chen, Y.Q., Liu, M.J., Zhao, Z.T., SELM: Semi-supervised ELM with application in sparse calibrated location estimation (2011) Neurocomputing, 74 (16), pp. 2566-2572; Liu, X.Y., Gao, C.H., Li, P., A comparative analysis of support vector machines and extreme learning machines (2012) Neural Networks, 33, pp. 58-66; Liu, G.H., Jiang, H., Xiao, X.H., Zhang, D.J., Mei, C.L., Ding, Y.H., Determination of process variable ph in solid-state fermentation by ft-nir spectroscopy and extreme learning machine (ELM) (2012) Spectroscopy and Spectral Analysis, 32 (4), pp. 970-973; Liu, X., Lin, S., Fang, J., Xu, Z., Is extreme learning machine feasible? a theoretical assessment (part I) (2014) IEEE Transactions on Neural Networks nd Learning Systems; Liu, N., Wang, H., Ensemble based extreme learning machine (2010) IEEE Signal Processing Letters, 17 (8), pp. 754-757; Liu, Y., Xu, X.J., Wang, C.Y., (2009) Simple ensemble of extreme learning machine, 1-9. , Proceedings of the 2009 2nd international congress on image and signal processing; Li, W.T., Wang, D.H., Chai, T.Y., Burning state recognition of rotary kiln using ELMs with heterogeneous features (2013) Neurocomputing, 102, pp. 144-153; Li, K., Zhang, J., Xu, H., Luo, S., Li, H., A semi-supervised extreme learning machine method based on co-training (2013) Journal of Computational Information Systems, 9 (1), pp. 207-214; Luo, J., Vong, C.-M., Wong, P.-K., Sparse bayesian extreme learning machine for multi-classification (2014) IEEE Transactions on Neural Networks nd Learning Systems, 25 (4), pp. 836-843; Lu, B., Wang, G.R., Yuan, Y., Han, D., Semantic concept detection for video based on extreme learning machine (2013) Neurocomputing, 102, pp. 176-183; Malar, E., Kandaswamy, A., Chakravarthy, D., Dharan, A.G., A novel approach for detection and classification of mammographic microcalcifications using wavelet analysis and extreme learning machine (2012) Computers in Biology and Medicine, 42 (9), pp. 898-905; Malathi, V., Marimuthu, N.S., Baskar, S., Intelligent approaches using support vector machine and extreme learning machine for transmission line protection (2010) Neurocomputing, 73 (10-12), pp. 2160-2167; Malathi, V., Marimuthu, N.S., Baskar, S., Ramar, K., Application of extreme learning machine for series compensated transmission line protection (2011) Engineering Applications of Artificial Intelligence, 24 (5), pp. 880-887; Man, Z.H., Lee, K., Wang, D.H., Cao, Z.W., Khoo, S.Y., Robust single-hidden layer feedforward network-based pattern classifier (2012) IEEE Transactions on Neural Networks and Learning Systems, 23 (12), pp. 1974-1986; Man, Z.H., Lee, K., Wang, D.H., Cao, Z.W., Miao, C.Y., A new robust training algorithm for a class of single-hidden layer feedforward neural networks (2011) Neurocomputing, 74 (16), pp. 2491-2501; Marques, I., Grana, M., Fusion of lattice independent and linear features improving face identification (2013) Neurocomputing, 114, pp. 80-85; Martinez-Martinez, J.M., Escandell-Montero, P., Soria-Olivas, E., Martin-Guerrero, J.D., Magdalena-Benedito, R., Gomez-Sanchis, J., Regularized extreme learning machine for regression problems (2011) Neurocomputing, 74 (17), pp. 3716-3721; Miche, Y., Sorjamaa, A., Bas, P., Simula, O., Jutten, C., Lendasse, A., OP-ELM: Optimally pruned extreme learning machine (2010) IEEE Transactions on Neural Networks, 21 (1), pp. 158-162; Minhas, R., Baradarani, A., Seifzadeh, S., Wu, Q.M.J., Human action recognition using extreme learning machine based on visual vocabularies (2010) Neurocomputing, 73 (10-12), pp. 1906-1917; Minhas, R., Mohammed, A.A., Wu, Q.M.J., A fast recognition framework based on extreme learning machine using hybrid object information (2010) Neurocomputing, 73 (10-12), pp. 1831-1839; Minhas, R., Mohammed, A.A., Wu, Q.M.J., Incremental learning in human action recognition based on snippets (2012) IEEE Transactions on Circuits and Systems for Video Technology, 22 (11), pp. 1529-1541; Mohammed, A.A., Minhas, R., Wu, Q.M.J., Sid-Ahmed, M.A., Human face recognition based on multidimensional pca and extreme learning machine (2011) Pattern Recognition, 44 (10-11), pp. 2588-2597; Muhammad, I.G., Tepe, K.E., Abdel-Raheem, E., QAM equalization and symbol detection in OFDM systems using extreme learning machine (2013) Neural Computing & Applications, 22 (3-4), pp. 491-500; Martínez-Rego, D., Fontenla-Romero, O., Pérez-Sánchez, B., Alonso-Betanzos, A., Fault prognosis of mechanical components using on-line learning neural networks (2010) Artificial Neural Networks-ICANN 2010, pp. 60-66. , Springer; Nian, R., He, B., Lendasse, A., 3d object recognition based on a geometrical topology model and extreme learning machine (2013) Neural Computing & Applications, 22 (3-4), pp. 427-433; Osman, M.K., Mashor, M.Y., Jaafar, H., Performance comparison of extreme learning machine algorithms for mycobacterium tuberculosis detection in tissue sections (2012) Journal of Medical Imaging and Health Informatics, 2 (3), pp. 307-312; Pal, M., Extreme-learning-machine-based land cover classification (2009) International Journal of Remote Sensing, 30 (14), pp. 3835-3841; Pal, M., Maxwell, A.E., Warner, T.A., Kernel-based extreme learning machine for remote-sensing image classification (2013) Remote Sensing Letters, 4 (9), pp. 853-862; Pan, C., Park, D.S., Lu, H.J., Wu, X.P., Color image segmentation by fixation-based active learning with ELM (2012) Soft Computing, 16 (9), pp. 1569-1584; Platt, J., A resource-allocating network for function interpolation (1991) Neural Computation, 3 (2), pp. 213-225; Plutowski, M., Cottrell, G., White, H., Experience with selecting exemplars from clean data (1996) Neural Networks, 9 (2), pp. 273-294; Poggio, T., Girosi, F., Networks for approximation and learning (1990) Proceedings of the IEEE, 78 (9), pp. 1481-1497; Poria, S., Cambria, E., Winterstein, G., Huang, G.-B., (2014) Sentic patterns: Dependency-based rules for concept-level sentiment analysis, , http://dx.doi.org/10.1016/j.knosys.2014.05.005, Knowledge-Based Systems; Qu, Y.P., Shang, C.J., Wu, W., Shen, Q., Evolutionary fuzzy extreme learning machine for mammographic risk analysis (2011) International Journal of Fuzzy Systems, 13 (4), pp. 282-291; Rahimi, A., Recht, B., Random features for large-scale kernel machines (2007) Advances in neural information processing systems, 3, p. 5; Rahimi, A., Recht, B., Uniform approximation of functions with random bases (2008) Communication, control, and computing, 2008 46th annual allerton conference on, pp. 555-561. , IEEE; Rahimi, A., Recht, B., Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning (2008) Advances in neural information processing systems, pp. 1313-1320; Rao, C.R., Mitra, S.K., (1971) Generalized inverse of matrices and its applications, Vol.~7, , Wiley, New York; Rasheed, Z., Rangwala, H., Metagenomic taxonomic classification using extreme learning machines (2012) Journal of Bioinformatics and Computational Biology, 10 (5); Rong, H.J., Huang, G.B., Sundararajan, N., Saratchandran, P., Online sequential fuzzy extreme learning machine for function approximation and classification problems (2009) IEEE Transactions on Systems Man and Cybernetics Part B-Cybernetics, 39 (4), pp. 1067-1072; Rong, H.-J., Ong, Y.-S., Tan, A.-H., Zhu, Z., A fast pruned-extreme learning machine for classification problem (2008) Neurocomputing, 72 (1), pp. 359-366; Rong, H.J., Suresh, S., Zhao, G.S., Stable indirect adaptive neural controller for a class of nonlinear system (2011) Neurocomputing, 74 (16), pp. 2582-2590; Rosenblatt, F., The perceptron: A probabilistic model for information storage and organization in the brain (1958) Psychological Review, 65 (6), pp. 386-408; Rosenblatt, F., (1962) Principles of neurodynamics: perceptrons and the theory of brain mechanisms, , Spartan Books, New York; Rumelhart, D.E., Hinton, G.E., Williams, R.J., Learning representations by back-propagating errors (1986) Nature, 323 (9), pp. 533-536; Saavedra-Moreno, B., Salcedo-Sanz, S., Carro-Calvo, L., Gascon-Moreno, J., Jimenez-Fernandez, S., Prieto, L., Very fast training neural-computation techniques for real measure-correlate-predict wind operations in wind farms (2013) Journal of Wind Engineering and Industrial Aerodynamics, 116, pp. 49-60; Sanchez-Monedero, J., Gutierrez, P.A., Fernandez-Navarro, F., Hervas-Martinez, C., Weighting efficient accuracy and minimum sensitivity for evolving multi-class classifiers (2011) Neural Processing Letters, 34 (2), pp. 101-116; Sanchez-Monedero, J., Hervas-Martinez, C., Gutierrez, P.A., Ruz, M.C., Moreno, M.C.R., Cruz-Ramirez, M., Evaluating the performance of evolutionary extreme learning machines by a combination of sensitivity and accuracy measures (2010) Neural Network World, 20 (7), pp. 899-912; Saraswathi, S., Fernandez-Martinez, J.L., Kolinski, A., Jernigan, R.L., Kloczkowski, A., Fast learning optimized prediction methodology (flopred) for protein secondary structure prediction (2012) Journal of Molecular Modeling, 18 (9), pp. 4275-4289; Saraswathi, S., Sundaram, S., Sundararajan, N., Zimmermann, M., Nilsen-Hamilton, M., ICGA-PSO-ELM approach for accurate multiclass cancer classification resulting in reduced gene sets in which genes encoding secreted proteins are highly represented (2011) IEEE-ACM Transactions on Computational Biology and Bioinformatics, 8 (2), pp. 452-463; Savitha, R., Suresh, S., Sundararajan, N., Fast learning circular complex-valued extreme learning machine (CC-ELM) for real-valued classification problems (2012) Information Sciences, 187, pp. 277-290; Savojardo, C., Fariselli, P., Casadio, R., Improving the detection of transmembrane beta-barrel chains with n-to-1 extreme learning machines (2011) Bioinformatics, 27 (22), pp. 3123-3128; Saxe, A., Koh, P.W., Chen, Z., Bhand, M., Suresh, B., Ng, A.Y., (2011) On random weights and unsupervised feature learning, pp. 1089-1096. , Proceedings of the 28th international conference on machine learning; Schmidt, W.F., Kraaijveld, M.A., Duin, R.P., Feed forward neural networks with random weights (1992) Proceedings of 11th IAPR international conference on pattern recognition methodology and systems, pp. 1-4. , Hague, Netherlands; Shi, J., Cai, Y., Zhu, J., Zhong, J., Wang, F., Semg-based hand motion recognition using cumulative residual entropy and extreme learning machine (2013) Medical & Biological Engineering & Computing, 51 (4), pp. 417-427; Shi, L.C., Lu, B.L., Eeg-based vigilance estimation using extreme learning machines (2013) Neurocomputing, 102, pp. 135-143; Song, Y., Crowcroft, J., Zhang, J., Automatic epileptic seizure detection in EEGs based on optimized sample entropy and extreme learning machine (2012) Journal of Neuroscience Methods, 210, pp. 132-146; Song, Y.D., Zhang, J.X., Automatic recognition of epileptic EEG patterns via extreme learning machine and multiresolution feature extraction (2013) Expert Systems with Applications, 40 (14), pp. 5477-5489; Soria-Olivas, E., Gomez-Sanchis, J., Jarman, I., Vila-Frances, J., Martinez, M., Magdalena, J.R., Belm: Bayesian extreme learning machine (2011) IEEE Transactions on Neural Networks, 22 (3), pp. 505-509; Sovilj, D., Sorjamaa, A., Yu, Q., Miche, Y., Severin, E., OPELM and OPKNN in long-term prediction of time series using projected input data (2010) Neurocomputing, 73 (10-12), pp. 1976-1986; Suresh, S., Babu, R.V., Kim, H.J., No-reference image quality assessment using modified extreme learning machine classifier (2009) Applied Soft Computing, 9 (2), pp. 541-552; Suykens, J.A., Vandewalle, J., Least squares support vector machine classifiers (1999) Neural Processing letters, 9 (3), pp. 293-300; Tan, Y.H., Dong, R.L., Chen, H., He, H., Neural network based identification of hysteresis in human meridian systems (2012) International Journal of Applied Mathematics and Computer Science, 22 (3), pp. 685-694; Tang, J., Deng, C., Huang, G.-B., Zhao, B., Compressed-domain ship detection on spaceborne optical image using deep neural network and extreme learning machine (2014) IEEE Transactions on Geoscience and Remote Sensing; Tang, X.L., Han, M., Ternary reversible extreme learning machines: the incremental tri-training method for semi-supervised classification (2010) Knowledge and Information Systems, 23 (3), pp. 345-372; Tian, H.X., Mao, Z.Z., An ensemble ELM based on modified AdaBoost.RT algorithm for predicting the temperature of molten steel in ladle furnace (2010) IEEE Transactions on Automation Science and Engineering, 7 (1), pp. 73-80; van Heeswijk, M., Miche, Y., Oja, E., Lendasse, A., GPU-accelerated and parallelized ELM ensembles for large-scale regression (2011) Neurocomputing, 74 (16), pp. 2430-2437; Vapnik, V., (2000) The nature of statistical learning theory, , Springer; Wang, Y.G., Cao, F.L., Yuan, Y.B., A study on effectiveness of extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2483-2490; Wang, D.H., Do, H.T., Computational localization of transcription factor binding sites using extreme learning machines (2012) Soft Computing, 16 (9), pp. 1595-1606; Wang, N., Er, M.-J., Han, M., Parsimonious extreme learning machine using recursive orthogonal least squares (2014) IEEE Transactions on Neural Networks; Wang, N., Er, M.J., Han, M., Parsimonious extreme learning machine using recursive orthogonal least squares (2014) IEEE Transactions on Neural Networks nd Learning Systems; Wang, X.Y., Han, M., Multivariate chaotic time series prediction based on extreme learning machine (2012) Acta Physica Sinica, 61 (8); Wang, L., Huang, Y.P., Luo, X.Y., Wang, Z., Luo, S.W., Image deblurring with filters learned by extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2464-2474; Wang, J.N., Jin, J.L., Geng, Y., Sun, S.L., Xu, H.L., Lu, Y.H., An accurate and efficient method to predict the electronic excitation energies of bodipy fluorescent dyes (2013) Journal of Computational Chemistry, 34 (7), pp. 566-575; Wang, G.T., Li, P., Cao, J.T., Variable activation function extreme learning machine based on residual prediction compensation (2012) Soft Computing, 16 (9), pp. 1477-1484; Wang, H., Qian, G., Feng, X.Q., Predicting consumer sentiments using online sequential extreme learning machine and intuitionistic fuzzy sets (2013) Neural Computing & Applications, 22 (3-4), pp. 479-489; Wang, X.Z., Shao, Q.Y., Miao, Q., Zhai, J.H., Architecture selection for networks trained with extreme learning machine using localized generalization error model (2013) Neurocomputing, 102, pp. 3-9; Wang, J.N., Xu, H.L., Sun, S.L., Gao, T., Li, H.Z., Li, H., An effective method for accurate prediction of the first hyperpolarizability of alkalides (2012) Journal of Computational Chemistry, 33 (2), pp. 231-236; Wefky, A., Espinosa, F., de Santiago, L., Revenga, P., Lazaro, J.L., Martinez, M., Electrical drive radiated emissions estimation in terms of input control using extreme learning machines (2012) Mathematical Problems in Engineering; White, H., (1989) An additional hidden unit test for neglected nonlinearity in multilayer feedforward networks, pp. 451-455. , Proceedings of the international conference on neural networks; White, H., Approxiate nonlinear forecasting methods (2006) Handbook of economics forecasting, pp. 460-512. , Elsevier, New York, G. Elliott, C.W.J. Granger, A. Timmermann (Eds.); White, H., (1992) Artificial neural networks: approximation and learning theory, , Blackwell Publishers, Inc; Widrow, B., Greenblatt, A., Kim, Y., Park, D., The No-Prop algorithm: A new learning algorithm for multilayer neural networks (2013) Neural Networks, 37, pp. 182-188; Wilamowski, B.M., Yu, H., Neural network learning without backpropagation (2010) IEEE Transactions on Neural Networks, 21 (11), pp. 1793-1803; Wong, W.K., Guo, Z.X., A hybrid intelligent model for medium-term sales forecasting in fashion retail supply chains using extreme learning machine and harmony search algorithm (2010) International Journal of Production Economics, 128 (2), pp. 614-624; Wong, K.I., Wong, P.K., Cheung, C.S., Vong, C.M., Modeling and optimization of biodiesel engine performance using advanced machine learning methods (2013)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Energy,55, pp. 519-528; Xia, M., Zhang, Y.C., Weng, L.G., Ye, X.L., Fashion retailing forecasting based on extreme learning machine with adaptive metrics of inputs (2012) Knowledge-Based Systems,36, pp. 253-259; Xu, Y., Dai, Y.Y., Dong, Z.Y., Zhang, R., Meng, K., Extreme learning machine-based predictor for real-time frequency stability assessment of electric power systems (2013) Neural Computing & Applications, 22 (3-4), pp. 501-508; Xu, Y., Dong, Z.Y., Xu, Z., Meng, K., Wong, K.P., An intelligent dynamic security assessment framework for power systems with wind power (2012) IEEE Transactions on Industrial Informatics, 8 (4), pp. 995-1003; Xu, Y., Dong, Z.Y., Zhao, J.H., Zhang, P., Wong, K.P., A reliable intelligent system for real-time dynamic security assessment of power systems (2012) IEEE Transactions on Power Systems, 27 (3), pp. 1253-1263; Yang, X., Mao, K., Reduced ELMs for causal relation extraction from unstructured text (2013) IEEE Intelligent Systems, 28 (5), pp. 48-52; Yang, Y.M., Wang, Y.N., Yuan, X.F., Parallel chaos search based incremental extreme learning machine (2013) Neural Processing Letters, 37 (3), pp. 277-301; Yang, Y.M., Wang, Y.N., Yuan, X.F., Bidirectional extreme learning machine for regression problem and its learning effectiveness (2012) IEEE Transactions on Neural Networks and Learning Systems, 23 (9), pp. 1498-1505; Yang, J.C., Xie, S., Yoon, S., Park, D., Fang, Z.J., Yang, S.Y., Fingerprint matching based on extreme learning machine (2013) Neural Computing & Applications, 22 (3-4), pp. 435-445; Yang, H.M., Xu, W.J., Zhao, J.H., Wang, D.H., Dong, Z.Y., Predicting the probability of ice storm damages to electricity transmission facilities based on ELM and copula function (2011) Neurocomputing, 74 (16), pp. 2573-2581; Yan, Z., Wang, J., Robust model predictive control of nonlinear systems with unmodeled dynamics and bounded uncertainties based on neural networks (2014) IEEE Transactions on Neural Networks nd Learning Systems, 25 (3), pp. 457-469; Yao, X., A review of evolutionary artificial neural networks (1993) International Journal of Intelligent Systems, 8 (4), pp. 539-567; Ye, Y.B., Squartini, S., Piazza, F., Online sequential extreme learning machine in nonstationary environments (2013) Neurocomputing,116, pp. 94-101; You, Z.H., Lei, Y.K., Zhu, L., Xia, J.F., Wang, B., Prediction of protein-protein interactions from amino acid sequences with ensemble extreme learning machines and principal component analysis (2013) BMC Bioinformatics, 14; Yuan, Y.B., Wang, Y.G., Cao, F.L., Optimization approximation solution for regression problem based on extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2475-2482; Yuan, Q., Zhou, W., Li, S., Cai, D., Epileptic EEG classification based on extreme learning machine and nonlinear features (2011) Epilepsy Research,96, pp. 29-38; Yuan, Q., Zhou, W.D., Li, S.F., Cai, D.M., Epileptic eeg classification based on extreme learning machine and nonlinear features (2011) Epilepsy Research, 96 (1-2), pp. 29-38; Yuan, Q., Zhou, W.D., Zhang, J., Li, S.F., Cai, D.M., Zeng, Y.J., EEG classification approach based on the extreme learning machine and wavelet transform (2012) Clinical EEG and Neuroscience, 43 (2), pp. 127-132; Yu, H., Chen, Y., Liu, J., Huang, G.-B., An adaptive and iterative online sequential ELM based multi-degree-of-freedom gesture recognition system (2013) IEEE Intelligent Systems, 28 (6), pp. 55-59; Yu, Y., Choi, T.M., Hui, C.L., An intelligent fast sales forecasting model for fashion products (2011) Expert Systems with Applications, 38 (6), pp. 7373-7379; Yu, Y., Choi, T.M., Hui, C.L., An intelligent quick prediction algorithm with applications in industrial control and loading problems (2012) IEEE Transactions on Automation Science and Engineering, 9 (2), pp. 276-287; Yu, D., Deng, L., Efficient and effective algorithms for training single-hidden-layer neural networks (2012) Pattern Recognition Letters, 33 (5), pp. 554-558; Yu, Q., Miche, Y., Eirola, E., van Heeswijk, M., Severin, E., Lendasse, A., Regularized extreme learning machine for regression with missing data (2013) Neurocomputing,102, pp. 45-51; Zhai, J.H., Xu, H.Y., Wang, X.Z., Dynamic ensemble extreme learning machine based on sample entropy (2012) Soft Computing, 16 (9), pp. 1493-1502; Zhang, R., Dong, Z.Y., Xu, Y., Meng, K., Wong, K.P., Short-term load forecasting of australian national electricity market by an ensemble model of extreme learning machine (2013) IET Generation Transmission & Distribution, 7 (4), pp. 391-397; Zhang, W.B., Ji, H.B., Fuzzy extreme learning machine for classification (2013) Electronics Letters, 49 (7), pp. 448-449; Zhang, R., Lan, Y., Huang, G.B., Xu, Z.B., Universal approximation of extreme learning machine with adaptive growth of hidden nodes (2012) IEEE Transactions on Neural Networks and Learning Systems, 23 (2), pp. 365-371; Zhang, Y., Slaughter, D.C., Hyperspectral species mapping for automatic weed control in tomato under thermal environmental stress (2011) Computers and Electronics in Agriculture, 77 (1), pp. 95-104; Zhang, X., Wang, H.L., Incremental regularized extreme learning machine based on cholesky factorization and its application to time series prediction (2011) Acta Physica Sinica, 60 (11); Zhang, X., Wang, H.L., Selective forgetting extreme learning machine and its application to time series prediction (2011) Acta Physica Sinica, 60 (8); Zhang, Y.W., Zhang, P.C., Optimization of nonlinear process based on sequential extreme learning machine (2011) Chemical Engineering Science, 66 (20), pp. 4702-4710; Zhao, Z.P., Li, P., Xu, X.Z., Forecasting model of coal mine water inrush based on extreme learning machine (2013) Applied Mathematics & Information Sciences, 7 (3), pp. 1243-1250; Zhao, L., Qi, J.Q., Wang, J., Yao, P.J., The study of using an extreme learning machine for rapid concentration estimation in multi-component gas mixtures (2012) Measurement Science & Technology, 23 (8); Zhao, X.G., Wang, G.R., Bi, X., Gong, P.Z., Zhao, Y.H., XML document classification based on ELM (2011) Neurocomputing, 74 (16), pp. 2444-2451; Zhao, J.W., Wang, Z.H., Park, D.S., Online sequential extreme learning machine with forgetting mechanism (2012) Neurocomputing,87, pp. 79-89; Zheng, W.B., Qian, Y.T., Lu, H.J., Text categorization based on regularization extreme learning machine (2013) Neural Computing & Applications, 22 (3-4), pp. 447-456; Zhou, Z.H., Zhao, J.W., Cao, F.L., Surface reconstruction based on extreme learning machine (2013) Neural Computing & Applications, 23 (2), pp. 283-292; Zong, W.W., Huang, G.-B., Learning to rank with extreme learning machine (2014) Neural processing letters, 39 (2), pp. 155-166; Zong, W.W., Huang, G.-B., Face recognition based on extreme learning machine (2011) Neurocomputing, 74 (16), pp. 2541-2551; Zong, W.W., Huang, G.-B., Chen, Y.Q., Weighted extreme learning machine for imbalance learning (2013) Neurocomputing,101," pp. 229-242""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Dreiseitl S., Ohno-Machado L.",6701810489;7005192335;,Logistic regression and artificial neural network classification models: A methodology review,2002,Journal of Biomedical Informatics,10.1016/S1532-0464(03)00034-0,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0043126911&doi=10.1016%2fS1532-0464%2803%2900034-0&partnerID=40&md5=7b819320e1f32d327ad7c9fdf174378f,"Logistic regression and artificial neural networks are the models of choice in many medical data classification tasks. In this review, we summarize the differences and similarities of these models from a technical point of view, and compare them with other machine learning algorithms. We provide considerations useful for critically assessing the quality of the models and the results based on these models. Finally, we summarize our findings on how quality criteria for logistic regression and artificial neural network models are met in a sample of papers from the medical literature. © 2003 Elsevier Science (USA). All rights reserved.",Artificial neural networks; Classification; Logistic regression; Medical data analysis; Model comparison; Model evaluation,accuracy; algorithm; area under the curve; artificial neural network; calculation; calibration; error; logistic regression analysis; machine; medical literature; methodology; model; parameter; priority journal; probability; qualitative analysis; review; sampling; statistical analysis; theory,"Duda, R., Hart, P., Stork, D., Pattern classification (2000) 2nd ed., , New York: Wiley/Interscience; Vapnik, V., The nature of statistical learning theory (2000) 2nd ed., , New York: Springer; Cristianini, N., Shawe-Taylor, J., (2000) An introduction to support vector machines and other kernel-based learning methods, , Cambridge: Cambridge University Press; Schölkopf, B., Smola, A., (2002) Learning with kernels: Support vector machines, regularization, optimization, and beyond, , Cambridge, MA: MIT Press; Dasarathy, B., (1991) Nearest neighbor pattern classification techniques, , Silver Spring, MD: IEEE Computer Society Press; Ripley, B., (1996) Pattern recognition and neural networks, , Cambridge: Cambridge University Press; Breiman, L., (1984) Classification and regression trees, , Belmont, CA: Wadsworth; Quinlan, R., (1993) C4.5: Programs for machine learning, , Los Altos, CA: Morgan Kaufmann; Bishop, C., (1995) Neural networks for pattern recognition, , Oxford: Oxford University Press; Hastie, T., Tibshirani, R., Friedman, J., (2001) The elements of statistical learning: Data mining, inference, and prediction, , New York: Springer; Press, W., Numerical recipes in C (1993) 2nd ed., , Cambridge: Cambridge University Press; Copas, J., Regression, prediction and shrinkage (with discussion) (1983) J. Roy. Stat. Soc. B, 45, pp. 311-354; Gelfand, A., Sahu, S., Carlin, B., Efficient parametrisations for generalized linear mixed models (1996) Bayesian statistics, 5, pp. 165-180. , Bernardo J. et al. Oxford: Oxford University Press; Neal, R., (1996) Bayesian learning for neural networks, , New York: Springer; Hosmer, D., Lemeshow, S., Applied logistic regression (2000) 2nd ed., , New York: Wiley; Harrell, F., (2001) Regression modeling strategies: With applications to linear models, logistic regression, and survival analysis, , New York: Springer; Zurada, J., Malinowski, A., Cloete, A., Sensitivity analysis for minimization of input dimension for feedforward neural networks (1994) Proc IEEE Int Symp Circuits Systems, 6, pp. 447-450; Stone, M., Cross-validatory choice and assessment of statistical predications (1974) J. Roy. Stat. Soc., 36, pp. 111-147; Allen, D., The relationship between variable selection and data augmentation and a method of prediction (1977) Technometric, 16, pp. 125-127; Efron, B., Tibshirani, R., (1993) An introduction to the bootstrap, , London: Chapman & Hall; Efron, B., Estimating the error rate of a prediction rule: Some improvements on cross-validation (1983) J. Am. Stat. Assoc., 78, pp. 316-331; Hanley, J., McNeil, B., A method of comparing the areas under receiver operating characteristic curves derived from the same cases (1983) Radiology, 148, pp. 839-843; DeLong, E., DeLong, D., Clarke-Pearson, D., Comparing the areas under two or more correlated receiver operating characteristic curves: A nonparametric approach (1988) Biometrics, 44, pp. 837-845; Altman, D., Rayston, P., What do we mean by validating a prognostic model? (2000) Stat. Med., 19, pp. 453-473; Vergouwe, Y., Validity of prognostic models: When is a model clinically useful (2002) Semin. Urol. Oncol., 20, pp. 96-107; Schwarzer, G., Vach, W., Schumacher, M., On the misuses of artificial neural networks for prognostic and diagnostic classification in oncology (2000) Stat. Med., 19, pp. 541-561; Lisboa, P., A review of evidence of health benefit from artificial neural networks in medical intervention (2002) Neural Networks, 15, pp. 11-39; Mitchell, T., (1997) Machine learning, , New York: McGraw-Hill; Dreiseitl, S., A comparison of machine learning methods for the diagnosis of pigmented skin lesions (2001) J. Biomed. Inform., 34, pp. 28-36; Chang, R., Support vector machines for diagnosis of breast tumors on US images (2003) Acad. Radiol., 10, pp. 189-197; Salzberg, S., On comparing classifiers: Pitfalls to avoid and a recommended approach (1997) Data Min. Knowl. Disc, 1, pp. 317-328; Harrell, F., Lee, K., Mark, D., Multivariable prognostic models: Issues in developing models, evaluation assumptions and adequacy, and measuring and reducing errors (1996) Stat. Med., 15, pp. 361-387; Hilden, J., Neural networks and the roles of cross validation (1998) Med. Decis. Making, 18, pp. 122-124; Steyerberg, E., Harrell, F., Goodman, P., Neural networks, logistic regression, and calibration (1998) Med. Decis. Making, 18, pp. 349-350; Steyerberg, E., Harrell, F., Goodman, P., Neural networks, logistic regression, and calibration: A rejoinder (1998) Med. Decis. Making, 18, pp. 445-446",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Litjens G., Kooi T., Bejnordi B.E., Setio A.A.A., Ciompi F., Ghafoorian M., van der Laak J.A.W.M., van Ginneken B., Sánchez C.I.",36622356600;41261813100;56986708300;53264801600;32667506900;55841332000;6701833644;57202688150;8543425100;,A survey on deep learning in medical image analysis,2017,Medical Image Analysis,10.1016/j.media.2017.07.005,https://www.scopus.com/inward/record.uri?eid=2-s2.0-85026529300&doi=10.1016%2fj.media.2017.07.005&partnerID=40&md5=7a8f8ab63ff9d2cdaab2acbbea2e9c2f,"Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research. © 2017 Elsevier B.V.",Convolutional neural networks; Deep learning; Medical imaging; Survey,"Convolution; Image segmentation; Learning algorithms; Medical imaging; Neural networks; Object detection; Surveying; Surveys; Application area; Convolutional networks; Convolutional neural network; Critical discussions; Digital pathologies; State of the art; Deep learning; abdomen; anatomic landmark; artificial neural network; brain; breast; classification; computer; diagnostic imaging; digital imaging; eye; human; image analysis; image enhancement; image retrieval; image segmentation; learning; learning algorithm; priority journal; registration; Review; software; thorax; unsupervised machine learning; algorithm; artificial neural network; diagnostic imaging; image processing; machine learning; procedures; Algorithms; Diagnostic Imaging; Humans; Image Processing, Computer-Assisted; Machine Learning; Neural Networks (Computer)","",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ional architecture for fast feature embedding (2014) Proceedings of the Twenty-Second ACM International Conference on Multimedia, pp. 675-678; Kainz, P., Pfeiffer, M., Urschler, M., Semantic segmentation of colon glands with deep convolutional neural networks and total variation segmentation (2015), arxiv: 1511.06919; Källén, H., Molin, J., Heyden, A., Lundstr, C., Aström, K., Towards grading gleason score using generically trained deep convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1163-1167; Kallenberg, M., Petersen, K., Nielsen, M., Ng, A., Diao, P., Igel, C., Vachon, C., Lillholm, M., Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring (2016) IEEE Trans. Med. Imaging,35, pp. 1322-1331; Kamnitsas, K., Ledig, C., Newcombe, V.F., Simpson, J.P., Kane, A.D., Menon, D.K., Rueckert, D., Glocker, B., Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation (2017) Med. Image Anal.,36, pp. 61-78; Karpathy, A., Fei-Fei, L., Deep visual-semantic alignments for generating image descriptions (2015) Proceedings of the Computer Vision and Pattern Recognition, , arxiv:1412.2306; Kashif, M.N., Raza, S.E.A., Sirinukunwattana, K., Arif, M., Rajpoot, N., Handcrafted features with convolutional neural networks for detection of tumor cells in histology images (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1029-1032; Kawahara, J., BenTaieb, A., Hamarneh, G., Deep features to classify skin lesions (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1397-1400; Kawahara, J., Brown, C.J., Miller, S.P., Booth, B.G., Chau, V., Grunau, R.E., Zwicker, J.G., Hamarneh, G., Brainnetcnn: convolutional neural networks for brain networks; towards predicting neurodevelopment (2016) Neuroimage; Kawahara, J., Hamarneh, G., Multi-resolution-tract CNN with hybrid pretrained and skin-lesion trained layers (2016) Proceedings of the Machine Learning in Medical Imaging, Lecture Notes in Computer Science,10019, pp. 164-171; Kendall, A., Gal, Y., What uncertainties do we need in Bayesian deep learning for computer vision? arXiv (2017), arXiv: 1703.04977; Kim, E., Cortre-Real, M., Baloch, Z., A deep semantic mobile application for thyroid cytopathology (2016) Proceedings of the SPIE on Medical Imaging,9789, p. 97890A; Kim, H., Hwang, S., Scale-invariant feature learning using deconvolutional neural networks for weakly-supervised semantic segmentation (2016), arxiv: 1602.04984; Kim, J., Calhoun, V.D., Shim, E., Lee, J.-H., Deep neural network with weight sparsity control and pre-training extracts hierarchical features and enhances classification performance: evidence from whole-brain resting-state functional connectivity patterns of schizophrenia (2016) Neuroimage,124, pp. 127-146; Kingma, D.P., Welling, M., Auto-encoding variational bayes (2013), arxiv: 1312.6114; Kisilev, P., Sason, E., Barkan, E., Hashoul, S., Medical image description using multi-task-loss CNN (2016) Proceedings of the International Workshop on Large-Scale Annotation of Biomedical Data and Expert Label Synthesis, pp. 121-129. , Springer; Kleesiek, J., Urban, G., Hubert, A., Schwarz, D., Maier-Hein, K., Bendszus, M., Biller, A., Deep MRI brain extraction: a 3D convolutional neural network for skull stripping. (2016) Neuroimage,129, pp. 460-469; Kong, B., Zhan, Y., Shin, M., Denny, T., Zhang, S., Recognizing end-diastole and end-systole frames via deep temporal regression network (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 264-272; Kooi, T., van Ginneken, B., Karssemeijer, N., den Heeten, A., Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network (2017) Med. Phys, 44 (3), pp. 1017-1027; Kooi, T., Litjens, G., van Ginneken, B., Gubern-Mérida, A., Sánchez, C.I., Mann, R., den Heeten, A., Karssemeijer, N., Large scale deep learning for computer aided detection of mammographic lesions (2016) Med. Image Anal.,35, pp. 303-312; Korez, R., Likar, B., Pernuš, F., Vrtovec, T., Model-based segmentation of vertebral bodies from MR images with 3D CNNs (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 433-441. , Springer; Krizhevsky, A., Sutskever, I., Hinton, G., Imagenet classification with deep convolutional neural networks (2012) Proceedings of the Advances in Neural Information Processing Systems, pp. 1097-1105; Kumar, A., Sridar, P., Quinton, A., Kumar, R.K., Feng, D., Nanan, R., Kim, J., Plane identification in fetal ultrasound images using saliency maps and convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 791-794; LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., Gradient-based learning applied to document recognition (1998) Proc. IEEE,86, pp. 2278-2324; Lekadir, K., Galimzianova, A., Betriu, A., Del Mar Vila, M., Igual, L., Rubin, D.L., Fernandez, E., Napel, S., A convolutional neural network for automatic characterization of plaque composition in carotid ultrasound (2017) IEEE J. Biomed. Health Inf.,21, pp. 48-55; Lessmann, N., Isgum, I., Setio, A.A., de Vos, B.D., Ciompi, F., de Jong, P.A., Oudkerk, M., van Ginneken, B., Deep convolutional neural networks for automatic coronary calcium scoring in a screening study with low-dose chest CT (2016) Proceedings of the SPIE on Medical Imaging,9785, 978511-1–978511-6; Li, R., Zhang, W., Suk, H.-I., Wang, L., Li, J., Shen, D., Ji, S., Deep learning based imaging data completion for improved brain disease diagnosis (2014) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8675, pp. 305-312; Li, W., Cao, P., Zhao, D., Wang, J., Pulmonary nodule classification with deep convolutional neural networks on computed tomography images (2016) Comput. Math. Methods Med., p. 6215085; Li, W., Jia, F., Hu, Q., Automatic segmentation of liver tumor in CT images with deep convolutional neural networks (2015) J. Comput. Commun., 3 (11), pp. 146-151; Li, W., Manivannan, S., Akbar, S., Zhang, J., Trucco, E., McKenna, S.J., Gland segmentation in colon histology images using hand-crafted features and convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1405-1408; Liao, S., Gao, Y., Oto, A., Shen, D., Representation learning: A unified deep learning framework for automatic prostate mr segmentation (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 254-261; Lin, M., Chen, Q., Yan, S., Network in network (2013), arxiv: 1312.4400; Litjens, G., Sánchez, C.I., Timofeeva, N., Hermsen, M., Nagtegaal, I., Kovacs, I., Hulsbergen-van de Kaa, C., van der Laak, J., Deep learning as a tool for increased accuracy and efficiency of histopathological diagnosis (2016) Nat. Sci. Rep.,6, p. 26286; Liu, J., Wang, D., Wei, Z., Lu, L., Kim, L., Turkbey, E., Summers, R.M., Colitis detection on computed tomography using regional convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 863-866; Liu, X., Tizhoosh, H.R., Kofman, J., Generating binary tags for fast medical image retrieval based on convolutional nets and Radon transform (2016) Proceedings of the International Joint Conference on Neural Networks, , arxiv:1604.04676; Liu, Y., Gadepalli, K., Norouzi, M., Dahl, G.E., Kohlberger, T., Boyko, A., Venugopalan, S., Stumpe, M.C., Detecting cancer metastases on gigapixel pathology images (2017), arxiv: 1703.02442; Lo, S.-C., Lou, S.-L., Lin, J.-S., Freedman, M.T., Chien, M.V., Mun, S.K., Artificial convolution neural network techniques and applications for lung nodule detection (1995) IEEE Trans. Med. Imaging,14, pp. 711-718; Long, J., Shelhamer, E., Darrell, T., Fully convolutional networks for semantic segmentation (2015), arxiv: 1411.4038; Lu, F., Wu, F., Hu, P., Peng, Z., Kong, D., Automatic 3D liver location and segmentation via convolutional neural network and graph cut (2017) Int. J. Comput. Assist. Radiol. Surg.,12, pp. 171-182; Lu, X., Xu, D., Liu, D., Robust 3d organ localization with dual learning architectures and fusion (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 12-20; Ma, J., Wu, F., Zhu, J., Xu, D., Kong, D., A pre-trained convolutional neural network based method for thyroid nodule diagnosis. (2017) Ultrasonics,73, pp. 221-230; Mahapatra, D., Roy, P.K., Sedai, S., Garnavi, R., Retinal image quality classification using saliency maps and CNNs (2016) Proceedings of the Machine Learning in Medical Imaging, Lecture Notes in Computer Science,10019, pp. 172-179; Malon, C.D., Cosatto, E., Classification of mitotic figures with convolutional neural networks and seeded blob features. (2013) J. Pathol. Inform.; Maninis, K.-K., Pont-Tuset, J., Arbeláez, P., Gool, L., Deep retinal image understanding (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 140-148; Mansoor, A., Cerrolaza, J., Idrees, R., Biggs, E., Alsharid, M., Avery, R., Linguraru, M.G., Deep learning guided partitioned shape model for anterior visual pathway segmentation (2016) IEEE Trans. Med. Imaging, 35 (8), pp. 1856-1865; Mao, Y., Yin, Z., A hierarchical convolutional neural network for mitosis detection in phase-contrast microscopy images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 685-692; Menegola, A., Fornaciali, M., Pires, R., Avila, S., Valle, E., Towards automated melanoma screening: exploring transfer learning schemes (2016), arxiv: 1609.01228; Merkow, J., Kriegman, D., Marsden, A., Tu, Z., Dense volume-to-volume vascular boundary detection (2016), arxiv: 1605.08401; Miao, S., Wang, Z.J., Liao, R., A CNN regression approach for real-time 2D/3D registration (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1352-1363; Milletari, F., Ahmadi, S.-A., Kroll, C., Plate, A., Rozanski, V., Maiostre, J., Levin, J., Navab, N.,-2016, Hough-CNN: deep learning for segmentation of deep brain regions in MRI and ultrasound. arxiv: 1601.07014; Milletari, F., Navab, N., Ahmadi, S.-A.,-2016, V-Net: fully convolutional neural networks for volumetric medical image segmentation. arxiv: 1606.04797; Mishra, M., Schmitt, S., Wang, L., Strasser, M.K., Marr, C., Navab, N., Zischka, H., Peng, T., Structure-based assessment of cancerous mitochondria using deep networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 545-548; Moeskops, P., Viergever, M.A., Mendrik, A.M., de Vries, L.S., Benders, M.J.N.L., Isgum, I., Automatic segmentation of MR brain images with a convolutional neural network (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1252-1262; Moeskops, P., Wolterink, J.M., Velden, B.H.M., Gilhuijs, K.G.A., Leiner, T., Viergever, M.A., Isgum, I., Deep learning for multi-task medical image segmentation in multiple modalities (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 478-486; Montavon, G., Lapuschkin, S., Binder, A., Samek, W., Müller, K.-R., Explaining nonlinear classification decisions with deep taylor decomposition (2017) Pattern Recognit.,65, pp. 211-222; Moradi, M., Guo, Y., Gur, Y., Negahdar, M., Syeda-Mahmood, T., A cross-modality neural network transform for semi-automatic medical image annotation (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 300-307; Moradi, M., Gur, Y., Wang, H., Prasanna, P., Syeda-Mahmood, T., A hybrid learning approach for semantic labeling of cardiac CT slices and recognition of body position (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging; Nappi, J.J., Hironaka, T., Regge, D., Yoshida, H., Deep transfer learning of virtual endoluminal views for the detection of polyps in CT colonography (2016) Proceedings of the Medical Imaging, p. 97852B; Nascimento, J.C., Carneiro, G., Multi-atlas segmentation using manifold learning with deep belief networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 867-871; Ngo, T.A., Lu, Z., Carneiro, G., Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance (2017) Med. Image Anal.,35, pp. 159-171; Nie, D., Cao, X., Gao, Y., Wang, L., Shen, D., Estimating CT image from MRI data using 3D fully convolutional networks (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 170-178; Nie, D., Wang, L., Gao, Y., Shen, D., Fully convolutional networks for multi-modality isointense infant brain image segmentation (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1342-1345; Nie, D., Zhang, H., Adeli, E., Liu, L., Shen, D., 3D deep learning for multi-modal imaging-guided survival time prediction of brain tumor patients (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 212-220; Nogues, I., Lu, L., Wang, X., Roth, H., Bertasius, G., Lay, N., Shi, J., Summers, R.M., Automatic lymph node cluster segmentation using holistically-nested neural networks and structured optimization in CT images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 388-397; Oktay, O., Bai, W., Lee, M., Guerrero, R., Kamnitsas, K., Caballero, J., Marvao, A., Rueckert, D., Multi-input cardiac image super-resolution using convolutional neural networks (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9902, pp. 246-254; Ortiz, A., Munilla, J., Górriz, J.M., Ramírez, J., Ensembles of deep learning architectures for the early diagnosis of the Alzheimer's disease (2016) Int. J. Neural Syst.,26, p. 1650025; Paeng, K., Hwang, S., Park, S., Kim, M., Kim, S., A unified framework for tumor proliferation score prediction in breast histopathology (2016), arxiv: 1612.07180; Pan, Y., Huang, W., Lin, Z., Zhu, W., Zhou, J., Wong, J., Ding, Z., Brain tumor grading based on neural networks and convolutional neural networks (2015) Proceedings of the IEEE Engineering in Medicine and Biology Society, pp. 699-702; Payan, A., Montana, G., Predicting Alzheimer's disease: a neuroimaging study with 3D convolutional neural networks (2015), arxiv: 1502.02506; Payer, C., Stern, D., Bischof, H., Urschler, M., Regressing heatmaps for multiple landmark localization using CNNs (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 230-238; Pereira, S., Pinto, A., Alves, V., Silva, C.A., Brain tumor segmentation using convolutional neural networks in MRI images (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1240-1251; Phan, H.T.H., Kumar, A., Kim, J., Feng, D., Transfer learning of a convolutional neural network for HEp-2 cell image classification (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1208-1211; Pinaya, W.H.L., Gadelha, A., Doyle, O.M., Noto, C., Zugman, A., Cordeiro, Q., Jackowski, A.P., Sato, J.R., Using deep belief network modelling to characterize differences in brain morphometry in schizophrenia (2016) Nat. Sci. Rep.,6, p. 38897; Plis, S.M., Hjelm, D.R., Salakhutdinov, R., Allen, E.A., Bockholt, H.J., Long, J.D., Johnson, H.J., Calhoun, V.D., Deep learning for neuroimaging: a validation study (2014) Front. Neurosci.; Poudel, R.P.K., Lamata, P., Montana, G., Recurrent fully convolutional neural networks for multi-slice MRI cardiac segmentation (2016), arxiv: 1608.03974; Prasoon, A., Petersen, K., Igel, C., Lauze, F., Dam, E., Nielsen, M., Deep feature learning for knee cartilage segmentation using a triplanar convolutional neural network (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 246-253; Prentasic, P., Heisler, M., Mammo, Z., Lee, S., Merkur, A., Navajas, E., Beg, M.F., Loncaric, S., Segmentation of the foveal microvasculature using deep learning networks. (2016) J. Biomed. Opt.,21, p. 75008; Prentasic, P., Loncaric, S., Detection of exudates in fundus photographs using deep neural networks and anatomical landmark detection fusion (2016) Comput. Methods Programs Biomed.,137, pp. 281-292; Qiu, Y., Wang, Y., Yan, S., Tan, M., Cheng, S., Liu, H., Zheng, B., An initial investigation on developing a new method to predict short-term breast cancer risk based on deep learning technology (2016) Proceedings of the SPIE Medical Imaging,9785, p. 978521; Quinn, J.A., Nakasi, R., Mugagga, P.K.B., Byanyima, P., Lubega, W., Andama, A., Deep convolutional neural networks for microscopy-based point of care diagnostics (2016), arxiv: 1608.02989; Rajchl, M., Lee, M.C., Oktay, O., Kamnitsas, K., Passerat-Palmbach, J., Bai, W., Kainz, B., Rueckert, D., Deepcut: object segmentation from bounding box annotations using convolutional neural networks (2017) IEEE Trans. Med. Imaging, 36 (2), pp. 674-683; Rajchl, M., Lee, M.C., Schrans, F., Davidson, A., Passerat-Palmbach, J., Tarroni, G., Alansary, A., Rueckert, D., Learning under distributed weak supervision (2016), arxiv: 1606.01100; Rajkomar, A., Lingam, S., Taylor, A.G., Blum, M., Mongan, J., High-throughput classification of radiographs using deep convolutional neural networks (2017) J. Digit. Imaging,30, pp. 95-101; Ravi, D., Wong, C., Deligianni, F., Berthelot, M., Andreu-Perez, J., Lo, B., Yang, G.-Z., Deep learning for health informatics. (2017) IEEE J. Biomed. Health Inf.,21, pp. 4-21; Ravishankar, H., Prabhu, S.M., Vaidya, V., Singhal, N., Hybrid approach for automatic segmentation of fetal abdomen from ultrasound images using deep learning (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 779-782; Ravishankar, H., Sudhakar, P., Venkataramani, R., Thiruvenkadam, S., Annangi, P., Babu, N., Vaidya, V., Understanding the mechanisms of deep transfer learning for medical images (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 188-196; Rezaeilouyeh, H., Mollahosseini, A., Mahoor, M.H., Microscopic medical image classification framework via deep learning and shearlet transform (2016) J. Med. Imaging, 3 (4), p. 044501; Romo-Bucheli, D., Janowczyk, A., Gilmore, H., Romero, E., Madabhushi, A., Automated tubule nuclei quantification and correlation with Oncotype DX risk categories in ER+ breast cancer whole slide images (2016) Nat. Sci. Rep.,6, p. 32706; Ronneberger, O., Fischer, P., Brox, T., U-net: convolutional networks for biomedical image segmentation (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9351, pp. 234-241; Roth, H.R., Lee, C.T., Shin, H.-C., Seff, A., Kim, L., Yao, J., Lu, L., Summers, R.M., Anatomy-specific classification of medical images using deep convolutional nets (2015) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 101-104; Roth, H.R., Lu, L., Farag, A., Shin, H.-C., Liu, J., Turkbey, E.B., Summers, R.M., DeepOrgan: Multi-level deep convolutional networks for automated pancreas segmentation (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9349, pp. 556-564; Roth, H.R., Lu, L., Farag, A., Sohn, A., Summers, R.M., Spatial aggregation of holistically-nested networks for automated pancreas segmentation (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 451-459; Roth, H.R., Lu, L., Liu, J., Yao, J., Seff, A., Cherry, K., Kim, L., Summers, R.M., Improving computer-aided detection using convolutional neural networks and random view aggregation (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1170-1181; Roth, H.R., Lu, L., Seff, A., Cherry, K.M., Hoffman, J., Wang, S., Liu, J., Summers, R.M., A new 2.5D representation for lymph node detection using random sets of deep convolutional neural network observations (2014) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8673, pp. 520-527; Roth, H.R., Wang, Y., Yao, J., Lu, L., Burns, J.E., Summers, R.M., Deep convolutional networks for automated detection of posterior-element fractures on spine CT (2016) Proceedings of the SPIE of Medical Imaging,9785, p. 97850P; Roth, H.R., Yao, J., Lu, L., Stieger, J., Burns, J.E., Summers, R.M., Detection of sclerotic spine metastases via random aggregation of deep convolutional?neural network classifications (2015) Proceedings of the Recent Advances in Computational Methods and Clinical Applications for Spine Imaging, Lecture Notes in Computational Vision and Biomechanics,20, pp. 3-12; Rupprecht, C., Huaroc, E., Baust, M., Navab, N., Deep active contours (2016), arxiv: 1607.05074; Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z., Fei-Fei, L., Imagenet large scale visual recognition challenge (2014) Int. J. Comput. Vis., 115 (3), pp. 1-42; Sahiner, B., Chan, H.-P., Petrick, N., Wei, D., Helvie, M.A., Adler, D.D., Goodsitt, M.M., Classification of mass and normal breast tissue: a convolution neural network classifier with spatial domain and texture images (1996) IEEE Trans. Med. Imaging,15, pp. 598-610; Samala, R.K., Chan, H.-P., Hadjiiski, L., Cha, K., Helvie, M.A., Deep-learning convolution neural network for computer-aided detection of microcalcifications in digital breast tomosynthesis (2016) Proceedings of the SPIE on Medical Imaging,9785, p. 97850Y; Samala, R.K., Chan, H.-P., Hadjiiski, L., Helvie, M.A., Wei, J., Cha, K., Mass detection in digital breast tomosynthesis: deep convolutional neural network with transfer learning from mammography (2016) Med. Phys., 43 (12), pp. 6654-6666; Sarraf, S., Tofighi, G., Classification of Alzheimer's disease using fmri data and deep learning convolutional neural networks (2016), arxiv: 1603.08631; Schaumberg, A.J., Rubin, M.A., Fuchs, T.J., H&e-stained whole slide deep learning predicts SPOP mutation state in prostate cancer (2016), http://biorxiv.org/content/early/2016/07/21/064279.full.pdf, arxiv: 064279. 10.1101/064279; Schlegl, T., Waldstein, S.M., Vogl, W.-D., Schmidt-Erfurth, U., Langs, G., Predicting semantic descriptions from medical images with convolutional neural networks (2015) Proceedings of the Information Processing in Medical Imaging, Lecture Notes in Computer Science,9123, pp. 437-448; Sethi, A., Sha, L., Vahadane, A.R., Deaton, R.J., Kumar, N., Macias, V., Gann, P.H., Empirical comparison of color normalization methods for epithelial-stromal classification in h and e images (2016) J. Pathol. Inf.,7, p. 17; Setio, A.A.A., Ciompi, F., Litjens, G., Gerke, P., Jacobs, C., van Riel, S., Wille, M.W., van Ginneken, B., Pulmonary nodule detection in CT images: false positive reduction using multi-view convolutional networks (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1160-1169; Sevetlidis, V., Giuffrida, M.V., Tsaftaris, S.A., Whole image synthesis using a deep encoder–decoder network (2016) Proceedings of the Simulation and Synthesis in Medical Imaging, Lecture Notes in Computer Science,9968, pp. 127-137; Shah, A., Conjeti, S., Navab, N., Katouzian, A., Deeply learnt hashing forests for content based image retrieval in prostate MR images (2016) Proceedings of the SPIE on Medical Imaging,9784, p. 978414; Shakeri, M., Tsogkas, S., Ferrante, E., Lippe, S., Kadoury, S., Paragios, N., Kokkinos, I., Sub-cortical brain structure segmentation using F-CNNs (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 269-272; Shen, D., Wu, G., Suk, H.-I., Deep learning in medical image analysis. (2017) Annu. Rev. Biomed. Eng.; Shen, W., Yang, F., Mu, W., Yang, C., Yang, X., Tian, J., Automatic localization of vertebrae based on convolutional neural networks (2015) Proceedings of the SPIE on Medical Imaging,9413, p. 94132E; Shen, W., Zhou, M., Yang, F., Dong, D., Yang, C., Zang, Y., Tian, J., Learning from experts: Developing transferable deep features for patient-level lung cancer prediction (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 124-131; Shen, W., Zhou, M., Yang, F., Yang, C., Tian, J., Multi-scale convolutional neural networks for lung nodule classification (2015) Proceedings of the Information Processing in Medical Imaging, Lecture Notes in Computer Science,9123, pp. 588-599; Shi, J., Zheng, X., Li, Y., Zhang, Q., Ying, S., Multimodal neuroimaging feature learning with multimodal stacked deep polynomial networks for diagnosis of aLzheimer's disease (2017) IEEE J. Biomed. Health Inf., , in press; Shin, H.-C., Lu, L., Kim, L., Seff, A., Yao, J., Summers, R.M., Interleaved text/image deep mining on a very large-scale radiology database (2015) Proceedings of the Computer Vision and Pattern Recognition, pp. 1090-1099; Shin, H.-C., Orton, M.R., Collins, D.J., Doran, S.J., Leach, M.O., Stacked autoencoders for unsupervised feature learning and multiple organ detection in a pilot study using 4D patient data (2013) IEEE Trans. Pattern Anal. Mach. Intell.,35, pp. 1930-1943; Shin, H.-C., Roberts, K., Lu, L., Demner-Fushman, D., Yao, J., Summers, R.M.,-2016, Learning to read chest x-rays: recurrent neural cascade model for automated image annotation. arxiv: 1603.08486; Shin, H.-C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J., Summers, R.M., Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1285-1298; Shkolyar, A., Gefen, A., Benayahu, D., Greenspan, H., Automatic detection of cell divisions (mitosis) in live-imaging microscopy images using convolutional neural networks (2015) Proceedings of the IEEE Engineering in Medicine and Biology Society, pp. 743-746; Simonovsky, M., Gutiérrez-Becker, B., Mateus, D., Navab, N., Komodakis, N., A deep metric for multimodal registration (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9902, pp. 10-18; Simonyan, K., Zisserman, A., Very deep convolutional networks for large-scale image recognition (2014), arxiv: 1409.1556; Sirinukunwattana, K., Raza, S.E.A., Tsang, Y.-W., Snead, D.R., Cree, I.A., Rajpoot, N.M., Locality sensitive deep learning for detection and classification of nuclei in routine colon cancer histology images (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1196-1206; Smistad, E., Løvstakken, L., Vessel detection in ultrasound images using deep convolutional neural networks (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 30-38; Snoek, J., Larochelle, H., Adams, R.P., Practical Bayesian optimization of machine learning algorithms (2012) Proceedings of the Advances in Neural Information Processing Systems, pp. 2951-2959; Song, Y., Tan, E.-L., Jiang, X., Cheng, J.-Z., Ni, D., Chen, S., Lei, B., Wang, T., Accurate cervical cell segmentation from overlapping clumps in pap smear images (2017) IEEE Trans. Med. Imaging,36, pp. 288-300; Song, Y., Zhang, L., Chen, S., Ni, D., Lei, B., Wang, T., Accurate segmentation of cervical cytoplasm and nuclei based on multiscale convolutional network and graph partitioning (2015) IEEE Trans. Biomed. Eng., 62 (10), pp. 2421-2433; Spampinato, C., Palazzo, S., Giordano, D., Aldinucci, M., Leonardi, R., Deep learning for automated skeletal bone age assessment in X-ray images (2017) Med. Image Anal.,36, pp. 41-51; Springenberg, J.T., Dosovitskiy, A., Brox, T., Riedmiller, M., Striving for simplicity: the all convolutional net (2014), arxiv: 1412.6806; Štern, D., Payer, C., Lepetit, V., Urschler, M., Automated age estimation from hand MRI volumes using deep learning (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 194-202; Stollenga, M.F., Byeon, W., Liwicki, M., Schmidhuber, J., Parallel multi-dimensional LSTM, with application to fast biomedical volumetric image segmentation (2015) Proceedings of the Advances in Neural Information Processing Systems, pp. 2998-3006; Suk, H.-I., Lee, S.-W., Shen, D., Hierarchical feature representation and multimodal fusion with deep learning for AD/MCI diagnosis (2014) Neuroimage,101, pp. 569-582; Suk, H.-I., Lee, S.-W., Shen, D., Latent feature representation with stacked auto-encoder for AD/MCI diagnosis (2015) Brain Struct. Funct.,220, pp. 841-859; Suk, H.-I., Shen, D., Deep learning-based feature representation for AD/MCI classification (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 583-590; Suk, H.-I., Shen, D., Deep ensemble sparse regression network for Alzheimer's disease diagnosis (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,10019, pp. 113-121; Suk, H.-I., Wee, C.-Y., Lee, S.-W., Shen, D., State-space model with deep learning for functional dynamics estimation in resting-state FMRI (2016) Neuroimage,129, pp. 292-307; Sun, W., Tseng, T.-L.B., Zhang, J., Qian, W., Enhancing deep convolutional neural network scheme for breast cancer diagnosis with unlabeled data. (2016) Comput. Med. Imaging Graph; Sun, W., Zheng, B., Qian, W., Computer aided lung cancer diagnosis with deep learning algorithms (2016) Proceedings of the SPIE Medical Imaging,9785, p. 97850Z; Suzani, A., Rasoulian, A., Seitel, A., Fels, S., Rohling, R., Abolmaesumi, P., Deep learning for automatic localization, identification, and segmentation of vertebral bodies in volumetric MR images (2015) Proceedings of the SPIE Medical Imaging,9415, p. 941514; Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Rabinovich, A., Going deeper with convolutions (2014), arxiv: 1409.4842; Tachibana, R., Näppi, J.J., Hironaka, T., Kim, S.H., Yoshida, H., Deep learning for electronic cleansing in dual-energy ct colonography (2016) Proceedings of the SPIE Medical Imaging,9785, p. 97851M; Tajbakhsh, N., Gotway, M.B., Liang, J., Computer-aided pulmonary embolism detection using a novel vessel-aligned multi-planar image representation and convolutional neural networks (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9350, pp. 62-69; Tajbakhsh, N., Gurudu, S.R., Liang, J., A comprehensive computer-aided polyp detection system for colonoscopy videos (2015) Proceedings of the Information Processing in Medical Imaging, Lecture Notes in Computer Science,9123, pp. 327-338; Tajbakhsh, N., Shin, J.Y., Gurudu, S.R., Hurst, R.T., Kendall, C.B., Gotway, M.B., Liang, J., Convolutional neural networks for medical image analysis: fine tuning or full training? (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1299-1312; Tarando, S.R., Fetita, C., Faccinetto, A., Yves, P., Increasing CAD system efficacy for lung texture analysis using a convolutional network (2016) Proceedings of the SPIE on Medical Imaging,9785, 97850Q–97850Q; Teikari, P., Santos, M., Poon, C., Hynynen, K., Deep learning convolutional networks for multiphoton microscopy vasculature segmentation (2016), arxiv: 1606.02382; Teramoto, A., Fujita, H., Yamamuro, O., Tamaki, T., Automated detection of pulmonary nodules in PET/CT images: ensemble false-positive reduction using a convolutional neural network technique (2016) Med. Phys.,43, pp. 2821-2827; Thong, W., Kadoury, S., Piché, N., Pal, C.J., Convolutional networks for kidney segmentation in contrast-enhanced CT scans (2016) Computer. Methods Biomech. Biomed. Eng. Imag. Vis., pp. 1-6; Tran, P.V., A fully convolutional neural network for cardiac segmentation in short-axis MRI (2016), arxiv: 1604.00494; Turkki, R., Linder, N., Kovanen, P.E., Pellinen, T., Lundin, J., Antibody-supervised deep learning for quantification of tumor-infiltrating immune cells in hematoxylin and eosin stained breast cancer samples. (2016) J. Pathol. Inf.,7, p. 38; Twinanda, A.P., Shehata, S., Mutter, D., Marescaux, J., de Mathelin, M., Padoy, N., Endonet: a deep architecture for recognition tasks on laparoscopic videos (2017) IEEE Trans. Med. Imaging,36, pp. 86-97; van der Burgh, H.K., Schmidt, R., Westeneng, H.-J., de Reus, M.A., van den Berg, L.H., van den Heuvel, M.P., Deep learning predictions of survival based on MRI in amyotrophic lateral sclerosis (2017) Neuroimage Clin.,13, pp. 361-369; van Ginneken, B., Setio, A.A., Jacobs, C., Ciompi, F., Off-the-shelf convolutional neural network features for pulmonary nodule detection in computed tomography scans (2015) Proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 286-289; van Grinsven, M.J.J.P., van Ginneken, B., Hoyng, C.B., Theelen, T., Sánchez, C.I., Fast convolutional neural network training using selective data sampling: application to hemorrhage detection in color fundus images (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1273-1284; van Tulder, G., de Bruijne, M., Combining generative and discriminative representation learning for lung CT analysis with convolutional Restricted Boltzmann machines (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1262-1272; Veta, M., van Diest, P.J., Pluim, J.P.W., Cutting out the middleman: measuring nuclear area in histopathology slides without segmentation (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 632-639; Vincent, P., Larochelle, H., Lajoie, I., Bengio, Y., Manzagol, P.-A., Stacked denoising autoencoders: learning useful representations in a deep network with a local denoising criterion (2010) J. Mach. Learn. Res.,11, pp. 3371-3408; Vivanti, R., Ephrat, A., Joskowicz, L., Karaaslan, O., Lev-Cohain, N., Sosna, J., Automatic liver tumor segmentation in follow-up CT studies using convolutional neural networks (2015) Proceedings of the Patch-Based Methods in Medical Image Processing Workshop, MICCAI’2015, pp. 54-61; Wang, C., Elazab, A., Wu, J., Hu, Q., Lung nodule classification using deep feature fusion in chest radiography (2016) Comput. Med. Imaging Graph; Wang, C., Yan, X., Smith, M., Kochhar, K., Rubin, M., Warren, S.M., Wrobel, J., Lee, H., A unified framework for automatic wound segmentation and analysis with deep convolutional neural networks (2015) Proceedings of the IEEE Engineering in Medicine and Biology Society, pp. 2415-2418; Wang, D., Khosla, A., Gargeya, R., Irshad, H., Beck, A.H.,-2016, Deep learning for identifying metastatic breast cancer. arxiv: 1606.05718; Wang, G., A perspective on deep imaging (2016) IEEE Access,4, pp. 8914-8924; Wang, H., Cruz-Roa, A., Basavanhally, A., Gilmore, H., Shih, N., Feldman, M., Tomaszewski, J., Madabhushi, A., Mitosis detection in breast cancer pathology images by combining handcrafted and convolutional neural network features (2014) J. Med. Imaging,1, p. 034003; Wang, J., Ding, H., Azamian, F., Zhou, B., Iribarren, C., Molloi, S., Baldi, P., Detecting cardiovascular disease from mammograms with deep learning (2017) IEEE Trans. Med. Imaging; Wang, J., MacKenzie, J.D., Ramachandran, R., Chen, D.Z., A deep learning approach for semantic segmentation in histology tissue images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 176-184. , Springer; Wang, S., Yao, J., Xu, Z., Huang, J., Subtype cell detection with an accelerated deep convolution neural network (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 640-648; Wang, X., Lu, L., Shin, H.-C., Kim, L., Nogues, I., Yao, J., Summers, R.,-2016, Unsupervised category discovery via looped deep pseudo-task optimization using a large scale radiology image database. arxiv: 1603.07965; Wolterink, J.M., Leiner, T., de Vos, B.D., van Hamersvelt, R.W., Viergever, M.A., Isgum, I., Automatic coronary artery calcium scoring in cardiac CT angiography using paired convolutional neural networks (2016) Med. Image Anal.,34, pp. 123-136; Worrall, D.E., Wilson, C.M., Brostow, G.J., Automated retinopathy of prematurity case detection with convolutional neural networks (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 68-76; Wu, A., Xu, Z., Gao, M., Buty, M., Mollura, D.J., Deep vessel tracking: a generalized probabilistic approach via deep learning (2016) proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 1363-1367; Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., Shen, D., Unsupervised deep feature learning for deformable registration of MR brain images (2013) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,8150, pp. 649-656; Xie, W., Noble, J.A., Zisserman, A., Microscopy cell counting and detection with fully convolutional regression networks (2016) Comput. Methods Biomech. Biomed. Eng. Imaging Vis., pp. 1-10; Xie, Y., Kong, X., Xing, F., Liu, F., Su, H., Yang, L., Deep voting: a robust approach toward nucleus localization in microscopy images (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9351, pp. 374-382; Xie, Y., Xing, F., Kong, X., Su, H., Yang, L., Beyond classification: structured regression for robust cell detection using convolutional neural network (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9351, pp. 358-365; Xie, Y., Zhang, Z., Sapkota, M., Yang, L., Spatial clockwork recurrent neural network for muscle perimysium segmentation (2016) Proceedings of the International Conference on Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 185-193. , Springer; Xing, F., Xie, Y., Yang, L., An automatic learning-based framework for robust nucleus segmentation (2016) IEEE Trans. Med. Imaging, 35 (2), pp. 550-566; Xu, J., Luo, X., Wang, G., Gilmore, H., Madabhushi, A., A deep convolutional neural network for segmenting and classifying epithelial and stromal regions in histopathological images (2016) Neurocomputing,191, pp. 214-223; Xu, J., Xiang, L., Liu, Q., Gilmore, H., Wu, J., Tang, J., Madabhushi, A., Stacked sparse autoencoder (SSAE) for nuclei detection on breast cancer histopathology images (2016) IEEE Trans. Med. Imaging,35, pp. 119-130; Xu, T., Zhang, H., Huang, X., Zhang, S., Metaxas, D.N., Multimodal deep learning for cervical dysplasia diagnosis (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 115-123; Xu, Y., Li, Y., Liu, M., Wang, Y., Lai, M., Chang, E.I.-C.,-2016, Gland instance segmentation by deep multichannel side supervision. arxiv: 1607.03222; Xu, Y., Mo, T., Feng, Q., Zhong, P., Lai, M., Chang, E.I.C., Deep learning of feature representation with multiple instance learning for medical image analysis (2014) Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 1626-1630; Xu, Z., Huang, J., Detecting 10,000 Cells in one second (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 676-684; Xue, D.-X., Zhang, R., Feng, H., Wang, Y.-L., CNN-SVM For microvascular morphological type recognition with data augmentation (2016) J. Med. Biol. Eng.,36, pp. 755-764; Yan, Z., Zhan, Y., Peng, Z., Liao, S., Shinagawa, Y., Zhang, S., Metaxas, D.N., Zhou, X.S., Multi-instance deep learning: discover discriminative local anatomies for bodypart recognition (2016) IEEE Trans. Med. Imaging, 35 (5), pp. 1332-1343; Yang, D., Zhang, S., Yan, Z., Tan, C., Li, K., Metaxas, D., Automated anatomical landmark detection on distal femur surface using convolutional neural network (2015) proceedings of the IEEE International Symposium on Biomedical Imaging, pp. 17-21; Yang, H., Sun, J., Li, H., Wang, L., Xu, Z., Deep fusion net for multi-atlas segmentation: Application to cardiac mr images (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 521-528; Yang, L., Zhang, Y., Guldner, I.H., Zhang, S., Chen, D.Z., 3d segmentation of glial cells using fully convolutional networks and k-terminal cut (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 658-666. , Springer; Yang, W., Chen, Y., Liu, Y., Zhong, L., Qin, G., Lu, Z., Feng, Q., Chen, W., Cascade of multi-scale convolutional neural networks for bone suppression of chest radiographs in gradient domain. (2016) Med. Image Anal.,35, pp. 421-433; Yang, X., Kwitt, R., Niethammer, M., Fast predictive image registration (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 48-57; Yao, J., Wang, S., Zhu, X., Huang, J., Imaging biomarker discovery for lung cancer survival prediction (2016) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9901, pp. 649-657; Yoo, Y., Tang, L.W., Brosch, T., Li, D.K.B., Metz, L., Traboulsee, A., Tam, R., Deep learning of brain lesion patterns for predicting future disease activity in patients with early symptoms of multiple sclerosis (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 86-94; Ypsilantis, P.-P., Siddique, M., Sohn, H.-M., Davies, A., Cook, G., Goh, V., Montana, G., Predicting response to neoadjuvant chemotherapy with pet imaging using convolutional neural networks (2015) PLoS One, 10 (9), pp. 1-18; Yu, L., Chen, H., Dou, Q., Qin, J., Heng, P.A., Automated melanoma recognition in dermoscopy images via very deep residual networks (2017) IEEE Trans. Med. Imaging, 36 (4), pp. 994-1004; Yu, L., Guo, Y., Wang, Y., Yu, J., Chen, P., Segmentation of fetal left ventricle in echocardiographic sequences based on dynamic convolutional neural networks (2017) IEEE Trans. Biomed. Eng., 64 (8), pp. 1886-1895; Yu, L., Yang, X., Chen, H., Qin, J., Heng, P.A., Volumetric convnets with mixed residual connections for automated prostate segmentation from 3D MR images (2017) Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence; Zeiler, M.D., Fergus, R., Visualizing and understanding convolutional networks (2014) Proceedings of the European Conference on Computer Vision, pp. 818-833; Zhang, H., Li, L., Qiao, K., Wang, L., Yan, B., Li, L., Hu, G.,-2016, Image prediction for limited-angle tomography via deep learning with convolutional neural network. arxiv: 1607.08707; Zhang, L., Gooya, A., Dong, B.H.R., Petersen, S.E., Medrano-Gracia, K.P., Frangi, A.F., Automated quality assessment of cardiac MR images using convolutional neural networks (2016) Proceedings of the Simulation and Synthesis in Medical Imaging (SASHIMI), Lecture Notes in Computer Science,9968, pp. 138-145; Zhang, Q., Xiao, Y., Dai, W., Suo, J., Wang, C., Shi, J., Zheng, H., Deep learning based classification of breast tumors with shear-wave elastography (2016) Ultrasonics,72, pp. 150-157; Zhang, R., Zheng, Y., Mak, T.W.C., Yu, R., Wong, S.H., Lau, J.Y.W., Poon, C.C.Y., Automatic detection and classification of colorectal polyps by transferring low-level CNN features from nonmedical domain (2017) IEEE J. Biomed. Health Inf.,21, pp. 41-47; Zhang, W., Li, R., Deng, H., Wang, L., Lin, W., Ji, S., Shen, D., Deep convolutional neural networks for multi-modality isointense infant brain image segmentation (2015) Neuroimage,108, pp. 214-224; Zhao, J., Zhang, M., Zhou, Z., Chu, J., Cao, F., Automatic detection and classification of leukocytes using convolutional neural networks (2016) Med. Biol. Eng. Comput.; Zhao, L., Jia, K., Multiscale CNNs for brain tumor segmentation and diagnosis (2016) Comput. Math. Methods Med.,2016, p. 8356294; Zheng, Y., Liu, D., Georgescu, B., Nguyen, H., Comaniciu, D., 3D deep learning for efficient and robust landmark detection in volumetric data (2015) Proceedings of the Medical Image Computing and Computer-Assisted Intervention, Lecture Notes in Computer Science,9349, pp. 565-572; Zhou, X., Ito, T., Takayama, R., Wang, S., Hara, T., Fujita, H., Three-dimensional CT image segmentation by combining 2D fully convolutional network with 3D majority voting (2016) Proceedings of the Deep Learning in Medical Image Analysis (DLMIA), Lecture Notes in Computer Science,10008, pp. 111-120; Zhu, Y., Wang, L., Liu, M., Qian, C., Yousuf, A., Oto, A., Shen, D., MRI Based prostate cancer detection with high-level representation and hierarchical classification (2017) Med. Phys., 44 (3), pp. 1028-1039. , in press; Zilly, J., Buhmann, J.M., Mahapatra, D., Glaucoma detection using entropy sampling and ensemble learning for automatic optic cup and disc segmentation (2017) Comput. Med. Imaging Graph,55, pp. 28-41; Zreik, M., Leiner, T., de Vos, B., van Hamersvelt, R., Viergever, M., Isgum, I., Automatic segmentation of the left ventricle in cardiac CT angiography using convolutional neural networks (2016) Proceedings of the IEEE International Symposium on Biomedical Imaging," pp. 40-43""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Jordan M.I., Mitchell T.M.",7202293939;7402175019;,"Machine learning: Trends, perspectives, and prospects",2015,Science,10.1126/science.aaa8415,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937801713&doi=10.1126%2fscience.aaa8415&partnerID=40&md5=1d384806d6aad8d5de295df324a892aa,"Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today's most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.",,"algorithm; automation; computer simulation; decision making; education; financial system; health care; machine learning; manufacturing; marketing; World Wide Web; accuracy; causal modeling; decision theory; decision tree; human; kernel method; learning algorithm; machine learning; natural language processing; prediction; priority journal; Review; speech discrimination; support vector machine; algorithm; artificial intelligence; computer system; statistical analysis; trends; Algorithms; Artificial Intelligence; Computer Systems; Data Interpretation, Statistical; Humans","Hastie, T., Tibshirani, R., Friedman, J., (2011) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, , Springer New York; Murphy, K., (2012) Machine Learning: A Probabilistic Perspective, , MIT Press Cambridge MA; Valiant, L., (1984) Commun. ACM, 27, pp. 1134-1142; Chandrasekaran, V., Jordan, M.I., (2013) Proc. Natl. Acad. Sci. U.S.A., 110, pp. 1181-1190; Decatur, S., Goldreich, O., Ron, D., (2000) SIAM J. Comput., 29, pp. 854-879; Shalev-Shwartz, S., Shamir, O., Tromer, E., Using more data to speed up training time (2012) Proceedings of the Fifteenth Conference on Artificial Intelligence and Statistics, , Canary Islands, Spain, 21 to 23 April; Boyd, S., Parikh, N., Chu, E., Peleato, B., Eckstein, J., (2011) Foundations and Trends in Machine Learning, 3, pp. 1-122. , (Now Publishers, Boston; Sra, S., Nowozin, S., Wright, S., (2011) Optimization for Machine Learning, , MIT Press Cambridge MA; Schmidhuber, J., (2015) Neural Netw., 61, pp. 85-117; Bengio, Y., (2009) Foundations and Trends in Machine Learning, 2, pp. 1-127. , (Now Publishers, Boston; Krizhevsky, A., Sutskever, I., Hinton, G., (2015) Adv. Neural Inf. Process. Syst., 25, pp. 1097-1105; Hinton, G., (2012) IEEE Signal Process Mag., 29, pp. 82-97; Hinton, G.E., Salakhutdinov, R.R., (2006) Science, 313, pp. 504-507; Mnih, V., (2015) Nature, 518, pp. 529-533; Sutton, R.S., Barto, A.G., (1998) Reinforcement Learning: An Introduction, , MIT Press Cambridge MA; Yaylali, E., Ivy, J.S., Partially observable mdps (pomdps): Introduction and examples (2011) Encyclopedia of Operations Research and Management Science, , (John Wiley New York; Schultz, W., Dayan, P., Montague, P.R., (1997) Science, 275, pp. 1593-1599; Dwork, C., McSherry, F., Nissim, K., Smith, A., (2006) Proceedings of the Third Theory of Cryptography Conference, pp. 265-284. , New York, 4 to 7 March; Blum, A., Ligett, K., Roth, A., (2013) J. ACM, 20; Duchi, J., Jordan, M.I., Wainwright, J., (2014) J. ACM, 61, pp. 1-57; Balcan, M.-F., Blum, A., Fine, S., Mansour, Y., Distributed learning, communication complexity and privacy Proceedings of the 29th Conference on Computational Learning Theory, , Edinburgh, UK, 26 June to 1 July 2012; Zhang, Y., Duchi, J., Jordan, M., Wainwright, M., (2014) Advances in Neural Information Processing Systems, 26, pp. 1-23. , L. Bottou, C. Burges, Z. Ghahramani, M. Welling, Eds. (Curran Associates, Red Hook, NY; Berthet, Q., Rigollet, P., (2013) Ann. Stat., 41, pp. 1780-1815; Kleiner, A., Talwalkar, A., Sarkar, P., Jordan, M.I., (2014) J. R. Stat. Soc. B, 76, pp. 795-816; Mahoney, M., (2011) Found. Trends Machine Learn., 3, pp. 123-224; Mitchell, T., Proceedings of the Twenty-Ninth Conference on Artificial Intelligence (AAAI-15), , 25 to 30 January 2015, Austin, TX; Taylor, M., Stone, P., (2009) J. Mach. Learn. Res., 10, pp. 1633-1685; Thrun, S., Pratt, L., (1998) Learning to Learn, , Kluwer Academic Press Boston; Wehbe, L., (2014) PLOS ONE, 9, p. e112575; Xu, K., Proceedings of the 32nd International Conference on Machine Learning, 37, pp. 2048-2057. , Lille, France, 6 to 11 July 2015; Blei, D., (2012) Commun. ACM, 55, pp. 77-84",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Nowak M.A., Komarova N.L., Niyogi P.",7201493023;7004475998;7004259002;,Computational and evolutionary aspects of language,2002,Nature,10.1038/nature00771,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0037030641&doi=10.1038%2fnature00771&partnerID=40&md5=dcb4c40af00ad97411a1ba7e14b841b8,"Language is our legacy. It is the main evolutionary contribution of humans, and perhaps the most interesting trait that has emerged in the past 500 million years. Understanding how darwinian evolution gives rise to human language requires the integration of formal language theory, learning theory and evolutionary dynamics. Formal language theory provides a mathematical description of language and grammar. Learning theory formalizes the task of language acquisition - it can be shown that no procedure can learn an unrestricted set of languages. Universal grammar specifies the restricted set of languages learnable by the human brain. Evolutionary dynamics can be formulated to describe the cultural evolution of language and the biological evolution of universal grammar.",,"Evolutionary algorithms; Formal languages; Learning systems; Evolutionary dynamics; Computational linguistics; evolution; language; learning; calculation; evolution; human; language; learning; linguistics; mathematical analysis; molecular dynamics; priority journal; review; theory; Brain; Culture; Evolution; Humans; Language; Learning; Linguistics; Models, Biological; Sound; Darwinia","Pinker, S., Bloom, A., Natural language and natural selection (1990) Behav. Brain Sci., 73, pp. 707-784; Jackendoff, R., Possible stages in the evolution of the language capacity (1999) Trends Cogn. Sci., 3, pp. 272-279; Bickerton, D., (1990) Language and Species, , Univ. Chicago Press, Chicago; Lighffoot, D., (1999) The Development of Language: Acquisition, Changes and Evolution, , Blackwell, Oxford; Brandon, R., Hornstein, N., From icon to symbol: Some speculations on the evolution of natural language (1986) Phil. Biol., 1, pp. 169-189; Hurford, J.R., Studdert-Kennedy, M.A., Knight, C., (1998) Approaches to the Evolution of Language, , Cambridge Univ. Press, Cambridge, UK; Newmeyer, F., Functional explanation in linguistics and the origins of language (1991) Lang. Commun., 11, pp. 3-28; Lieberman, P., (1984) The Biology and Evolution of Language, , Harvard Univ. Press, Cambridge, Massachusetts; Maynard Smith, I., Szathmary, E., (1995) The Major Transitions in Evolution, , Freeman Spektrum, Oxford; Hawkins, J.A., Gell-Mann, M., (1992) The Evolution of Human Languages, , Addison-Wesley, Reading, Massachusetts; Aitchinsom, J., (1996) The Seeds of Speech, , Cambridge Univ. Press, Cambridge, UK; Cavalli-Sforza, L.L., Genes, peoples and languages (1997) Proc. Natl Acad. Sci. USA, 94, pp. 7719-7724; Gopnik, M., Crago, M., Familial aggregation of a developmental language disorder (1991) Cognition, 39, pp. 1-50; Lai, C.S.L., Fisher, S.E., Hurst, J.A., Vargha-Khadem, F., Monaco, A.P., A forhead-domain gene is mutated in a severe speech and language disorder (2001) Nature, 413, pp. 519-523; Deacon, T., (1997) The Symbolic Species, , Penguin, London; Vargha-Khadem, F., Neural basis of an inherited speech and language disorder (1998) Proc. Natl Acad. Sci. USA, 95, pp. 12695-12700; Smith, W.J., (1977) The Behaviour of Communicating, , Harvard Univ. Press, Cambridge, UK; Dunbar, R., (1996) Grooming, Gossip, and the Evolution of Language, , Cambridge Univ. Press, Cambridge, UK; Fitch, W.T., The evolution of speech: A comparative review (2000) Trends Cogn. Sci., 4, pp. 258-267; Hauser, M.D., (1996) The Evolution of Communication, , Harvard Univ. Press, Cambridge, Massachusetts; Chomsky, N.A., (1957) Syntactic Structures, , Mouton, New York; Harrison, M.A., (1978) Introduction to Formal Language Theory, , Addison-Wesley, Reading, Massachusetts; Gold, E.M., Language identification in the limit (1961) Informat. Control, 10, pp. 447-474; Vapnik, V.N., Chervonenkis, A.Y., On the uniform convergence of relative frequencies of events to their probabilities (1971) Theor. Prob. Applicat., 17, pp. 264-280; Valiant, L.G., A theory of learnable (1984) Commun. ACM, 27, pp. 436-445; Vapnik, V.N., (1998) Statistical Learning Theory, , Wiley, New York; Osherson, D., Stob, M., Weinstein, S., (1986) Systems That Learn, , MIT Press, Cambridge, Massachusetts; Pinker, S., Formal models of language learning (1979) Cognition, 7, pp. 217-283; Pullum, G.K., Gazdar, G., Natural languages and context free languages (1982) Linguist. Phil., 4, pp. 471-504; Shieber, S.M., Evidence against the context-freeness of natural language (1985) Linguist. Phil., 8, pp. 333-343; Chomsky, N.A., (1984) Lectures on Government and Binding: The Pisa Lectures, , Foris, Dordrecht; Sadock, J.M., (1991) Autolexical Syntax: A Theory of Parallel Grammatical Representations. Studies in Contemporary, Linguistics, , Univ. Chicago Press, Chicago; Bresnan, J., (2001) Lexical-Functional Syntax, , Blackwells, London; Pollard, C.J., Sag, I.A., (1994) Head-Driven Phrase Structure Grammar, , Univ. Chicago Press, Chicago; Chomsky, N., (1972) Language and Mind, , Harcourt Brace Jovanovich, New York; Wexler, K., Culicover, P., (1980) Formal Principles of Language Acquisition, , MIT Press, Cambridge, Massachusetts; Jackendoff, R., (2001) Foundations of Language, , Oxford Univ. Press, Oxford; Chomsky, N., (1981) Explanation in Linguistics, pp. 123-146. , (eds Hornstein, N. & Lightfoot, D.) (Longman, London); Baker, M.C., (2001) Atoms of Language, , Basic Books, New York; Prince, A., Smolensky, P., Optimality: From neural networks to universal grammar (1997) Science, 275, pp. 1604-1610; Elman, J.L., (1996) Rethinking Innateness, , MIT Press, Cambridge, Massachusetts; Tomasello, M., (1999) The Cultural Origins of Human Cognition, , Harvard Univ. Press, Cambridge, Massachusetts; Sampson, G., (1999) Educating Eve: The Language Instinct Debate, , Cassell Academic, London; Greenberg, J.H., Ferguson, C.A., Moravcsik, E.A., (1978) Universals of Human Language, , Stanford Univ. Press, Stanford; Comrie, B., (1981) Language Universals and Linguistic Typology, , Univ. Chicago Press, Chicago; Geman, S., Bienenstock, E., Doursat, R., Neural networks and the bias/variance dilemma (1992) Neural Comput., 4, pp. 1-58; Langacker, R., (1987) Foundations of cognitive Linguistics, 1. , Stanford Univ. Press, Stanford; Lakoff, G., (1987) Women, Fire and Dangerous Things: What Categories Reveal about the Mind, , Univ. Chicago Press, Chicago; Bates, E., MacWhinney, B., (1982) Language Acquisition: The State of the Art, , Cambridge Univ. Press, Cambridge; Aoki, K., Feldman, M.W., Toward a theory for the evolution of cultural communication: Coevolution of signal transmission and reception (1987) Proc. Natl Acad. Sci. USA, 84, pp. 7164-7168; Hurford, J.R., Biological evolution of the Saussurean sign as a component of the language acquisition device (1989) Lingua, 77, pp. 187-222; Cangelosi, A., Parisi, D., (2002) Simulating the Evolution of Language, , Springer, London; Kirby, S., Hurford, J., (1997) Proc. Fourth European Conf. on Artificial Life, pp. 493-502. , (eds Husbands, P. & Harvey, I.) (MIT Press, Cambridge, Massachusetts); Steels, L., (1996) Proc. Fifth Artificial Life Conf, pp. 113-131. , (eds Langton, C. G. & Shimohara, T.) (MIT Press, Tokyo); Nowak, M.A., Krakauer, D.C., The evolution of language (1999) Proc. Natl. Acad. Sci. USA, 96, pp. 8028-8033; Nowak, M.A., Plotkin, J.B., Jansen, V.A.A., Evolution of syntactic communication (2000) Nature, 404, pp. 495-498; Komarova, N.L., Nowak, M.A., Evolutionary dynamics of the lexical matrix (2001) Bull. Math. Biol., 63, pp. 451-485; Christiansen, M.H., Dale, R.A.C., Ellefson, M.R., Conway, C.M., (2002) Simulating the Evolution of Language, pp. 165-187. , (eds Cangelosi, A. & Parisi, D.) (Springer, London); Hashimoto, T., Ikegami, T., Emergence of net-grammar in communicating agents (1996) Biosystyms, 38, pp. 1-14; Hazlehurst, B., Hutchins, E., The emergence of propositions from the coordination of talk and action in a shared worlds (1998) Lang. Cogn. Process., 13, pp. 373-424; Pinker, S., (1994) The Language Instinct, , Morrow, New York; Nowak, M.A., Komarova, N.L., Niyogi, P., Evolution of universal grammar (2001) Science, 291, pp. 114-118; Komarova, N.L., Rivin, I., (2001) Mathematics of learning, , http://lanLarXiv.org, Preprint math.PR/0105235; Rivin, I., (2001) Yet another zeta function and learning, , http://lanLarXiv.org, Preprint cs.LG/0107033; Lightfoot, D., (1991) How to Set Parameters: Arguments from Language Change, , MIT Press, Cambridge, Massachusetts; Kroch, A., Reflexes of grammar in patterns of language change (1989) Long. Variat. Change, 1, pp. 199-244; Wang, W.S.Y., (1998) The Origins and Past of Modern Humans, pp. 247-262. , (eds Omoto, K. & Tobias, P. V.) (World Scientific, Singapore); Niyogi, P., Berwick, R.C., Evolutionary consequences of language learning (1997) Linguist. Phil., 20, pp. 697-719; Hopper, P., Traugott, E., (1993) Grammaticalization, , Cambridge Univ. Press, Cambridge; De Graff, M., (1999) Language Creation and Language Change: Creolization, Diachrony and Development, , MIT Press, Cambridge, MA; Mufwene, S., (2001) The Ecology of Language Evolution, , Cambridge Univ. Press, Cambridge; Angluin, D., Learning regular sets from queries and counterexamples (1987) Informat. Comput., 75, pp. 87-106; Angluin, D., Kharitonov, M., When won't membership queries help? (1995) J. Comput. Syst. Sci., 50, pp. 336-355; Gasarch, W., Smith, C., Learning via queries (1992) J. Assoc. Comput. Machin., 39, pp. 649-674",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Podgorelec V., Kokol P., Stiglic B., Rozman I.",6701496970;7006196824;6602685509;7003701924;,Decision trees: An overview and their use in medicine,2002,Journal of Medical Systems,10.1023/A:1016409317640,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0036778479&doi=10.1023%2fA%3a1016409317640&partnerID=40&md5=59ef7a3f5ef37e5ad360b1bccd5b9823,"In medical decision making (classification, diagnosing, etc.) there are many situations where decision must be made effectively and reliably. Conceptual simple decision making models with the possibility of automatic learning are the most appropriate for performing such tasks. Decision trees are a reliable and effective decision making technique that provide high classification accuracy with a simple representation of gathered knowledge and they have been used in different areas of medical decision making. In the paper we present the basic characteristics of decision trees and the successful alternatives to the traditional induction approach with the emphasis on existing and possible future applications in medicine.",Classification; Decision making; Decision trees; Machine learning,"algorithm; data analysis; decision making; decision theory; diagnostic accuracy; heart disease; human; human computer interaction; man machine interaction; medical decision making; model; review; systolic blood pressure; clinical medicine; decision support system; decision tree; United States; Clinical Medicine; Decision Support Systems, Clinical; Decision Trees; Humans; United States","Quinlan, J.R., (1993) C4.5: Programs for Machine Learning, , Morgan Kaufmann, San Francisco; Quinlan, J.R., Induction of decision trees (1986) Mach. Learn., 1, pp. 81-106; Quinlan, J.R., Simplifying decision trees (1987) Int. J. Man-Mach. Stud., 27, pp. 221-234; Shannon, C., Weaver, W., (1949) The Mathematical Theory of Communication, , University of Illinois Press, USA; Breiman, L., Friedman, J.H., Olsen, R.A., Stone, C.J., (1984) Classification and Regression Trees, , Wadsworth, USA; Paterson, A., Niblett, T.B., (1982) ACLS Manual, , Intelligent Terminals Ltd., Edinburgh; Zorman, M., Podgorelec, V., Kokol, P., Peterson, M., Lane, J., Decision tree's induction strategies evaluated on a hard real world problem (2000) Proc. 13th IEEE Symp. Comp.-Based Med. Syst. (CBMS-2000), pp. 19-24; Zorman, M., Hieb, S., Sprogar, M., Advanced tool for building decision trees MtDecit 2.0 (1999) Proc. Int. Conf. Artif. Intellig. (ICAI-99); Tou, J.T., Gonzalez, R.C., Pattern Recognition Principles, p. 1974. , Addison-Wesley, Reading, MA; Murthy, K.V.S., (1997) On Growing Better Decision Trees from Data, , PhD dissertation, Johns Hopkins University, Baltimore, MD; Neapolitan, R., Naimipour, K., (1996) Foundations of Algorithms, , D. C. Heath and Company, Lexington, MA; Heath, D., Kasif, S., Salzberg, S., k-DT: A multi-tree learning method (1993) Proc. Second Int. Workshop Multistrategy Learn, pp. 138-149; Heath, D., Kasif, S., Salzberg, S., Learning oblique decision trees (1993) Proc. Thirteenth Int. Joint Conf. Artif. Intellig. (IJCAI-93), pp. 1002-1007; Rich, E., Knight, K., (1991) Artificial Intelligence (2nd Edn.), , McGraw Hill, New York; Kirkpatrick, S., Gelatt, C.D., Vecchi, M.P., Optimization by simulated annealing (1983) Science, 220, p. 4598; Utgoff, P.E., Incremental induction of decision trees (1989) Mach. Learn., 4 (2), pp. 161-186; Crawford, S., Extensions to the CART algorithm (1989) Int. J. Man-Mach. Stud., 31 (2), pp. 197-217; Dietterich, T.G., Kong, E.B., Machine Learning Bias, Statistical Bias and Statistical Variance of Decision Tree Algorithms, p. 1995. , Technical Report, Oregon State University; Ho, T.K., The random subspace method for constructing decision forests (1998) IEEE Trans. Pattern Anal. Mach. Intellig., 20 (8), pp. 832-844; Podgorelec, V., Kokol, P., Evolutionary decision forests - Decision making with multiple evolutionary constructed decision trees (2001) Problems in Applied Mathematics and Computational Intelligence, pp. 97-103. , WSES Press; Shlien, S., Multiple binary decision tree classifiers (1992) Pattern Recogn. Lett., 23 (7), pp. 757-763; Utgoff, P.E., Perceptron trees: A case study in hybrid concept representations (1989) Connect. Science, 1, pp. 377-391; Craven, M.W., Shavlik, J.W., Extracting tree-structured representations of trained networks (1996) Advances in Neural Information Processing Systems, 8. , MIT Press, Cambridge, MA; Zorman, M., Kokol, P., Podgorelec, V., Medical decision making supported by hybrid decision trees (2000) Proc. ICSC Symp. Intellig. Syst. Appl. (ISA-2000), , ICSC Academic Press; Banerjee, A., Initializing neural networks using decision trees (1994) Proc. Int. Workshop Comput. Learn. Nat. Learn. Syst., pp. 3-15; Goldberg, D.E., (1989) Genetic Algorithms in Search, Optimization, and Machine Learning, , Addison Wesley, Reading, MA; Nikolaev, N., Slavov, V., Inductive genetic programming with decision trees (1998) Intellig. Data Anal. Int. J., 2 (1), pp. 31-44; Podgorelec, V., Kokol, P., Induction f medical decision trees with genetic algorithms (1999) Proc. Int. ICSC Congr. Comput. Intellig. Methods Appl. (CIMA 1999); Cantu-Paz, E., Kamath, C., Using evolutionary algorithms to induce oblique decision trees (2000) Proc. Genet. Evol. Comput. Conf. (GECCO-2000), pp. 1053-1060; Podgorelec, V., Kokol, P., Towards more optimal medical diagnosing with evolutionary algorithms (2001) J. Med. Syst., 25 (3), pp. 195-219; Sprogar, M., Kokol, P., Hleb, S., Podgorelec, V., Zorman, M., Vector decision trees (2000) Intellig. Data Anal., 4 (3-4), pp. 305-321; Podgorelec, V., (2001) Intelligent Systems Design and Knowledge Discovery with Automatic Programming, , PhD thesis, University of Maribor, Oct; Cremilleux, B., Robert, C., A theoretical framework for decision trees in uncertain domains: Application to medical data sets (1997) Lecture Notes in Artificial Intelligence, 1211, pp. 145-156. , Springer-Verlag; Kokol, P., Zorman, M., Stiglic, M.M., Malcic, I., The limitations of decision trees and automatic learning in real world medical decision making (1998) Proc. 9th World Congr. Med. Inform. (MEDINFO-98), 52, pp. 529-533; Tsien, C.L., Fraser, H.S.F., Eong, W.J., Kennedy, R.L., Using classification tree and logistic regression methods to diagnose myocardial infarction (1998) Proc. 9th World Congr. Med. Inform. (MEDINFO-98), 52, pp. 493-497; Babic, S.H., Kokol, P., Stiglic, M.M., Fuzzy decision trees in the support of breastfeeding (2000) Proc. 13th IEEE Symp. Comp.-Based Med. Syst. (CBMS-2000), pp. 7-11; Jones, J.K., The role of data mining technology in the identification of signals of possible adverse drug reactions: Value and limitations (2001) Curr. Ther. Res.-Clin. Exp., 62 (9), pp. 664-672; Ohno-Machado, L., Lacson, R., Massad, E., Decision trees and fuzzy logic: A comparison of models for the selection of measles vaccination strategies in Brazil (2000) J. Am. Med. Inform. Assoc., (SUPPL.), pp. 625-629. , September; Dantchev, N., Therapeutic decision frees in psychiatry (1996) Encephale-Revue de Psychiatrie Clinique Biologique et Therapeutique, 22 (3), pp. 205-214; Gambhir, S.S., Decision analysis in nuclear medicine (1999) J. Nucl. Med., 40 (9), pp. 1570-1581; Tsien, C.E., Kohane, I.S., McIntosh, N., Multiple signal integration by decision tree induction to detect artifacts in the neonatal intensive care unit (2000) Artif. Intellig. Med., 19 (3), pp. 189-202; Bonner, G., Decision making for health care professionals: Use of decision trees within the community mental health setting (2001) J. Adv. Nurs., 35, pp. 349-356; Letourneau, S., Jensen, L., Impact of a decision tree on chronic wound care (1998) J. Wound Ostomy Continence Nurs., 25, pp. 240-247; Sanders, G.D., Hagerty, C.G., Sonnenberg, F.A., Hlatky, M.A., Owens, D.K., Distributed decision support using a web-based interface: Prevention of sudden cardiac death (2000) Med. Decision Making, 19 (2), pp. 157-166; Sims, C.J., Meyn, L., Caruana, R., Rao, R.B., Mitchell, T., Krohn, M., Predicting cesarean delivery with decision tree models (2000) Am. J. Obstet. Gynecol., 183, pp. 1198-1206",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Khosravi A., Nahavandi S., Creighton D., Atiya A.F.",56234594800;55992860000;9334174900;7004005716;,Comprehensive review of neural network-based prediction intervals and new advances,2011,IEEE Transactions on Neural Networks,10.1109/TNN.2011.2162110,https://www.scopus.com/inward/record.uri?eid=2-s2.0-80052409097&doi=10.1109%2fTNN.2011.2162110&partnerID=40&md5=c6856a878a9625d218309623b4840f88,"This paper evaluates the four leading techniques proposed in the literature for construction of prediction intervals (PIs) for neural network point forecasts. The delta, Bayesian, bootstrap, and mean-variance estimation (MVE) methods are reviewed and their performance for generating high-quality PIs is compared. PI-based measures are proposed and applied for the objective and quantitative assessment of each method's performance. A selection of 12 synthetic and real-world case studies is used to examine each method's performance for PI construction. The comparison is performed on the basis of the quality of generated PIs, the repeatability of the results, the computational requirements and the PIs variability with regard to the data uncertainty. The obtained results in this paper indicate that: 1) the delta and Bayesian methods are the best in terms of quality and repeatability, and 2) the MVE and bootstrap methods are the best in terms of low computational load and the width variability of PIs. This paper also introduces the concept of combinations of PIs, and proposes a new method for generating combined PIs using the traditional PIs. Genetic algorithm is applied for adjusting the combiner parameters through minimization of a PI-based cost function subject to two sets of restrictions. It is shown that the quality of PIs produced by the combiners is dramatically better than the quality of PIs obtained from each individual method. © 2006 IEEE.",Bayesian; bootstrap; delta; mean-variance estimation; neural network; prediction interval,Bayesian; bootstrap; delta; Mean variance; prediction interval; Bayesian networks; Forecasting; Neural networks; algorithm; animal; artificial neural network; Bayes theorem; computer simulation; human; predictive value; review; time; Algorithms; Animals; Bayes Theorem; Computer Simulation; Humans; Neural Networks (Computer); Predictive Value of Tests; Time Factors,"Hornik, K., Stinchcombe, M., White, H., Multilayer feedforward networks are universal approximators (1989) Neural Netw., 2 (5), pp. 359-366; Bishop, C.M., (1995) Neural Networks for Pattern Recognition, , London, U. K.: Oxford Univ. Press; Hussain, M.A., Review of the applications of neural networks in chemical process control - Simulation and online implementation (1999) Artif. Intell. Eng., 13 (1), pp. 55-68. , Jan; De Gooijer, J.G., Hyndman, R.J., 25 years of time series forecasting (2006) Int. J. Forecast., 22 (3), pp. 443-473; Bose, B.K., Neural network applications in power electronics and motor drives-an introduction and perspective (2007) IEEE Trans. Ind. Electron., 54 (1), pp. 14-33. , Feb; Paliwal, M., Kumar, U.A., Review: Neural networks and statistical techniques: A review of applications (2009) Expert Syst. Appl., 36 (1), pp. 2-17. , Jan; Liu, W.-H., Forecasting the semiconductor industry cycles by bootstrap prediction intervals (2007) Appl. Econ., 39 (13), pp. 1731-1742; Ho, S., Xie, M., Tang, L., Xu, K., Goh, T., Neural network modeling with confidence bounds: A case study on the solder paste deposition process (2001) IEEE Trans. Electron. Packag. Manuf., 24 (4), pp. 323-332. , Oct; Zhao, J.H., Dong, Z.Y., Xu, Z., Wong, K.P., A statistical approach for interval forecasting of the electricity price (2008) IEEE Trans. Power Syst., 23 (2), pp. 267-276. , May; Khosravi, A., Nahavandi, S., Creighton, D., Construction of optimal prediction intervals for load forecasting problems (2010) IEEE Trans. Power Syst., 25 (3), pp. 1496-1503. , Aug; Pierce, S.G., Worden, K., Bezazi, A., Uncertainty analysis of a neural network used for fatigue lifetime prediction (2008) Mech. Syst. Signal Process., 22 (6), pp. 1395-1411. , Aug; Benoit, D.F., Van Den Poel, D., Benefits of quantile regression for the analysis of customer lifetime value in a contractual setting: An application in financial services (2009) Expert Syst. Appl., 36 (7), pp. 10475-10484. , Sep; Shrestha, D.L., Solomatine, D.P., Machine learning approaches for estimation of prediction interval for the model output (2006) Neural Netw., 19 (2), pp. 225-235. , Mar; Van Hinsbergen, C., Van Lint, J., Van Zuylen, H., Bayesian committee of neural networks to predict travel times with confidence intervals (2009) Transport. Res. Part C: Emerg. Technol., 17 (5), pp. 498-509. , Oct; Khosravi, A., Mazloumi, E., Nahavandi, S., Creighton, D., Van Lint, J.W.C., Prediction intervals to account for uncertainties in travel time prediction (2011) IEEE Trans. Intell. Transport. Syst., 12 (2), pp. 537-547. , Jun; Khosravi, A., Mazloumi, E., Nahavandi, S., Creighton, D., Van Lint, J.W.C., A genetic algorithm-based method for improving quality of travel time prediction interval (2011) Transport. Res. Part C: Emerg. Technol., , Jun, to be published; Khosravi, A., Nahavandi, S., Creighton, D., A prediction intervalbased approach to determine optimal structures of neural network metamodels (2010) Expert Syst. Appl., 37 (3), pp. 2377-2387. , Mar; Hwang, J.T.G., Ding, A.A., Prediction intervals for artificial neural networks (1997) J. Amer. Stat. Assoc., 92 (438), pp. 748-757. , Jun; De Veaux, R.D., Schumi, J., Schweinsberg, J., Ungar, L.H., Prediction intervals for neural networks via nonlinear regression (1998) Technometrics, 40 (4), pp. 273-282. , Nov; MacKay, D.J.C., The evidence framework applied to classification networks (1992) Neural Comput., 4 (5), pp. 720-736. , Sep; Nix, D.A., Weigend, A.S., Estimating the mean and variance of the target probability distribution (1994) Proc. IEEE Int. Conf. Neural Netw., 1, pp. 55-60. , Orlando, FL, Jun.-, Jul; Efron, B., Bootstrap methods: Another look at the jackknife (1979) Ann. Stat., 7 (1), pp. 1-26. , Jan; Heskes, T., Practical confidence and prediction intervals (1997) Neural Information Processing Systems, 9, pp. 176-182. , T. P. M. Mozer and M. Jordan, Eds. Cambridge, MA: MIT Press; Papadopoulos, G., Edwards, P.J., Murray, A.F., Confidence estimation methods for neural networks: A practical comparison (2001) IEEE Trans. Neural Netw., 12 (6), pp. 1278-1287. , Nov; Ding, A., He, X., Backpropagation of pseudo-errors: Neural networks that are adaptive to heterogeneous noise (2003) IEEE Trans. Neural Netw., 14 (2), pp. 253-262. , Mar; Giordano, F., La Rocca, M., Perna, C., Forecasting nonlinear time series with neural network sieve bootstrap (2007) Comput. Stat. Data Anal., 51 (8), pp. 3871-3884. , May; Rivals, I., Personnaz, L., Construction of confidence intervals for neural networks based on least squares estimation (2000) Neural Netw., 13 (4-5), pp. 463-484. , Jun; Wild, C.J., Seber, G.A.F., (1989) Nonlinear Regression, , New York: Wiley; Tibshirani, R., A comparison of some error estimates for neural network models (1996) Neural Comput., 8 (1), pp. 152-163. , Jan; Hagan, M., Menhaj, M., Training feedforward networks with the Marquardt algorithm (1994) IEEE Trans. Neural Netw., 5 (6), pp. 989-993. , Nov; Dybowski, R., Roberts, S., Confidence intervals and prediction intervals for feed-forward neural networks (2000) Clinical Applications of Artificial Neural Networks, , R. Dybowski and V. Gant, Eds. Cambridge, U. K.: Cambridge Univ. Press; Khosravi, A., Nahavandi, S., Creighton, D., Atiya, A.F., Lower upper bound estimation method for construction of neural network-based prediction intervals (2011) IEEE Trans. Neural Netw., 22 (3), pp. 337-346. , Mar; Halberg, A.-M., Teigen, K.H., Fostervold, K.I., Maximum versus minimum values: Preferences of speakers and listeners for upper and lower limit estimates (2009) Acta Psychol., 132 (3), pp. 228-239. , Nov; Hashem, S., Optimal linear combinations of neural networks (1997) Neural Netw., 10 (4), pp. 599-614. , Jun; Ma, L., Khorasani, K., New training strategies for constructive neural networks with application to regression problems (2004) Neural Netw., 17 (4), pp. 589-609. , May; Vlachos, P., (2010) StatLib Datasets Archive, , http://lib.stat.cmu.edu/datasets, Jan; Khosravi, A., Nahavandi, S., Creighton, D., Constructing prediction intervals for neural network metamodels of complex systems (2009) Proc. Int. Joint Conf. Neural Netw., pp. 1576-1582. , Atlanta, GA, Jun; Asuncion, A., Newman, D.J., (2010) UCI Machine Learning Repository, , http://www.ics.uci.edu/~mlearn/MLRepository.html, Jan., School Inf. Comput. Sci., Univ. California, Irvine; De Moor, B., (2010) DaISy: Database for the Identification of Systems, , http://homes.esat.kuleuven.be/~smc/daisy, Jan., Dept. Electr. Eng., ESAT/SISTA, K. U. Leuven, Leuven, Belgium; Kirkpatrick, S., Gelatt Jr., C.D., Vecchi, M.P., Optimization by simulated annealing (1983) Science, 220 (4598), pp. 671-680. , May; Breiman, L., Bagging predictors (1996) Mach. Learn., 24 (2), pp. 123-140; Islam, M., Yao, X., Murase, K., A constructive algorithm for training cooperative neural network ensembles (2003) IEEE Trans. Neural Netw., 14 (4), pp. 820-834. , Jul; Efron, B., Tibshirani, R.J., (1993) An Introduction to the Bootstrap, , New York: Chapman & Hall; Davison, A.C., Hinkley, D.V., (1997) Bootstrap Methods and Their Application, , Cambridge, U. K.: Cambridge Univ. Press; Hansen, L., Salamon, P., Neural network ensembles (1990) IEEE Trans. Pattern Anal. Mach. Intell., 12 (10), pp. 993-1001. , Oct; Yao, X., Islam, M., Evolving artificial neural network ensembles (2008) IEEE Comput. Intell. Mag., 3 (1), pp. 31-42. , Feb; Gunter, S.I., Nonnegativity restricted least squares combinations (1992) Int. J. Forecast., 8 (1), pp. 45-59. , Jun; Taylor, J.W., Majithia, S., Using combined forecasts with changing weights for electricity demand profiling (2000) J. Oper. Res. Soc., 51 (1), pp. 72-82; Goldberg, D.E., (1989) Genetic Algorithms in Search, Optimization and Machine Learning, , Reading, MA: Addison-Wesley; Mitchell, M., (1996) An Introduction to Genetic Algorithms, , Cambridge, MA: MIT Press; Reeves, C.R., Rowe, J.E., (2003) Genetic Algorithms: Principles and Perspectives: A Guide to GA Theory, , Norwell, MA: Kluwer",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Mjolsness E., DeCoste D.",56822278400;55923760400;,Machine learning for science: State of the art and future prospects,2001,Science,10.1126/science.293.5537.2051,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0035860537&doi=10.1126%2fscience.293.5537.2051&partnerID=40&md5=fc5137ac1da89c7dac27dd8dc0b9d05b,"Recent advances in machine learning methods, along with successful applications across a wide variety of fields such as planetary science and bioinformatics, promise powerful new tools for practicing scientists. This viewpoint highlights some useful characteristics of modern machine learning methods and their relevance to scientific applications. We conclude with some speculations on near-term progress and promising directions.",,"Biotechnology; Space research; Bioinformatics; Planetary science; Learning systems; artificial neural network; astronomy; automation; educational technology; hypothesis; information science; methodology; model; observation; phenomenology; priority journal; review; science; Algorithms; Animals; Artificial Intelligence; Astronomy; Cluster Analysis; Computational Biology; Computer Simulation; Gene Expression Profiling; Gene Expression Regulation; Image Processing, Computer-Assisted; Neural Networks (Computer); Physics; Robotics","Mitchell, T., (1997) Machine Learning, , McGraw-Hill, New York; Burge, C., Karlin, S., (1997) J. Mol. Biol., 268, p. 78; Shoemaker, D.D., (2001) Nature, 409, p. 922; Spellman, P.T., (1998) Mol. Biol. Cell, 9, p. 3273; Eisen, N.B., Spellman, P.T., Brown, P.O., Botstein, D., (1998) Proc. Natl. Acad. Sci. U.S.A., 95, p. 14863; Schölkopf, B., Smola, A., Müller, K.-R., (1999) Advances in Kernel Methods-SV Learning, pp. 327-352. , B. Schölkopf, C. J. C. Burges, A. J. Smola, Eds. (MIT Press, Cambridge, MA); Bell, A.J., Sejnowski, T.J., (1995) Neural Comput., 7, p. 6; Roweis, S., Saul, L., (2000) Science, 290, p. 2323; Shiozawa, M., (1999) Nucl. Instrum. Methods Phys. Res. Sect. A, 433, p. 240; Golub, T.R., (1999) Science, 286, p. 531; Brown, M., (2000) Proc. Natl. Acad. Sci. U.S.A., 97, p. 1; Mjolsness, E., Mann, T., Castaño, R., Wold, B., (2000) Adv. Neural Inform. Processing Syst., 12, p. 928; Jung, T.-P., (2001) Proc. IEEE, 89, p. 7; Burl, M.C., (1998) Machine Learning, 30, pp. 16S; Burl, M.C., (2001) 5th International Symposium on Artificial Intelligence, Robotics, and Automation in Space (i-SAIRAS), , Montreal, Canada, June; DeCoste, D., Schölkopf, B., Machine Learning, , in press; Levison, H.F., Dones, L., Duncan, M.J., (2001) Astron. J., 121, p. 4; Williams, B., Damle, S., Wold, B., unpublished data; Reinitz, J., Sharp, D.H., (1995) Mech. Dev., 49, p. 133; Mjolsness, E.D., Sharp, H., Reinitz, J., (1991) J. Theor. Biol., 152, p. 429; Gilmore, M.S., (2000) J. Geophys. Res., 105, p. 29233; Estlin, T., (1999) Proceedings of the American Association for Artificial Intelligence Conference, pp. 613-620. , AAAI Press/MIT Press, Orlando, FL; Davies, A., (2001) Autonomous Sciencecraft Constellation Science Study Report, , http://asc.jpl.nasa.gov, (Jet Propulsion Laboratory, Pasadena, CA, August); Turmon, M., Mukhtar, S., Pap, J., (1997) Proceedings of the Third Conference on Knowledge Discovery and Data Mining, pp. 267-270. , AAAI Press, Newport Beach, CA; Turmon, M., Pap, J.M., Mukhtar, S., (1998) Structure and Dynamics of the Interior of the Sun and Sun-like Stars, pp. 979-984. , ESA SP-418, European Space Agency Publications Division, Noordwijk, Netherlands; Jordan, M., (1998) Learning in Graphical Models, , Kluwer, Dordrecht, Netherlands; Murphy, K., Weiss, Y., Jordan, M., (1999) Proceedings of the Fifteenth Conference on Uncertainty in Artificial Intelligence, pp. 467-475. , K. B. Laskey, H. Prade, Eds. (Kaufmann, San Francisco, CA); Weiss, Y., (2000) Neural Comput., 12, p. 1; Burges, C.J.C., (1998) Data Mining Knowledge Discov., 2, p. 2; Tong, S., Koller, D., (2000) Proceedings of the Seventeenth International Conference on Machine Learning, pp. 999-1006. , Kaufman, San Francisco, CA; Gold, S., Rangarajan, A., Mjolsness, E., (1996) Neural Comput., 8, p. 4; Mika, S., Rätsch, G., Müller, K.-R., (2001) Adv. Neural Inform. Processing Syst., 13, p. 591; Zien, A., (2000) Bioinformatics, 16, p. 799; note; note",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gold C., Sollich P.",9245309500;7004107468;,Model selection for support vector machine classification,2003,Neurocomputing,10.1016/S0925-2312(03)00375-8,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0242288807&doi=10.1016%2fS0925-2312%2803%2900375-8&partnerID=40&md5=81857133688ee48d5571963ab1bdd639,"We address the problem of model selection for Support Vector Machine (SVM) classification. For fixed functional form of the kernel, model selection amounts to tuning kernel parameters and the slack penalty coefficient C. We begin by reviewing a recently developed probabilistic frame-work for SVM classification. An extension to the case of SVMs with quadratic slack penalties is given and a simple approximation for the evidence is derived, which can be used as a criterion for model selection. We also derive the exact gradients of the evidence in terms of posterior averages and describe how they can be estimated numerically using Hybrid Monte-Carlo techniques. Though computationally demanding, the resulting gradient ascent algorithm is a useful baseline tool for probabilistic SVM model selection, since it can locate maxima of the exact (unapproximated) evidence. We then perform extensive experiments on several benchmark data sets. The aim of these experiments is to compare the performance of probabilistic model selection criteria with alternatives based on estimates of the test error, namely the so-called ""span estimate"" and Wahba's Generalized Approximate Cross-Validation (GACV) error. We find that all the ""simple"" model criteria (Laplace evidence approximations, and the span and GACV error estimates) exhibit multiple local optima with respect to the hyperparameters. While some of these give performance that is competitive with results from other approaches in the literature, a significant fraction lead to rather higher test errors. The results for the evidence gradient ascent method show that also the exact evidence exhibits local optima, but these give test errors which are much less variable and also consistently lower than for the simpler model selection criteria. © 2003 Elsevier B.V. All rights reserved.",Bayesian evidence; Classification; Model selection; Probabilistic methods; Support vector machines,Algorithms; Approximation theory; Mathematical models; Monte Carlo methods; Probability; Vectors; Model selection; Neural networks; algorithm; analytic method; analytical error; classification; controlled study; machine; mathematical computing; mathematical model; Monte Carlo method; normal distribution; priority journal; probability; review; system analysis; validation process,"Barber, D., Williams, C.K.I., Gaussian processes for Bayesian classification via hybrid Monte Carlo (1997) Advances in Neural Information Processing Systems, 9, pp. 340-346. , M.C. Mozer, M.I. Jordan, T. Petsche (Eds.), MIT Press, Cambridge, MA; Burges, C.J.C., A tutorial on support vector machines for pattern recognition (1998) Data Mining Knowledge Discovery, 2 (2), pp. 121-167; Chapelle, O., Vapnik, V.N., Model selection for support vector machines (2000) Advances in Neural Information Processing Systems, 12, pp. 230-236. , S.A. Solla, T.K. Leen, K.-R. Müller (Eds.), MIT Press, Cambridge, MA; Chapelle, O., Vapnik, V., Bousquet, O., Mukherjee, S., Choosing multiple parameters for support vector machines (2002) Mach. Learning, 46 (1-3), pp. 131-159; Cristianini, N., Campbell, C., Shawe-Taylor, J., Dynamically adapting kernels in support vector machines (1999) Advances in Neural Information Processing Systems, 11, pp. 204-210. , M. Kearns, S.A. Solla, D. Cohn (Eds.), MIT Press, Cambridge, MA; Cristianini, N., Shawe-Taylor, J., (2000) an Introduction to Support Vector Machines, , Cambridge University Press, Cambridge; Jaakkola, T., Haussler, D., Probabilistic kernel regression models (1999) Proceedings of the Seventh International Workshop on Artificial Intelligence and Statistics, , D. Heckerman, J. Whittaker (Eds.), San Francisco, CA, Morgan Kaufmann, Los Altos, CA; Krauth, W., Introduction to Monte Carlo algorithms (1998) Advances in Computer Simulation, , J. Kertesz, I. Kondor (Eds.), Springer, Berlin; Kwok, J.T.Y., Moderating the outputs of support vector machine classifiers (1999) IEEE Trans. Neural Networks, 10 (5), pp. 1018-1031; Kwok, J.T.Y., The evidence framework applied to support vector machines (2000) IEEE Trans. Neural Networks, 11 (5), pp. 1162-1173; MacKay, D.J.C., Bayesian interpolation (1992) Neural Comput., 4, pp. 415-447; MacKay, D.J.C., The evidence framework applied to classification networks (1992) Neural Comput., 4, pp. 720-736; Neal, R.M., Probabilistic inference using Markov chain Monte Carlo methods (1993), Technical Report CRG-TR-93-1, University of Toronto; Neal, R.M., (1996) Bayesian Learning for Neural Networks, , Springer, New York; Opper, M., Winther, O., Gaussian process classification and SVM: Mean field results and leave-one-out estimator (2000) Advances in Large Margin Classifiers, pp. 311-326. , A.J. Smola, P. Bartlett, B. Schölkopf, D. Schuurmans (Eds.), MIT Press, Cambridge, MA; Opper, M., Winther, O., Gaussian processes for classification: Mean-field algorithms (2000) Neural Comput., 12 (11), pp. 2655-2684; Press, W.H., Teukolsky, S.A., Vetterling, W.T., Flannery, B.P., (1992) Numerical Recipes in C, , 2nd Edition, Cambridge University Press, Cambridge; Seeger, M., Bayesian model selection for support vector machines, Gaussian processes and other kernel classifiers (2000) Advances in Neural Information Processing Systems, 12, pp. 603-609. , S.A. Solla, T.K. Leen, K.R. Müller (Eds.), MIT Press, Cambridge, MA; Smola, A.J., Schölkopf, B., Müller, K.R., The connection between regularization operators and support vector kernels (1998) Neural Networks, 11 (4), pp. 637-649; Sollich, P., Probabilistic interpretation and Bayesian methods for support vector machines (1999), pp. 91-96. , ICANN99 - Ninth International Conference on Artificial Neural Networks, The Institution of Electrical Engineers, London; Sollich, P., Probabilistic methods for support vector machines (2000) Advances in Neural Information Processing Systems, 12, pp. 349-355. , S.A. Solla, T.K. Leen, K.-R. Müller (Eds.), MIT Press, Cambridge, MA; Sollich, P., Bayesian methods for support vector machines: Evidence and predictive class probabilities (2002) Mach. Learning, 46 (1-3), pp. 21-52; Tipping, M.E., The relevance vector machine (2000) Advances in Neural Information Processing Systems, 12, pp. 652-658. , S.A. Solla, T.K. Leen, K.-R. Müller (Eds.), MIT Press, Cambridge, MA; Vapnik, V., (1995) The Nature of Statistical Learning Theory, , Springer, New York; Vapnik, V., (1998) Statistical Learning Theory, , Wiley, New York; Vapnik, V., Chapelle, O., Bounds on error expectation for support vector machines (2000) Neural Comput., 12 (9), pp. 2013-2036; Wahba, G., Support vector machines, reproducing kernel Hilbert spaces and the randomized GACV (1998) Advances in Kernel Methods: Support Vector Machines, pp. 69-88. , B. Schölkopf, C. Burges, A.J. Smola (Eds.), MIT Press, Cambridge, MA; Williams, C.K.I., Prediction with Gaussian processes: From linear regression to linear prediction and beyond (1998) Learning and Inference in Graphical Models, pp. 599-621. , M.I. Jordan (Ed.), Kluwer Academic, Dordrecht; Williams, C.K.I., Barber, D., Bayesian classification with Gaussian processes (1998) IEEE Trans. Pattern Anal. Mach. Intell., 20 (12), pp. 1342-1351; Williams, C.K.I., Seeger, M., Using the Nyström method to speed up kernel machines (2001) Advances in Neural Information Processing Systems, 13, pp. 682-688. , T.K. Leen, T.G. Dietterich, V. Tresp (Eds.), MIT Press, Cambridge, MA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mittal S.,36158412700;,A survey of techniques for approximate computing,2016,ACM Computing Surveys,10.1145/2893356,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963984095&doi=10.1145%2f2893356&partnerID=40&md5=6ad7d90f3f5cac5617dff60d26381e53,"Approximate computing trades off computation quality with effort expended, and as rising performance demands confront plateauing resource budgets, approximate computing has become not merely attractive, but even imperative. In this article, we present a survey of techniques for approximate computing (AC). We discuss strategies for finding approximable program portions and monitoring output quality, techniques for using AC in different processing units (e.g., CPU, GPU, and FPGA), processor components, memory technologies, and so forth, as well as programming frameworks for AC. We classify these techniques based on several key characteristics to emphasize their similarities and differences. The aim of this article is to provide insights to researchers into working of AC techniques and inspire more efforts in this area to make AC the mainstream computing approach in future systems. © 2016 ACM.",Approximate computing technique (ACT); Approximate storage; Classification; CPU; FPGA; GPU; Neural networks; Quality configurability; Review,Budget control; Classification (of information); Field programmable gate arrays (FPGA); Neural networks; Program processors; Reconfigurable hardware; Reviews; Surveys; Computation quality; Computing techniques; Configurability; Key characteristics; Memory technology; Processing units; Programming framework; Resource budget; FORTH (programming language),"Akturk, I., Khatamifard, K., Karpuzcu, U.R., On quantification of accuracy loss in approximate computing (2015) Workshop on Duplicating, Deconstructing and Debunking; Alvarez, C., Corbal, J., Valero, M., Fuzzy memoization for floating-point multimedia applications (2005) IEEE Transactions on Computers, 54 (7), pp. 922-927; St Amant, R., Yazdanbakhsh, A., Park, J., Thwaites, B., Esmaeilzadeh, H., Hassibi, A., Ceze, L., Burger, D., General-purpose code acceleration with limited-precision analog computation (2014) International Symposium on Computer Architecture, pp. 505-516; Anam, M.A., Whatmough, P., Andreopoulos, Y., Precision-energythroughput scaling of generic matrix multiplication and discrete convolution kernels via linear projections (2013) Symposium on Embedded Systems for Real-time Multimedia (ESTIMedia'13), pp. 21-30; Ansel, J., Wong, Y.L., Chan, C., Olszewski, M., Edelman, A., Amarasinghe, S., Language and compiler support for auto-tuning variable-accuracy algorithms (2011) International Symposium on Code Generation and Optimization, pp. 85-96; Baek, W., Chilimbi, T.M., Green: A framework for supporting energy-conscious programming using controlled approximation (2010) ACM SIGPLAN Notices, 45, pp. 198-209; Bornholt, J., Mytkowicz, T., McKinley, K.S., Uncertain<T>: A first-order type for uncertain data (2014) ACM SIGARCH Computer Architecture News, 42 (1), pp. 51-66; Byna, S., Meng, J., Raghunathan, A., Chakradhar, S., Cadambi, S., Besteffort semantic document search on GPUs (2010) General-Purpose Computation on Graphics Processing Units, pp. 86-93; Carbin, M., Misailovic, S., Rinard, M.C., Verifying quantitative reliability for programs that execute on unreliable hardware (2013) ACM SIGPLAN Notices, 48, pp. 33-52; Chakradhar, S.T., Raghunathan, A., Best-effort computing: Re-thinking parallel software and hardware (2010) Design Automation Conference, pp. 865-870; Chippa, V.K., Chakradhar, S.T., Roy, K., Raghunathan, A., Analysis and characterization of inherent application resilience for approximate computing (2013) Design Automation Conference, p. 113; Chippa, V.K., Mohapatra, D., Roy, K., Chakradhar, S.T., Raghunathan, A., Scalable effort hardware design (2014) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 22 (9), pp. 2004-2016; Cho, K., Lee, Y., Oh, Y.H., Hwang, G.-C., Lee, J.W., EDRAM-based tieredreliability memory with applications to low-power frame buffers (2014) International Symposium on Low Power Electronics and Design, pp. 333-338; Du, Z., Lingamneni, A., Chen, Y., Palem, K., Temam, O., Wu, C., Leveraging the error resilience of machine-learning applications for designing highly energy efficient accelerators (2014) Asia and South Pacific Design Automation Conference (ASP-DAC'14), pp. 201-206; Düben, P., Schlachter, J., Parishkrati, Yenugula, S., Augustine, J., Enz, C., Palem, K., Palmer, T.N., Opportunities for energy efficient computing: A study of inexact general purpose processors for high-performance and big-data applications (2015) Design, Automation & Test in Europe, pp. 764-769; Eldridge, S., Raudies, F., Zou, D., Joshi, A., Neural network-based accelerators for transcendental function approximation (2014) Great Lakes Symposium on VLSI, pp. 169-174; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Architecture support for disciplined approximate programming (2012) ACM SIGPLAN Notices, 47, pp. 301-312; Esmaeilzadeh, H., Sampson, A., Ceze, L., Burger, D., Neural acceleration for generalpurpose approximate programs (2012) IEEE/ACM International Symposium on Microarchitecture, pp. 449-460; Fang, Y., Li, H., Li, X., SoftPCM: Enhancing energy efficiency and lifetime of phase change memory in video applications via approximate write (2012) IEEE Asian Test Symposium (ATS), pp. 131-136; Ganapathy, S., Karakonstantis, G., Teman, A.S., Burg, A.P., Mitigating the impact of faults in unreliable memories for error-resilient applications (2015) Design Automation Conference; Gantz, J., Reinsel, D., (2011) Extracting Value from Chaos, , http://www.emc.com/collateral/analyst-reports/idc-extracting-value-from-chaos-ar.pdf, Retrieved February 25, 2016 from; Goiri, Í., Bianchini, R., Nagarakatte, S., Nguyen, T.D., Approx hadoop: Bringing approximations to MapReduce frameworks (2015) International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 383-397; Grigorian, B., Farahpour, N., Reinman, G., BRAINIAC: Bringing reliable accuracy into neurally-implemented approximate computing (2015) International Symposium on High Performance Computer Architecture (HPCA'15), pp. 615-626; Grigorian, B., Reinman, G., Dynamically adaptive and reliable approximate computing using light-weight error analysis (2014) Conference on Adaptive Hardware and Systems (AHS'14), pp. 248-255; Grigorian, B., Reinman, G., Accelerating divergent applications on SIMD architectures using neural networks (2015) ACM Transactions on Architecture and Code Optimization (TACO), 12 (1), p. 2; Gupta, V., Mohapatra, D., Park, S.P., Raghunathan, A., Roy, K., IMPACT: Imprecise adders for low-power approximate computing (2011) International Symposium on Low Power Electronics and Design, pp. 409-414; Hegde, R., Shanbhag, N.R., Energy-efficient signal processing via algorithmic noisetolerance (1999) International Symposium on Low Power Electronics and Design, pp. 30-35; Hsiao, C.-C., Chu, S.-L., Chen, C.-Y., Energy-aware hybrid precision selection framework for mobile GPUs (2013) Computers and Graphics, 37 (5), pp. 431-444; Kahng, A.B., Kang, S., Accuracy-configurable adder for approximate arithmetic designs (2012) Design Automation Conference, pp. 820-825; Keramidas, G., Kokkala, C., Stamoulis, I., Clumsy value cache: An approximate memoization technique for mobile GPU fragment shaders (2015) Workshop on Approximate Computing (WAPCO'15); Khudia, D.S., Zamirai, B., Samadi, M., Mahlke, S., Rumba: An online quality management system for approximate computing (2015) International Symposium on Computer Architecture, pp. 554-566; Kulkarni, P., Gupta, P., Ercegovac, M., Trading accuracy for power with an underdesigned multiplier architecture (2011) International Conference on VLSI Design (VLSI Design'11), pp. 346-351; Li, B., Gu, P., Shan, Y., Wang, Y., Chen, Y., Yang, H., RRAM-based analog approximate computing (2015) IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems; Liu, S., Pattabiraman, K., Moscibroda, T., Zorn, B.G., Flikker: Saving DRAM refresh-power through critical data partitioning (2012) ACM SIGPLAN Notices, 47 (4), pp. 213-224; Lopes, A.R., Shahzad, A., Constantinides, G., Kerrigan, E.C., More flops or more precision? Accuracy parameterizable linear equation solvers for model predictive control (2009) Symposium on Field Programmable Custom Computing Machines (FCCM'09), pp. 209-216; Mahajan, D., Yazdanbakhsh, A., Park, J., Thwaites, B., Esmaeilzadeh, H., Prediction-based quality control for approximate accelerators (2015) Workshop on Approximate Computing Across the System Stack; McAfee, L., Olukotun, K., EMEURO: A framework for generating multi-purpose accelerators via deep learning (2015) International Symposium on Code Generation and Optimization, pp. 125-135; Miguel, J.S., Badr, M., Jerger, E.N., Load value approximation (2014) MICRO; Misailovic, S., Carbin, M., Achour, S., Qi, Z., Rinard, M.C., Chisel: Reliabilityand accuracy-aware optimization of approximate computational kernels (2014) International Conference on Object Oriented Programming Systems Languages and Applications, pp. 309-328; Mishra, A.K., Barik, R., Paul, S., IACT: A software-hardware framework for understanding the scope of approximate computing (2014) Workshop on Approximate Computing Across the System Stack (WACAS'14); Mittal, S., A survey of architectural techniques for DRAM power management (2012) International Journal of High Performance Systems Architecture, 4 (2), pp. 110-119; Mittal, S., (2014) Power Management Techniques for Data Centers: A Survey, , Technical Report. Oak Ridge National Laboratory, Oak Ridge, TN; Mittal, S., A survey of architectural techniques for improving cache power efficiency (2014) Sustainable Computing: Informatics and Systems, 4 (1), pp. 33-43; Mittal, S., A survey of architectural techniques for near-threshold computing (2015) ACM Journal on Emerging Technologies in Computing Systems, 12 (4), pp. 1-26; Mittal, S., Vetter, J., A survey of techniques for modeling and improving reliability of computing systems (2015) IEEE Transactions on Parallel and Distributed Systems (TPDS); Mittal, S., Vetter, J.S., Li, D., A survey of architectural approaches for managing embedded DRAM and non-volatile on-chip caches (2015) IEEE Transactions on Parallel and Distributed Systems (TPDS), 26 (6), pp. 1524-1537; Moreau, T., Wyse, M., Nelson, J., Sampson, A., Esmaeilzadeh, H., Ceze, L., Oskin, M., SNNAP: Approximate computing on programmable SoCs via neural acceleration (2015) International Symposium on High Performance Computer Architecture (HPCA'15), pp. 603-614; NRDC, (2015), http://www.nrdc.org/energy/data-center-efficiencyassessment.asp, Retrieved February 25, 2016 from; Rahimi, A., Benini, L., Gupta, R.K., Spatial memoization: Concurrent instruction reuse to correct timing errors in SIMD architectures (2013) IEEE Transactions on Circuits and Systems II: Express Briefs, 60 (12), pp. 847-851; Rahimi, A., Ghofrani, A., Cheng, K.-T., Benini, L., Gupta, R.K., Approximate associative memristive memory for energy-efficient GPUs (2015) Design, Automation and Test in Europe, pp. 1497-1502; Raha, A., Venkataramani, S., Raghunathan, V., Raghunathan, A., Quality configurable reduce-and-rank for energy efficient approximate computing (2015) Design, Automation and Test in Europe, pp. 665-670; Rahimi, A., Marongiu, A., Gupta, R.K., Benini, L., A variability-aware OpenMP environment for efficient execution of accuracy-configurable computation on shared-FPU processor clusters (2013) International Conference on Hardware/Software Codesign and System Synthesis, p. 35; Ranjan, A., Venkataramani, S., Fong, X., Roy, K., Raghunathan, A., Approximate storage for energy efficient spintronic memories (2015) Design Automation Conference, p. 195; Ringenburg, M., Sampson, A., Ackerman, I., Ceze, L., Grossman, D., Monitoring and debugging the quality of results in approximate programs (2015) International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 399-411; Ringenburg, M.F., Sampson, A., Ceze, L., Grossman, D., Profiling and autotuning for energy-aware approximate programming (2014) Workshop on Approximate Computing Across the System Stack (WACAS'14); Roy, P., Ray, R., Wang, C., Wong, W.F., ASAC: Automatic sensitivity analysis for approximate computing (2014) Conference on Languages, Compilers and Tools for Embedded Systems, pp. 95-104; Samadi, M., Jamshidi, D.A., Lee, J., Mahlke, S., Paraprox: Patternbased approximation for data parallel applications (2014) ACM SIGARCH Computer Architecture News, 42, pp. 35-50; Samadi, M., Lee, J., Anoushe Jamshidi, D., Hormati, A., Mahlke, S., SAGE: Self-tuning approximation for graphics engines (2013) International Symposium on Microarchitecture, pp. 13-24; Samadi, M., Mahlke, S., CPU-GPU collaboration for output quality monitoring (2014) Workshop on Approximate Computing Across the System Stack, pp. 1-3; Sampson, A., Baixo, A., Ransford, B., Moreau, T., Yip, J., Ceze, L., Oskin, M., (2015) ACCEPT: A Programmer-Guided Compiler Framework for Practical Approximate Computing, , Technical Report. University of Washington, Seattle, WA; Sampson, A., Dietl, W., Fortuna, E., Gnanapragasam, D., Ceze, L., Grossman, D., EnerJ: Approximate data types for safe and general low-power computation (2011) ACM SIGPLAN Notices, 46, pp. 164-174; Sampson, A., Nelson, J., Strauss, K., Ceze, L., Approximate storage in solid-state memories (2013) International Symposium on Microarchitecture, pp. 25-36; Sartori, J., Kumar, R., Branch and data herding: Reducing control andmemory divergence for error-tolerant GPU applications (2013) IEEE Transactions on Multimedia, 15 (2), pp. 279-290; Shi, Q., Hoffmann, H., Khan, O., A HW-SW multicore architecture to tradeoff program accuracy and resilience overheads (2015) Computer Architecture Letters; Shim, B., Sridhara, S.R., Shanbhag, N.R., Reliable low-power digital signal processing via reduced precision redundancy (2004) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 12 (5), pp. 497-510; Shoushtari, M., Mofrad, A.B., Dutt, N., Exploiting partially-forgetful memories for approximate computing (2015) IEEE Embedded Systems Letters, 7 (1), pp. 19-22; Sidiroglou, S., Misailovic, S., Hoffmann, H., Rinard, M., Managing performance vs. Accuracy trade-offs with loop perforation (2011) ACM SIGSOFT Symposium and the 13th European Conference on Foundations of Software Engineering, pp. 124-134; Sutherland, M., Miguel, J.S., Jerger, N.E., Texture cache approximation on GPUs (2015) Workshop on Approximate Computing Across the Stack; Tian, Y., Zhang, Q., Wang, T., Yuan, F., Xu, Q., Approx MA: Approximate memory access for dynamic precision scaling (2015) ACM Great Lakes Symposium on VLSI, pp. 337-342; Varatkar, G.V., Shanbhag, N.R., Error-resilient motion estimation architecture (2008) IEEE Transactions on Very Large Scale Integration (VLSI) Systems, 16 (10), pp. 1399-1412; Vassiliadis, V., Parasyris, K., Chaliosy, C., Antonopoulos, C.D., Lalis, S., Bellas, N., Vandierendoncky, H., Nikolopoulos, D.S., A programming model and runtime system for significance-aware energy-efficient computing (2015) 1st Workshop on Approximate Computing (WAPCO'15); Venkataramani, S., Chakradhar, S.T., Roy, K., Raghunathan, A., Approximate computing and the quest for computing efficiency (2015) Design Automation Conference, p. 120; Venkataramani, S., Chippa, V.K., Chakradhar, S.T., Roy, K., Raghunathan, A., Quality programmable vector processors for approximate computing (2013) International Symposium on Microarchitecture, pp. 1-12; Venkataramani, S., Raghunathan, A., Liu, J., Shoaib, M., Scalable-effort classifiers for energy-efficient machine learning (2015) Design Automation Conference, p. 67; Venkataramani, S., Ranjan, A., Roy, K., Raghunathan, A., AxNN: Energyefficient neuromorphic systems using approximate computing (2014) International Symposium on Low Power Electronics and Design, pp. 27-32; Venkataramani, S., Sabne, A., Kozhikkottu, V., Roy, K., Raghunathan, A., SALSA: Systematic logic synthesis of approximate circuits (2012) Design Automation Conference, pp. 796-801; Vetter, J.S., Mittal, S., Opportunities for nonvolatile memory systems in extreme-scale high performance computing (2015) Computing in Science and Engineering, 17 (2), pp. 73-82; Xu, X., Howie Huang, H., Exploring data-level error tolerance in high-performance solid-state drives (2015) IEEE Transactions on Reliability, 64 (1), pp. 15-30; Yazdanbakhsh, A., Mahajan, D., Thwaites, B., Park, J., Nagendrakumar, A., Sethuraman, S., Ramkrishnan, K., Bazargan, K., Axilog: Language support for approximate hardware design (2015) Design, Automation and Test in Europe Conference and Exhibition, pp. 812-817; Yazdanbakhsh, A., Pekhimenko, G., Thwaites, B., Esmaeilzadeh, H., Kim, T., Mutlu, O., Mowry, T.C., (2015) RFVP: Rollback-Free Value Prediction with Safe-to-Approximate Loads, , Technical Report. Georgia Institute of Technology, Atlanta, GA; Yeh, T.Y., Faloutsos, P., Ercegovac, M., Patel, S.J., Reinman, G., The art of deception: Adaptive precision reduction for area efficient physics acceleration (2007) International Symposium on Microarchitecture, pp. 394-406; Yetim, Y., Martonosi, M., Malik, S., Extracting useful computation from errorprone processors for streaming applications (2013) Design, Automation and Test in Europe Conference and Exhibition (DATE'13), pp. 202-207; Zhang, H., Putic, M., Lach, J., Low power GPGPU computation with imprecise hardware (2014) Design Automation Conference (DAC'14), pp. 1-6; Zhang, Q., Wang, T., Tian, Y., Yuan, F., Xu, Q., Approx ANN: An approximate computing framework for artificial neural network (2015) Design, Automation and Test in Europe, pp. 701-706",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Tsodyks M., Gilbert C.",7003469335;7201382780;,Neural networks and perceptual learning,2004,Nature,10.1038/nature03013,https://www.scopus.com/inward/record.uri?eid=2-s2.0-7244257333&doi=10.1038%2fnature03013&partnerID=40&md5=8e72247fbb2232b76cdadb8abac6ce48,"Sensory perception is a learned trait. The brain strategies we use to perceive the world are constantly modified by experience. With practice, we subconsciously become better at identifying familiar objects or distinguishing fine details in our environment. Current theoretical models simulate some properties of perceptual learning, but neglect the underlying cortical circuits. Future neural network models must incorporate the top-down alteration of cortical function by expectation or perceptual tasks. These newly found dynamic processes are challenging earlier views of static and feedforward processing of sensory information.",,"Brain; Computer simulation; Feedforward neural networks; Information analysis; Sensors; Sensory perception; Brain strategies; Cortical functions; Dynamic processes; Perceptual learning; Learning systems; biology; learning; brain; brain function; expectation; experience; information processing; learning; nerve cell network; perception; positive feedback; priority journal; review; sensory system; task performance; theoretical model; Brain; Humans; Learning; Models, Neurological; Nerve Net; Neuronal Plasticity; Perception","Wang, Q., Cavanagh, P., Green, M., Familiarity and pop-out in visual search (1994) Percept. Psychophys., 56, pp. 495-500; Sigman, M., Gilber, C.D., Learning to find a shape (2000) Nature Neurosci., 3, pp. 264-269; Hertz, J., Krogh, A., Palmer, R.G., (1991) Introduction to the Theory of Neural Computation, , Perseus Publishing, Cambridge, Massachussetts; Zhaoping, L., Herzog, M., Dayan, P., Nonlinear observation and recurrent preprocessing in perceptual learning (2003) Network, 14, pp. 233-247; Poggio, T., Fahle, M., Edelman, S., Fast perceptual learning in visual hyperacuity (1992) Science, 256, pp. 1018-1021; Herzog, M.H., Fahle, M., The role of feedback in learning a vernier discrimination task (1997) Vision Res., 37, pp. 2133-2141; Adini, Y., Sagi, D., Tsodyks, M., Context enabled learning in human visual system (2003) Nature, 415, pp. 790-794; Tsodyks, M., Adini, Y., Sagi, D., Associative learning in early vision (2004) Neural Netw., 17, pp. 823-832; Wilson, H.R., Cowan, J.D., Excitatory and inhibitory interactions in localized populations of model neurons (1972) Biophys. J., 12, pp. 1-24; Hoshino, O., Neuronal bases of perceptual learning revealed by a synaptic balance scheme (2004) Neural Comput., 16, pp. 563-594; Teich, A., Qian, N., Learning and adaptation in a recurrent model of V1 orientation selectivity (2003) J. Neurophysiol., 89, pp. 2086-2100; Schoups, A., Vogels, R., Qian, N., Orban, G., Practising orientation identification improves orientation coding in V1 neurons (2001) Nature, 412, pp. 549-553; Ben-Yishai, R., Bar-Or, R.L., Sompolinsky, H., Theory of orientation tuning in visual cortex (1995) Proc. Natl. Acad. Sci. USA, 92, pp. 3844-3848; Douglas, R., Koch, C., Mahowald, M., Martin, K., Suarez, H., Recurrent excitation in neocortical circuits (1995) Science, 269, pp. 981-985; Somers, D., Nelson, S., Sur, M., An emergent model of orientation selectivity in cat visual cortical simple cells (1995) J. Neurosci., 15, pp. 5448-5465; Gilbert, C.D., Wiesel, T.N., The influence of contextual stimuli on the orientation selectivity of cells in primary visual cortex of the cat (1990) Vision Res., 30, pp. 1689-1701; Dragoi, V., Sharma, J., Sur, M., Adaptation-induced plasticity of orientation tuning in adult visual cortex (2000) Neuron, 28, pp. 287-298; Polat, U., Sagi, D., Spatial interactions in human vision: From near to far via experience-dependent cascade of connections (1994) Proc. Natl. Acad. Sci. USA, 91, pp. 1206-1209; Seung, H.S., Learning in spiking neural networks by reinforcement of stochastic synaptic transmission (2003) Neuron, 40, pp. 1063-1073; Williams, R., Simple statistical gradient-following algorithms for connectionst reinforcement learning (1992) Mach. Learn., 8, pp. 229-256; Grist, R.E., Kapadia, M., Westheimer, G., Gilbert, C.D., Perceptual learning of spatial localization: Specificity for orientation, position and context (1997) J. Neurophysiol., 78, pp. 2889-2894; McKee, S.P., Westheimer, G., Improvement in vernier acuity with practice (1978) Percept. Psychophys., 24, pp. 258-262; Polat, U., Ma-Naim, T., Belkin, M., Sagi, D., Improving vision in adult amblyopia by perceptual learning (2004) Proc. Natl. Acad. Sci. USA, 101, pp. 6692-6697; Ullman, S., Bart, E., Recognition invariance obtained by extended and invariant features (2004) Neural Netw., 17, pp. 833-848; Grist, R., Li, W., Gilbert, C., Learning to see: Experience and attention in primary visual cortex (2001) Nature Neurosci., 4, pp. 519-525; Li, W., Piech, V., Gilber, C.D., Perceptual learning and top-down influences in primary visual cortex (2004) Nature Neurosci., 7, pp. 651-657; Recanzone, G.H., Merzenich, M.M., Jenkins, W.M., Frequency discrimination training engaging a restricted skin surface results in an emergence of a cutaneous response zone in cortical area 3a (1992) J. Neurophysiol., 67, pp. 1057-1070; Recanzone, G.H., Schreiner, C.E., Merzenich, M.M., Plasticity in the frequency representation of primary auditory cortex following discrimination training in adult owl monkeys (1993) J. Neurosci., 13, pp. 87-103; Recanzone, G.H., Merzenich, M.M., Schreiner, C.E., Changes in the distributed temporal response properties of SI cortical neurons reflect improvements in performance on a temporally based tactile discrimination task (1992) J. Neurophysiol., 67, pp. 1071-1091; Bakin, J.S., Winberger, N.M., Induction of a physiological memory in the cerebral cortex by stimulation of the nuclear basalis (1996) Proc. Natl. Acad. Sci. USA, 93, pp. 11219-11224; Kilgard, M.P., Merzenich, M.M., Cortical map reorganization enabled by nucleus basalis activity (1998) Science, 279, pp. 1714-1718; Seung, H.S., Sompolinsky, H., Tishby, N., Statistical mechanics of learning from examples (1992) Phys. Rev. A, 45, pp. 6056-6091; Herzog, M.H., Fahle, M., Modeling perceptual learning difficulties and how they can be overcome (1998) Biol. Cybern., 78, pp. 107-117; Mato, G., Sompolinsky, H., Neural network models of perceptual learning of angle discrimination (1996) Neural Comput., 8, pp. 270-299; Dosher, B.A., Lu, Z.L., Perceptual learning reflects external noise filtering and internal noise reduction through channel reweighting (1998) Proc. Natl. Acad. Sci. USA, 95, pp. 13988-13993; Moses, Y., Schechtman, G., Ullman, S., Self-calibrated collinearity detector (1990) Biol. Cybern., 63, pp. 463-475; Weiss, Y., Edelman, S., Fahle, M., Models of perceptual learning in vernier hyperacuity (1993) Neural Comput., 5, pp. 695-718; Karni, A., Sagi, D., The time course of learning a visual skill (1993) Nature, 365, pp. 250-252; Ahissar, M., Hochstein, S., Attentional control of early perceptual learning (1993) Proc. Natl. Acad. Sci. USA, 90, pp. 5718-5722; Watanabe, T., Nanez, J.E., Sasaki, Y., Perceptual learning without perception (2001) Nature, 413, pp. 844-848; Seitz, A.R., Watanabe, T., Psychophysics: Is subliminal learning really passive? (2003) Nature, 422, p. 36; Rao, R.P., Ballard, D.H., Dynamic model of visual recognition predicts neural response properties in the visual cortex (1997) Neural Comput., 9, pp. 721-763; Ullman, S., Sequence seeking and counter streams: A computational model for bidirectional information flow in the visual cortex (1995) Cereb. Cortex, 5, pp. 1-11; Hebb, D.O., (1949) Organization of Behavior, , John Wiley & Sons Inc; Barlow, H.B., Foldiak, P., (1989) The Computing Neuron, pp. 54-72. , (eds Durbin, R. Miall, C. & Mitchison, G.) (Addison-Wesley, Workingham, England); Markram, H., Lubke, J., Frotscher, M., Sakmann, B., Regulation of synaptic efficacy by coincidence of postsynaptic Aps and EPSPs (1997) Science, 275, pp. 213-215; Senn, W., Markram, H., Tsodyks, M., An algorithm for modifying neurotransmitter release probability based on pre- and post-synaptic spike timing (2001) Neural Comput., 13, pp. 35-67; Yu, C., Levi, D.M., Klein, S.A., Perceptual learning in contrast discrimination and the (minimal) role of context (2004) J. Vision, 4, pp. 169-182; Adini, Y., Wilkonsky, A., Haspel, R., Tsodyks, M., Sagi, D., Perceptual learning in contrast discrimination: The effect of contrast uncertainty J. Vision, , in the press; Chose, G.M., Yang, T., Maunsell, J.H.R., Physiological correlates of perceptual learning in monkey V1 and V2 (2002) J. Nearophysiol., 87, pp. 1867-1888",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Eiben A.E., Smith J.",7004362543;7410180217;,From evolutionary computation to the evolution of things,2015,Nature,10.1038/nature14544,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84930674315&doi=10.1038%2fnature14544&partnerID=40&md5=3649e5b9c6aa0813132e2ae3624ff0c0,"Evolution has provided a source of inspiration for algorithm designers since the birth of computers. The resulting field, evolutionary computation, has been successful in solving engineering tasks ranging in outlook from the molecular to the astronomical. Today, the field is entering a new phase as evolutionary algorithms that take place in hardware are developed, opening up new avenues towards autonomous machines that can adapt to their environment. We discuss how evolutionary computation compares with natural evolution and what its benefits are relative to other computing approaches, and we introduce the emerging area of artificial evolution in physical systems. © 2015 Macmillan Publishers Limited. All rights reserved .",,"algorithm; hardware; machinery; technological development; art; artificial intelligence; astronomy; computer; evolutionary adaptation; evolutionary algorithm; genotype; human; machine learning; priority journal; problem solving; research; Review; adaptation; algorithm; automation; biomimetics; computer; devices; evolution; mathematics; robotics; theoretical model; trends; Adaptation, Physiological; Algorithms; Automation; Biological Evolution; Biomimetics; Computers; Genotype; Mathematics; Models, Theoretical; Problem Solving; Robotics","Turing, A.M., (1969) Machine Intelligence, 5. , eds Meltzer, B. & Michie, D. Edinburgh Univ. Press; Fogel, L., Owens, L.A.J., Walsh, M.J., (1966) Artificial Intelligence Through Simulated Evolution, , Wiley; Rechenberg, I., (1973) Evolutionstrategie: Optimierung Technisher Systeme Nach Prinzipien des Biologischen Evolution, , in German. Fromman-HozlboogHozlboog; Schwefel, H.-P., (1977) Numerical Optimization of Computer Models, , Birkhäuser; Holland, J.H., (1975) Adaption in Natural and Artificial Systems, , Univ. Michigan Press; Koza, J.R., (1992) Genetic Programming, , MIT Press; Eiben, A.E., Smith, J.E., (2003) Introduction to Evolutionary Computing, , Springer; Ashlock, D., (2006) Evolutionary Computation for Modeling and Optimization, , Springer; De Jong, K., (2006) Evolutionary Computation: A Unified Approach, , MIT Press; Wang, C., Yu, S., Chen, W., Sun, C., Highly efficient light-trapping structure design inspired by natural evolution (2013) Sci. Rep., 3, p. 1025; Schmidt, M., Lipson, H., Distilling free-form natural laws from experimental data (2009) Science, 324, pp. 81-85; Eiben, A.E., Kernbach, S., Haasdijk, E., Embodied artificial evolution: Artificial evolutionary systems in the 21st Century (2012) Evol. Intel., 5, pp. 261-272; Eiben, A.E., (2014) Parallel Problem Solving from Nature-PPSNXII, pp. 24-39. , eds Filipic, B., Bartz-Beielstein, T. Branke, J. & Smith, J. Springer; Piperno, D.R., Ranere, A.J., Holst, I., Iriarte, J., Dickau, R., Starch grain and phytolith evidence for early ninth millennium B.P. Maize from the central balsas river valley, Mexico (2009) Proc. Natl Acad. Sci. USA, 106, pp. 5019-5024; Akey, J.M., Tracking footprints of artificial selection in the dog genome (2010) Proc. Natl Acad. Sci. USA, 107, pp. 1160-1165; Dennett, D., (1995) Darwin's Dangerous Idea, , Penguin; Goldberg, D., (1989) Genetic Algorithms in Search, Optimization, and Machine Learning, , Addison-Wesley; Fogel, D.B., (1995) Evolutionary Computation, , IEEE; Schwefel, H.-P., (1995) Evolution and Optimum Seeking, , Wiley; Bäck, T., (1996) Evolutionary Algorithms in Theory and Practice, , Oxford Univ. Press; Banzhaf, W., Nordin, P., Keller, R.E., Francone, F.D., (1998) Genetic Programming: An Introduction, , Morgan Kaufmann; Storn, R., Price, K., Differential evolution-a simple and efficient heuristic for global optimization over continuous spaces (1997) J. Glob. Optim., 11, pp. 341-359; Price, K.V., Storn, R.N., Lampinen, J.A., (2005) Differential Evolution: A Practical Approach to Global Optimization, , Springer; Kennedy, J., Eberhart, R.C., Particle swarm optimization (1995) Proc. IEEE International Conference on Neural Networks, pp. 1942-1948. , IEEE; Kennedy, J., Eberhart, R.C., (2001) Swarm Intelligence, , Morgan Kaufmann; De Jong, K.A., Are genetic algorithms function optimizers (1992) Proc. 2nd Conference on Parallel Problem Solving from Nature, pp. 3-13. , eds Manner, R. & Manderick, B. North-Holland; Hornby, G.S., Lohn, J.D., Linden, D.S., Computer-automated evolution of an X-band antenna for NASA's space technology 5 mission (2011) Evol. Comput., 19, pp. 1-23; Arias-Montano, A., Coello, C.A.C., Mezura-Montes, E., Multiobjective evolutionary algorithms in aeronautical and aerospace engineering (2012) IEEE Trans. Evol. Comput., 16, pp. 662-694; Besnard, J., Automated design of ligands to polypharmacological profiles (2012) Nature, 492, pp. 215-220; Posìk Huyer, P.W., Pal, L., A comparison of global search algorithms for continuous black box optimization (2012) Evol. Comput., 20, pp. 509-541; Hansen, N., Ostermeier, A., Completely derandomized self-adaptation in evolution strategies (2001) Evol. Comput., 9, pp. 159-195; Bäck, T., Foussette, C., Krause, P., (2013) Contemporary Evolution Strategies, , Springer; Yao, X., Evolving artificial neural networks (1999) Proc. IEEE, 87, pp. 1423-1447; Floreano, D., Dürr, P., Mattiussi, C., Neuroevolution: From architectures to learning (2008) Evol. Intel., 1, pp. 47-62; Barros, R.C., Basgalupp, M.P., De Carvalho, A.C.P.L.F., Freitas, A.A., A survey of evolutionary algorithms for decision-tree induction (2012) IEEE Trans. Syst. Man Cybern. C, 42, pp. 291-312; Widera, P., Garibaldi, J.M., Krasnogor, N., GP challenge: Evolving energy function for protein structure prediction (2010) Genet. Program. Evolvable Mach., 11, pp. 61-88; Filipi, B., Urbani, T., Križman, V., A combined machine learning and genetic algorithm approach to controller design (1999) Eng. Appl. Artif. Intell., 12, pp. 401-409; Watson, R.A., Ficici, S.G., Pollack, J.B., Embodied evolution: Distributing an evolutionary algorithm in a population of robots (2002) Robot. Auton. Syst., 39, pp. 1-18; Bredeche, N., Montanier, J.M., Liu, W., Winfield, A.F.T., Environment-driven distributed evolutionary adaptation in a population of autonomous robotic agents (2012) Math. Comput. Model. Dyn. Syst., 18, pp. 101-129; Nolfi, S., Floreano, D., (2000) Evolutionary Robotics: The Biology, Intelligence, and Technology of Self-Organizing Machines, , MIT Press; Bongard, J., Evolutionary robotics (2013) Commun. ACM, 56, pp. 74-85; Floreano, D., Keller, L., Evolution of adaptive behavior in robots by means of darwinian selection (2010) PLoS Biol., 8, p. e1000292; Hinton, G.E., Nowlan, S.J., How learning can guide evolution (1987) Complex Syst., 1, pp. 495-502; Borenstein, E., Meilijson, I., Ruppin, E., The effect of phenotypic plasticity on evolution in multipeaked fitness landscapes (2006) J. Evol. Biol., 19, pp. 1555-1570; Paenke, I., Jin, Y., Branke, J., Balancing population and individual level of adaptation in changing environments (2009) Adapt. Behav., 17, pp. 153-174; Chen, X.S., Ong, Y.S., Lim, M.H., Tan, K.C.A., Multi-facet survey on memetic computation (2011) IEEE Trans. Evol. Comput., 15, pp. 591-607; Krasnogor, N., Smith, J.E., A tutorial for competent memetic algorithms: Model, taxonomy and design issues (2005) IEEE Trans. Evol. Comput., 9, pp. 474-488; Smith, J.E., Clark, A.R., Staggemeier, A.T., Serpell, M.C., A genetic approach to statistical disclosure control (2012) IEEE Trans. Evol. Comput., 16, pp. 431-441; Bentley, P., Corne, D., (2002) Creative Evolutionary Systems, , Morgan Kaufmann; Romero, J.J., Machado, P., (2008) The Art of Artificial Evolution: A Handbook on Evolutionary Art and Music, , Springer; Secretan, J., Picbreeder: A case study in collaborative evolutionary exploration of design space (2011) Evol. Comput., 19, pp. 373-403; Bentley, P., (1999) Evolutionary Design by Computers, , Morgan Kaufmann; Hingston, P.F., Barone, L.C., Michalewicz, Z., (2008) Advances in Evolutionary Design, , Springer; Koza, J.R., Human-competitive results produced by genetic programming (2010) Genet. Program. Evolvable Mach., 11, pp. 251-284; Eiben, A.E., Rudolph, G., Theory of evolutionary algorithms: A bird's eye view (1999) Theor. Comput. Sci., 229, pp. 3-9; Wolpert, D.H., Macready, W.G., No free lunch theorems for optimisation (1997) IEEE Trans. Evol. Comput., 1, pp. 67-82; Rudolph, G., Convergence analysis of canonical genetic algorithms (1994) IEEE Trans. Neural Netw., 5, pp. 96-101; Lehre, P.R., Yao, X., On the impact of mutation-selection balance on the runtime of evolutionary algorithms (2012) IEEE Trans. Evol. Comput., 16, pp. 225-241; Jansen, T., (2005) Analyzing Evolutionary Algorithms: The Computer Science Perspective, , Springer; Borenstein, Y., Moraglio, A., (2014) Theory and Principled Methods for Designing Metaheuristics, , Springer; Eiben, A.E., Hinterding, R., Michalewicz, Z., Parameter control in evolutionary algorithms (1999) IEEE Trans. Evol. Comput., 3, pp. 124-141; Bartz-Beielstein, T.T., (2006) Experimental Research in Evolutionary Computation: The New Experimentalism, , Springer; Hutter, F., Hoos, H.H., Leyton-Brown, K., Stützle, T., ParamILS: An automatic algorithm configuration framework (2009) J. Artif. Intell. Res., 36, pp. 267-306; Eiben, A.E., Smit, S.K., Parameter tuning for configuring and analyzing evolutionary algorithms (2011) Swarm Evol. Comput., 1, pp. 19-31; Bartz-Beielstein, T., Preuss, M., (2014) Theory and Principled Methods for Designing Metaheuristics, pp. 205-245. , eds Borenstein, Y. & Moraglio, A. Springer; Lobo, F.J., Lima, C.F., Michalewicz, Z., (2007) Parameter Setting in Evolutionary Algorithms, , Springer; Serpell, M., Smith, J.E., Self-adaption of mutation operator and probability for permutation representations in genetic algorithms (2010) Evol. Comput., 18, pp. 491-514; Fialho, A., Da Costa, L., Schoenauer, M., Sebag, M., Analyzing bandit-based adaptive operator selection mechanisms (2010) Ann. Math. Artif. Intell., 60, pp. 25-64; Karafotias, G., Hoogendoorn, M., Eiben, A.E., Parameter control in evolutionary algorithms: Trends and challenges (2015) IEEE Trans. Evol. Comput., 19, pp. 167-187; Jin, Y.A., Comprehensive survey of fitness approximation in evolutionary computation (2005) Soft Comput., 9, pp. 3-12; Jin, Y., Surrogate-assisted evolutionary computation: Recent advances and future challenges (2011) Swarm Evol. Comput., 1, pp. 61-70; Loshchilov, I., Schoenauer, M., Sebag, M., Self-adaptive surrogate-assisted covariance matrix adaptation evolution strategy (2012) Proc. Conference on Genetic and Evolutionary Computation, pp. 321-328. , eds Soule, T. & Moore, J. H. ACM; Zaefferer, M., Efficient global optimization for combinatorial problems (2014) Proc. Conference on Genetic and Evolutionary Computation, pp. 871-878. , eds Igel, C. & Arnold, D. V. ACM; Deb, K., (2001) Multi-objective Optimization Using Evolutionary Algorithms, , Wiley; Zhang, Q., Li, H., MOEA/D: A multi-objective evolutionary algorithm based on decomposition (2007) IEEE Trans. Evol. Comput., 11, pp. 712-731; Deb, K., Jain, H., An evolutionary many-objective optimization algorithm using reference-point-based nondominated sorting approach, part I: Solving problems with box constraints (2014) IEEE Trans. Evol. Comput., 18, pp. 577-601; Jain, H., Deb, K., An evolutionary many-objective optimization algorithm using reference-point based non-dominated sorting approach, part II: Handling constraints and extending to an adaptive approach (2014) IEEE Trans. Evol. Comput., 18, pp. 602-622; Branke, J., Greco, S., Slowinski, R., Zielniewicz, P., Learning value functions in interactive evolutionary multiobjective optimization (2015) IEEE Trans. Evol. Comput., 19, pp. 88-102; Stanley, K.O., Compositional pattern producing networks: A novel abstraction of development (2007) Genet. Program. Evolvable Mach., 8, pp. 131-162; O'Reilly, U.-M., Hemberg, H., Integrating generative growth and evolutionary computation for form exploration (2007) Genet. Program. Evolvable Mach., 8, pp. 163-186; Clune, J., Stanley, K.O., Pennock, R., Ofria, C., On the performance of indirect encoding across the continuum of regularity (2011) IEEE Trans. Evol. Comput., 15, pp. 346-367; Jin, Y., Meng, Y., Morphogenetic robotics: An emerging new field in developmental robotics (2011) IEEE Trans. Syst. Man Cybern. C, 41, pp. 145-160; Doursat, R., Sayama, H., Michel, O., (2013) Orphogenetic Engineering: Toward Programmable Complex Systems, , Springer; Doncieux, S., Bredeche, N., Mouret, J.-B., (2011) New Horizons in Evolutionary Robotics, , Springer; Vargas, P.A., Di Paolo, E.A., Harvey, I., Husbands, P., (2014) The Horizons of Evolutionary Robotics, , MIT Press; Harman, M., McMinn, P., A theoretical and empirical study of search-based testing: Local, global, and hybrid search (2010) IEEE Trans. Softw. Eng., 36, pp. 226-247; Preen, R., Bull, L., Towards the coevolution of novel vertical-axis wind turbines (2015) IEEE Trans. Evol. Comput., 19, pp. 284-294; Banzhaf, W., From artificial evolution to computational evolution: A research agenda (2006) Nature Rev. Genet., 7, pp. 729-735; Maynard Smith, J., Byte-sized evolution (1992) Nature, 355, pp. 772-773; Waibel, M., Floreano, D., Keller, L., A quantitative test of Hamilton's rule for the evolution of altruism (2011) PLoS Biol., 9, p. e1000615; Long, J., Darwin's devices: What evolving robots can teach us about the history of life and the future of technology (2012) Basic Books; Virgo, N., Fernando, C., Bigge, B., Husbands, P., Evolvable physical self-replicators (2012) Artif. Life, 18, pp. 129-142; Bongard, J., Lipson, H., Evolved machines shed light on robustness and resilience (2014) Proc. IEEE, 102, pp. 899-914; Bongard, J., Morphological change in machines accelerates the evolution of robust behavior (2011) Proc. Natl Acad. Sci. USA, 108, pp. 1234-1239; Eiben, A.E., Grand challenges for evolutionary robotics (2014) Front. Robot. AI, p. 1. , http://dx.doi.org/10.3389/frobt.2014.00004; Fernando, C., Kampis, G., Szathmáry, E., Evolvability of natural and artificial systems (2011) Procedia Comput. Sci., 7, pp. 73-76",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Kingsford C., Salzberg S.L.",35611336100;7005045166;,What are decision trees?,2008,Nature Biotechnology,10.1038/nbt0908-1011,https://www.scopus.com/inward/record.uri?eid=2-s2.0-51349111653&doi=10.1038%2fnbt0908-1011&partnerID=40&md5=cd28d841c1d9b38e9b420c9621e6f449,[No abstract available],,"accuracy; bioinformatics; biology; calculation; classification; decision tree; gene expression; machine learning; performance; prediction; priority journal; probability; protein function; review; spliceosome; validation process; Algorithms; Artificial Intelligence; Biomedical Research; Computational Biology; Decision Making, Computer-Assisted; Decision Support Techniques; Decision Trees; Genome, Fungal; Genome, Human; Humans; Models, Statistical; Neural Networks (Computer); Protein Interaction Mapping; Saccharomyces cerevisiae","Quinlan, J.R., (1993) C4.5: Programs for Machine Learning, , Morgan Kaufmann Publishers, San Mateo, CA, USA; Breiman, L., Friedman, J., Olshen, R., Stone, C., (1984) Classification and Regression Trees, , Wadsworth International Group, Belmont, CA, USA; Caruana, R., Niculescu-Mizil, A., An empirical comparison of supervised learning algorithms (2003) Machine Learning, Proceedings of the Twenty-Third International Conference, pp. 161-168. , eds. Cohen, W.W. & Moore, A, ACM, New York; Zadrozny, B., Elkan, C., Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers (2001) Proceedings of the 18th International Conference on Machine Learning, pp. 609-616. , eds. Brodley, C.E. & Danyluk, A.P, Morgan Kaufmann, San Francisco; Murthy, S.K., Kasif, S., Salzberg, S., A system for induction of oblique decision trees (1994) J. Artif. Intell. Res, 2, pp. 1-32; MacKay, D.J.C., (2003) Information Theory, Inference and Learning Algorithms, , Cambridge University Press, Cambridge, UK; Quinlan, J.R., Rivest, R.L., Inferring decision trees using the Minimum Description Length Principle (1989) Inf. Comput, 80, pp. 227-248; Breiman, L., Random forests (2001) Mach. Learn, 45, pp. 5-32; Heath, D., Kasif, S., Salzberg, S., Committees of decision trees (1996) Cognitive Technology: In Search of a Human Interface, pp. 305-317. , eds. Gorayska, B. & Mey, J, Elsevier Science, Amsterdam, The Netherlands; Schapire, R.E., The boosting approach to machine learning: An overview (2003) Nonlinear Estimation and Classification, pp. 141-171. , eds. Denison, D.D, Hansen, M.H, Holmes, C.C, Mallick, B. & Yu, B, Springer, New York; Freund, Y., Mason, L., The alternating decision tree learning algorithm (1999) Proceedings of the 16th International Conference on Machine Learning, pp. 124-133. , eds. Bratko, I. & Džeroski, S, Morgan Kaufmann, San Francisco; Wong, S.L., Combining biological networks to predict genetic interactions (2004) Proc. Natl. Acad. Sci. USA, 101, pp. 15682-15687; Allen, J.E., Majoros, W.H., Pertea, M., Salzberg, S.L., JIGSAW, GeneZilla, and GlimmerHMM: Puzzling out the features of human genes in the ENCODE regions (2006) Genome Biol, 7 (SUPPL.), p. 9. , S; Middendorf, M., Kundaje, A., Wiggins, C., Freund, Y., Leslie, C., Predicting genetic regulatory response using classification (2004) Bioinformatics, 20, pp. i232-i240; Chen, X.-W., Liu, M., Prediction of protein-protein interactions using random decision forest framework (2005) Bioinformatics, 21, pp. 4394-4400",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Hirschberg J., Manning C.D.",7005619286;35280197500;,Advances in natural language processing,2015,Science,10.1126/science.aaa8685,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937806794&doi=10.1126%2fscience.aaa8685&partnerID=40&md5=fa9fad53db9bf2a3108cba2e55687864,"Natural language processing employs computational techniques for the purpose of learning, understanding, and producing human language content. Early computational approaches to language research focused on automating the analysis of the linguistic structure of language and developing basic technologies such asmachine translation, speech recognition, and speech synthesis.Today's researchers refine and make use of such tools in real-world applications, creating spoken dialogue systems and speech-to-speech translation engines, mining social media for information about health or finance, and identifying sentiment and emotion toward products and services.We describe successes and challenges in this rapidly advancing area.",,automation; computer simulation; finance; language; learning; research work; technological change; technological development; computer interface; human; linguistics; machine learning; natural language processing; oral communication; priority journal; reading; Review; social media; speech; translating (language); data mining; procedures; translating (language); Data Mining; Humans; Natural Language Processing; Social Media; Translating,"Manning, C.D., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S.J., McClosky, D., The stanford corenlp natural language processing toolkit (2014) Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, System Demonstrations, pp. 55-60. , (Association for Computational Linguistics Stroudsburg, PA; Linguistic Data Consortium, , www.ldc.upenn.edu; CoNLL Shared Tasks, , http://ifarm.nl/signll/conll; Kaggle, , www.kaggle.com; Brown, P.F., Della Pietra, S.A., Della Pietra, V.J., Mercer, R.L., (1993) Comput. Linguist., 19, pp. 263-311; Koehn, P., Och, F.J., Marcu, D., Statistical phrase-based translation (2003) Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pp. 48-54. , (Association for Computational Linguistics, Stroudsburg, PA; Chiang, D., A hierarchical phrase-based model for statistical machine translation (2005) Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pp. 263-270. , (Association for Computational Linguistics, Stroudsburg, PA; Galley, M., Hopkins, M., Knight, K., Marcu, D., What's in a translation rule? (2004) Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL 2004), , (Association for Computational Linguistics, Stroudsburg, PA; Jones, B., Andreas, J., Bauer, D., Hermann, K.M., Knight, K., Semantics-based machine translation with hyperedge replacement grammars (2012) Proceedings of COLING 2012 (Technical Papers, pp. 1359-1376. , The COLING 2012 Organizing Committee, Mumbai, India; Sutskever, I., Vinyals, O., Le, Q.V., Sequence to sequence learning with neural networks (2014) Advances in Neural Information Processing Systems, 27, pp. 3104-3112. , (NIPS 2014), Z. Ghahramani M. Welling, C. Cortes, N. D. Lawrence, K. Q. Weinberger, Eds. (Curran Associates, Red Hook, NY; Bahdanau, D., Cho, K., Bengio, Y., (2015) Neural Machine Translation by Jointly Learning to Align and Translate, , http://arxiv.org/abs/1409.0473; Luong, M.-T., Sutskever, I., Le, Q.V., Vinyals, O., Zaremba, W., (2015) Addressing the Rare Word Problem in Neural Machine Translation, , http://arxiv.org/abs/1410.8206; Jean, S., Cho, K., Memisevic, R., Bengio, Y., (2015) On Using Very Large Target Vocabulary for Neural Machine Translation, , http://arxiv.org/abs/1412.2007; Stymne, S., Hardmeier, C., Tiedemann, J., Nivre, J., Feature weight optimization for discourse-level SMT (2013) Proceedings of the Workshop on Discourse in Machine Translation (DiscoMT), pp. 60-69. , (Association for Computational Linguistics, Stroudsburg, PA; Green, S., Chuang, J., Heer, J., Manning, C.D., Predictive translation memory: A mixed-initiative system for human language translation (2014) Proceedings of the 27th Annual ACM Symposium on User Interface Software and Technology, pp. 177-187. , Honolulu, HI, 5 to 8 October 2014 (Association for Computing Machinery, New York; Rosenthal, S., Biswas, J., Veloso, M., An effective personal mobile robot agent through symbiotic human-robot interaction (2010) Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2010), pp. 915-922. , Toronto, Canada, 10 to 14 May 2010 (International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC; Fasola, J., Matari, M.J., (2013) J. Human-Robot Interact., 2, pp. 3-32; Core, M., Lane, H.C., Traum, D., Intelligent tutoring support for learners interacting with virtual humans (2014) Design Recommendations for Intelligent Tutoring Systems, 2, pp. 249-257. , (U.S. Army Research Laboratory Orlando, FL; Devault, D., Artstein, R., Benn, G., Dey, T., Fast, E., Gainer, A., Georgila, K., Morency, L.-P., SimSensei Kiosk: A virtual human interviewer for healthcare decision support (2014) Proceedings of the 13th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2014), pp. 1061-1068. , http://aamas2014.lip6.fr/proceedings/aamas/p1061.pdf, Paris, France, 5 to 9 May 2014 (International Foundation for Autonomous Agents and Multiagent Systems, Richland, SC; Hinton, G., (2012) IEEE Signal Process Mag., 29, pp. 82-97; Weizenbaum, J., (1966) Commun. ACM, 9, pp. 36-45; Nonaka, Y., Sakai, Y., Yasuda, K., Nakano, Y., Towards assessing the communication responsiveness of people with dementia (2012) 12th International Conference on Intelligent Virtual Agents, pp. 496-498. , IVA'12 Springer, Berlin; Nass, C., Moon, Y., Fogg, B.J., Reeves, B., Dryer, D.C., (1995) Int. J. Hum. Comput. Stud., 43, pp. 223-239; Giles, H., Mulac, A., Bradac, J.J., Johnson, P., Speech accommodation theory: The next decade and beyond (1987) Communication Yearbook, 10, pp. 13-48. , Sage, Newbury Park, CA; Young, S., Gasic, M., Thomson, B., Williams, J., (2013) Proc. IEEE, 101, pp. 1160-1179; Wikipedia, , www.wikipedia.org; Hunter, L., Cohen, K.B., (2006) Mol. Cell, 21, pp. 589-594; Culotta, A., Sorensen, J., Dependency tree kernels for relation extraction (2004) Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (Association for Computational Linguistics, pp. 423-429. , Stroudsburg, PA; Fundel, K., Küffner, R., Zimmer, R., (2007) Bioinformatics, 23, pp. 365-371; Björne, J., (2011) Comput Intell., 27, pp. 541-557; Van Landeghem, S., (2013) PLOS ONE, 8, p. e55814; Ashburner, M., The gene ontology consortium (2000) Nat. Genet., 25, pp. 25-29; PaleoBiology Database, , https://paleobiodb.org; Coulet, A., Cohen, K.B., Altman, R.B., (2012) J. Biomed. Inform., 45, pp. 825-826; Percha, B., Garten, Y., Altman, R.B., (2012) Pac. Symp. Biocomput., 2012, pp. 410-421; Freebase, , www.freebase.com; Dbpedia, , http://dbpedia.org; Wikidata, , www.wikidata.org; Mintz, M., Bills, S., Snow, R., Jurafsky, D., Distant supervision for relation extraction without labeled data (2009) Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (Association for Computational Linguistics, 2, pp. 1003-1011. , Stroudsburg, PA; Surdeanu, M., Tibshirani, J., Nallapati, R., Manning, C.D., Multi-instance multi-label learning for relation extraction (2012) Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing and Natural Language Learning (EMNLP-CoNLL), pp. 455-465. , Jeju Island, South Korea, 12 to 14 July 2012 (Association for Computational Linguistics, Stroudsburg, PA; Min, B., Grishman, R., Wan, L., Wang, C., Gondek, D., Distant supervision for relation extraction with an incomplete knowledge base (2013) Proceedings of NAACL-HLT 2013, pp. 777-782. , Atlanta, GA, 9 to 14 June 2013 (Association for Computational Linguistics, Stroudsburg, PA; DeepDive, , http://deepdive.stanford.edu; Peters, S.E., Zhang, C., Livny, M., Ré, C., (2014) PLOS ONE, 9, p. e113523; Etzioni, E., Banko, M., Cafarella, M.J., Machine reading (2006) Proceedings of the 21st National Conference on Artificial Intelligence (AAAI 2006), 2, pp. 1517-1519. , Boston, MA, 16 to 20 July 2006 (AAAI Press, Menlo Park, CA; Banko, M., Cafarella, M.J., Soderland, S., Broadhead, M., Etzioni, O., Open information extraction from the web (2007) Proceedings of the 20th International Joint Conference on Artifical Intelligence (IJCAI 2007), pp. 2670-2676. , (Morgan Kaufmann, San Francisco; Etzioni, O., Fader, A., Christensen, J., Soderland Mausam, S., Open information extraction: The second generation (2011) Proceedings of the 22nd International Joint Conference on Artificial Intelligence, pp. 3-10. , Barcelona, Spain, 16 to 22 July 2011 (AAAI Press, Menlo Park, CA; Riedel, S., Yao, L., McCallum, A., Marlin, B.M., Relation extraction with matrix factorization and universal schemas (2013) Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics (HLT NAACL 2013), pp. 74-84. , (Stroudsburg, PA; Angeli, G., Manning, C.D., NaturalLI: Natural logic inference for common sense reasoning (2014) Proceedings of the 2014 Conference on Emprical Methods in Natural Language Processing, pp. 534-545. , Doha, Qatar, 25 to 29 October 2014 (Association for Computational Linguistics, Stroudsburg, PA; Berant, J., Srikumar, V., Chen, P.-C., Vander Linden, A., Harding, B., Huang, B., Clark, P., Manning, C.D., Modeling biological processes for reading comprehension (2014) Proceedings of the 2014 Conference on Emprical Methods in Natural Language Processing, pp. 1499-1510. , Doha, Qatar, 25 to 29 October 2014 (Association for Computational Linguistics, Stroudsburg, PA; Fader, A., Zettlemoyer, L., Etzioni, O., Open question answering over curated and extracted knowledge bases (2014) Proceedings of the Conference on Knowledge Discovery and Data Mining (KDD), pp. 1156-1165. , (Association for Computing Machinery, New York; Russell, M.A., (2013) Mining the Social Web: Data Mining Facebook Twitter LinkedIn Google+ GitHub and More, 2. , O'Reilly Media Sebastopol, CA, ed; Elhadad, N., Gravano, L., Hsu, D., Balter, S., Reddy, V., Waechter, H., Information extraction from social media for public health (2014) KDD at Bloomberg Workshop, Data Frameworks Track, , (KDD 2014) (Association for Computing Machinery, New York; Ott, M., Cardie, C., Hancock, J.T., Estimating the prevalence of deception in online review communities (2012) Proceedings of the 21st International Conference on World Wide Web Conference, pp. 201-210. , Lyon, France, 16 to 20 April 2012 (Association for Computing Machinery, New York; Liscombe, J., (2007) Thesis, , Columbia University; Wiebe, J., Wilson, T., Cardie, C., (2005) Lang. Resour. Eval., 39, pp. 165-210; Whissell, C., The dictionary of affect in language (1989) Emotion: Theory, Research and Experience, , R. Plutchik, H. Kellerman, Eds. Academic Press, London; Tausczik, Y.R., Pennebaker, J.W., (2010) J. Lang. Soc. Psychol., 29, pp. 24-54; Türk, O., Schröder, M., (2010) IEEE Trans. Audio Speech Lang. Proc., 18, pp. 965-973; Pang, B., Lee, L., Vaithyanathan, S., Thumbs up? Sentiment classification using machine learning techniques (2002) Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, 10, pp. 79-86. , Philadelphia, PA, July 2002 (Association for Computational Linguistics, Stroudsburg, PA; Wang, H., Ester, M., A sentiment-aligned topic model for product aspect rating prediction (2014) Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pp. 1192-1202. , Doha, Qatar, 25 to 29 October 2014 (Association for Computational Linguistics, Stroudsburg, PA; Thomas, M., Pang, B., Lee, L., Get out the vote: Determining support or opposition from Congressional floor-debate transcripts (2006) Proceedings of the 2006 Conference on Emprical Methods in Natural Language Processing, pp. 327-335. , Sydney, Australia, 22 to 23 July 2006 (Association for Computational Linguistics, Stroudsburg, PA; Bollen, J., Mao, H., Pepe, A., Modeling public mood and emotion: Twitter sentiment and socio-economic phenomena (2011) Proceedings of the Fifth International AAAI Conference on Weblogs and Social Media, pp. 450-453. , Barcelona, Spain, 17 to 21 July 2011 (AAAI Press, Menlo Park; Gonzalez-Ibanez, R., Muresan, S., Wacholder, N., Identifying sarcasm in Twitter: A closer look (2011) Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pp. 581-586. , Portland, Oregon, 19 to 24 June 2011 (Association for Computational Linguistics, Stroudsburg, PA; Biran, O., Rosenthal, S., Andreas, J., McKeown, K., Rambow, O., Detecting influencers in written online conversations Proceedings of the 2012 Workshop on Language in Social Media, Montreal, pp. 37-45. , Canada, 7 June 2012 (Association for Computational Linguistics, Stroudsburg, PA, 2012; Yu, L.-C., Ho, C.-Y., Identifying emotion labels from psychiatric social texts using independent component analysis (2014) Proceedings of COLING 2014 (Technical Papers, Association for Computational Linguistics, pp. 837-847. , Stroudsburg, PA; Hayes, B., Londe, Z., (2006) Phonology, 23, pp. 59-104; Levy, R., (2008) Cognition, 106, pp. 1126-1177; Goodman, N.D., Lassiter, D., Probabilistic semantics and pragmatics: Uncertainty in language and thought (2015) Handbook of Contemporary Semantics, 2. , C. Fox, S. Lappin, Eds. Blackwell, Hoboken,NJ, ed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gershman S.J., Horvitz E.J., Tenenbaum J.B.",35108983800;6701318945;7006818404;,"Computational rationality: A converging paradigm for intelligence in brains, minds, and machines",2015,Science,10.1126/science.aac6076,https://www.scopus.com/inward/record.uri?eid=2-s2.0-84937783963&doi=10.1126%2fscience.aac6076&partnerID=40&md5=6d50fa20c1a26e74a67dfca1c683603b,"After growing up together, and mostly growing apart in the second half of the 20th century, the fields of artificial intelligence (AI), cognitive science, and neuroscience are reconverging on a shared view of the computational foundations of intelligence that promotes valuable cross-disciplinary exchanges on questions, methods, and results. We chart advances over the past several decades that address challenges of perception and action under uncertainty through the lens of computation. Advances include the development of representations and inferential procedures for large-scale probabilistic inference and machinery for enabling reflection and decisions about tradeoffs in effort, precision, and timeliness of computations. These tools are deployed toward the goal of computational rationality: identifying decisions with highest expected utility, while taking into consideration the costs of computation in complex real-world problems in which most relevant calculations can only be approximated.We highlight key concepts with examples that show the potential for interchange between computer science, cognitive science, and neuroscience.",,artificial intelligence; brain; cognition; computer simulation; decision analysis; machinery; mathematical analysis; neurology; paradigm shift; perception; trade-off; accuracy; artificial intelligence; Bayes theorem; brain; brain function; cognition; computational fluid dynamics; computer; decision making; executive function; history; human; intelligence; machine; neuroscience; perception; priority journal; probability; psychologist; psychology; Review; thinking; uncertainty; brain; intelligence; physiology; trends; Artificial Intelligence; Brain; Humans; Intelligence; Neurosciences; Thinking; Uncertainty,"Koller, D., Friedman, N., (2009) Probabilistic Graphical Models: Principles and Techniques, , MIT Press Cambridge MA; Pearl, J., (1988) Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference, , Morgan Kaufmann Publishers Los Altos CA; Russell, S., Norvig, P., (2009) Artificial Intelligence: A Modern Approach, , Pearson Upper Saddle River NJ; Von Neumann, J., Morgenstern, O., (1947) Theory of Games and Economic Behavior, , (Princeton Univ. Press, Princeton, NJ; Tenenbaum, J.B., Kemp, C., Griffiths, T.L., Goodman, N.D., (2011) Science, 331, pp. 1279-1285; Turing, A.M., (1936) Proc. Lond. Math. Soc., 2, pp. 230-265; Turing, A.M., (1950) Mind, 59, pp. 433-460; Von Neumann, J., (1958) The Computer and the Brain, , (Yale Univ. Press, New Haven, CT; Simon, H.A., (1957) Models of Man, , Wiley New York; Good, I.J., (1952) J. R. Stat. Soc. B, 14, pp. 107-114; Horvitz, E., (1987) Proceedings of the 3rd International Conference on Uncertainty in Artificial Intelligence, pp. 429-444. , (Mountain View, CA, July 1987; Russell, S., Wefald, E., (1991) Artif. Intell., 49, pp. 361-395; Horvitz, E., Cooper, G., Heckerman, D., (1989) Proceedings of IJCAI, pp. 1121-1127. , January 1989; Horvitz, E., Rutledge, G., (1991) Proceedings of the 7th International Conference on Uncertainty in Artificial Intelligence, pp. 151-158. , Morgan Kaufmann Publishers San Francisco; Horvitz, E., Ruan, Y., Gomes, G., Kautz, H., Selman, B., Chickering, D.M., (2001) Proceedings of 17th Conference on Uncertainty in Artificial Intelligence, pp. 235-244. , Morgan Kaufmann Publishers San Francisco; Horvitz, E., (2001) Artif. Intell., 126, pp. 159-196; Burns, E., Ruml, W., Do, M.B., (2013) J. Artif. Intell. Res., 47, pp. 697-740; Lin, C.H., Kolobov, A., Kamar, A., Horvitz, E., Metareasoning for planning under uncertainty (2015) Proceedings of IJCAI; Dean, T., Kaelbling, L.P., Kirman, J., Nicholson, A., (1995) Artif. Intell., 76, pp. 35-74; Hay, N., Russell, S., Tolpin, D., Shimony, S., (2012) Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence, pp. 346-355; Heckerman, D., Breese, J.S., Horvitz, E., (1989) Proceedings of the 5th Conference on Uncertainty in Artifical Intelligence, pp. 162-173. , July 1989; Cooper, G., (1990) Artif. Intell., 42, pp. 393-405; Peterson, C.R., Beach, L.R., (1967) Psychol. Bull., 68, pp. 29-46; Tversky, A., Kahneman, D., (1974) Science, 185, pp. 1124-1131; Gigerenzer, G., (2008) Rationality for Mortals: How People Cope with Uncertainty, , (Oxford Univ. Press, Oxford; Anderson, J.R., (1990) The Adaptive Character of Thought, , Lawrence Erlbaum Hillsdale NJ; Oaksford, M., Chater, N., (2007) Bayesian Rationality, , Oxford Univ. Press, Oxford; Griffiths, T.L., Tenenbaum, J.B., (2005) Cognit. Psychol., 51, pp. 334-384; Doya, K., Ishii, S., Pouget, A., Rao, R.P.N., (2007) The Bayesian Brain: Probabilistic Approaches to Neural Coding, , Eds MIT Press, Cambridge, MA; Griffiths, T.L., Lieder, F., Goodman, N.D., (2015) Top. Cogn. Sci., 7, pp. 217-229; Denison, S., Bonawitz, E., Gopnik, A., Griffiths, T.L., (2013) Cognition, 126, pp. 285-300; Vul, E., Frank, M., Alvarez, G., Tenenbaum, J.B., (2009) Adv. Neural Inf. Process. Syst., 29, pp. 1955-1963; Gershman, S.J., Vul, E., Tenenbaum, J.B., (2012) Neural Comput., 24, pp. 1-24; Sanborn, A.N., Griffiths, T.L., Navarro, D.J., (2010) Psychol. Rev., 117, pp. 1144-1167; Buesing, L., Bill, J., Nessler, B., Maass, W., (2011) PLOS Comput Biol., 7, p. e1002211; Isard, M., Blake, A., (1998) Int. J. Comput. Vis., 29, pp. 5-28; Levy, R., Reali, F., Griffiths, T.L., (2009) Adv. Neural Inf. Process. Syst., 21, pp. 937-944; Vul, E., Goodman, N., Griffiths, T.L., Tenenbaum, J.B., (2014) Cogn. Sci., 38, pp. 599-637; Kool, W., McGuire, J.T., Rosen, Z.B., Botvinick, M.M., (2010) J. Exp. Psychol. Gen., 139, pp. 665-682; Kool, W., Botvinick, M., (2014) J. Exp. Psychol. Gen., 143, pp. 131-141; McGuire, J.T., Botvinick, M.M., (2010) Proc. Natl. Acad. Sci. U.S.A., 107, pp. 7922-7926; Lieder, F., (2014) Adv. Neural Inf. Process. Syst., 27, pp. 2870-2878; Lewis, R.L., Howes, A., Singh, S., (2014) Top. Cogn. Sci., 6, pp. 279-311; Payne, J.W., Bettman, J.R., Johnson, E.J., (1988) J. Exp. Psychol. Learn. Mem. Cogn., 14, pp. 534-552; Rieskamp, J., Otto, P.E., (2006) J. Exp. Psychol. Gen., 135, pp. 207-236; Lieder, F., Hsu, M., Griffiths, T.L., (2014) Proc. 36th Ann. Conf. Cognitive Science Society, , (Austin, TX; Daw, N.D., Niv, Y., Dayan, P., (2005) Nat. Neurosci., 8, pp. 1704-1711; Killcross, S., Coutureau, E., (2003) Cereb Cortex, 13, pp. 400-408; Yin, H.H., Knowlton, B.J., Balleine, B.W., (2004) Eur. J. Neurosci., 19, pp. 181-189; Daw, N.D., Gershman, S.J., Seymour, B., Dayan, P., Dolan, R.J., (2011) Neuron, 69, pp. 1204-1215; Keramati, M., Dezfouli, A., Piray, P., (2011) PLOS Comput Biol., 7, p. e1002055; Dickinson, A., (1985) Philos. Trans. R. Soc. London B Biol. Sci., 308, pp. 67-78; Otto, A.R., Gershman, S.J., Markman, A.B., Daw, N.D., (2013) Psychol. Sci., 24, pp. 751-761; Lee, S.W., Shimojo, S., O'Doherty, J.P., (2014) Neuron, 81, pp. 687-699; Gelly, S., (2012) Commun. ACM, 55, pp. 106-113; Johnson, A., Redish, A.D., (2007) J. Neurosci., 27, pp. 12176-12189; Pfeiffer, B.E., Foster, D.J., (2013) Nature, 497, pp. 74-79; Mnih, V., (2015) Nature, 518, pp. 529-533; http://arxiv.org/abs/1412.6564, C. J. Maddison, A. Huang, I. Sutskever, D. Silver; Guo, X., Singh, S., Lee, H., Lewis, R., Wang, X., (2014) Adv. Neural Inf. Process. Syst., 27, pp. 3338-3346; Chaslot, G.M.J.-B., Bakkes, S., Szita, I., Spronck, P., (2008) Proc. Artif. Intell. Interact. Digit. Entertain. Conf., pp. 216-217. , (Stanford, CA",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Scheier C., Pfeifer R., Kunyioshi Y.",6701368473;7007140164;6504566373;,Embedded neural networks: Exploiting constraints,1998,Neural Networks,10.1016/S0893-6080(98)00084-7,https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032192328&doi=10.1016%2fS0893-6080%2898%2900084-7&partnerID=40&md5=8bc159d5273d6c0d619bd1c46ec00099,"Using concepts and tools of embodied cognitive science, we investigate the implications of embedding neural networks in a physical structure, the body of a robot. Embedding a neural network in a body provides constraints that can be exploited for learning. We show that the constraints are given by the environment and object properties, the agent's morphology, the agent's motor system and specific ways of interacting with the objects. We argue that designing embedded neural networks implies (a) understanding these constraints, and (b) exploiting them, i.e., designing neural networks such that they - one way or other - incorporate the constraints. This in turn results in cheap and simple networks that are suited for the task environment, and have real-time responses. Moreover, this constraint-based approach provides new perspectives on two fundamental problems of cognitive science: focus-of-attention and object constancy. The main arguments are illustrated with a series of case studies with simulated and physical mobile robots that are controlled by hand-designed as well as evolved neural networks.Using concepts and tools of embodied cognitive science, we investigate the implications of embedding neural networks in a physical structure, the body of a robot. Embedding a neural network in a body provides constraints that can be exploited for learning. We show that the constraints are given by the environment and object properties, the agent's morphology, the agent's motor system and specific ways of interacting with the objects. We argue that designing embedded neural networks implies (a) understanding these constraints, and (b) exploiting them, i.e., designing neural networks such that they - one way or other - incorporate the constraints. This in turn results in cheap and simple networks that are suited for the task environment, and have real-time responses. Moreover, this constraint-based approach provides new perspectives on two fundamental problems of cognitive science: focus-of-attention and object constancy. The main arguments are illustrated with a series of case studies with simulated and physical mobile robots that are controlled by hand-designed as well as evolved neural networks.",Adaptive behavior; Constraints; Embodiment; Learning,Real time systems; Robot learning; Robots; Constraints; Neural networks; adaptive behavior; artificial neural network; environment; learning; movement (physiology); priority journal; review; robotics; visuomotor coordination,"Abu-Mustafa, Y.S., Hints and the VC dimension (1992) Neural Computation, 5, pp. 278-288; Almassy, N., Edelman, G.M., Sporns, O., Behavioral constraints in the development of neuronal properties: A cortical model embedded in a real world device (1998) Cerebral Cortex, 8, pp. 346-361; Arkin, R., (1998) Behavior-based Robotics, , Cambridge, MA: MIT Press; Ashby, W.R., (1956) An Introduction to Cybernetics, , London: Chapman and Hall; Ballard, D., Hayhoe, M., Pook, K., Rao, R., Deictic codes for the embodiment of cognition (1997) Behavioral and Brain Sciences, 23, pp. 233-265; Bensinger, D.G., Hayhoe, M., Ballard, D., Visual memory in a natural task (1995) Investigative Ophthalmology and Visual Science, 36, p. 14; Brooks, R.A., Intelligence without representation (1991) Artificial Intelligence, 47, pp. 139-160; Chappell, G.J., Taylor, J.G., The temporal Kohonen map (1993) Neural Networks, 6, pp. 441-445; Chiel, H.J., Beer, R.D., The brain has a body: Adaptive behavior emerges from interactions of nervous system, body and environment (1997) Trends in Neuroscience, 20, pp. 553-557; Clark, A., Thornton, C., Trading spaces: Computation, representation and the limits of uninformed learning (1997) Behaviourial and Brain Sciences, 20, pp. 57-90; Garcia, M., Chatterjee, A., Ruina, A., Coleman, M., The simplest walking model: stability, complexity, and scaling ASME Journal of Biomechanical Engineering, , (in press). (in press); Glenberg, A.M., What memory is for? (1996) Behavioral and Brain Sciences, 20, pp. 1-55; Hertz, J., Krogh, A., Palmer, R.G., (1991) Introduction to the Theory of Neural Computation, , Redwood City, CA: Addison-Wesley; Horswill, I., Characterizing adaptation by constraint (1992) In Proceedings First European Conference Artificial Life, pp. 58-64. , In F. J. Varela, & P. Bourgine (Eds.), Toward a practice of autonomous systems. Cambridge, MA: MIT-Press; Horswill, I., A simple, cheap, and robust visual navigation system (1993) In Proceedings Second International Conference Simulation of Adaptive Behavior, pp. 129-136. , In J.-A. Meyer, H. L. Roitblat, & S. W. Wilson (Eds.), From animals to animats. Cambridge, MA: MIT Press (A Bradford Book); Maris, M., Te Boekhorst, R., Exploiting physical constraints: heap formation through behavioral error in a group of robots (1996) In Proceedings IROS'96, IEEE/RSJ International Conference on Intelligent Robots and Systems; Meier, D., (1997) Generalization and Constraints in Learning Machines, , Unpublished PhD thesis, Department of Computer Science, University of Zurich; Millar, S., (1994) Understanding and Representing Space, , Oxford: Oxford Science Publications; Montello, D.R., Presson, C.C., Movement and orientation in surrounding and imaginal spaces. (Manuscript cited in Glenberg, A. M. (1997)). What memory is for? (1993) Behavioral and Brain Sciences, 20, pp. 1-55; Nolfi, S., (1996) Adaptation As a More Powerful Tool Than Decomposition and Integration. Technical Report 96-03, , Department of Neural Systems and Artificial Life, Institute of Psychology, C.N.R., Rome, Italy; Pfeifer, R., Scheier, C., Sensory-motor coordination: The metaphor and beyond (1997) Robotics and Autonomous Systems, 20, pp. 157-178. , In R. Pfeifer, & R. Brooks (Eds.), (Special Issue on 'Practice and future of autonomous agents'); Pfeifer, R., Scheier, C., Understanding Intelligence, , (in press-a). Cambridge, MA: MIT Press; Pfeifer, R., Scheier, C., Representation in natural and artificial agents: an embodied cognitive science perspective Zeitschrift fuer Naturforschung [Section C, a Journal of Biosciences], , (in press-b); Pfeifer, R., Verschure, P.F.M.J., Distributed adaptive control: A paradigm for designing autonomous agents (1992) In Proceedings First European Conference on Artificial Life, pp. 21-30. , In F. J. Varela, & P. Bourgine (Eds.), Toward a practice of autonomous systems Cambridge, MA: MIT Press; Ruff, H.A., Infants' manipulative exploration of objects: Effects of age and object characteristics (1984) Development Psychology, 20, pp. 9-20; Salinas, E., Romo, R., Conversion of sensory signals into motor commands in primary cortex (1998) J. Neuroscience, 18 (10), pp. 499-511; Salomon, R., Neural networks in the context of autonomous agents: important concepts revisited (1996) Proceedings of the Artificial Neural Networks in Engineering (ANNIE'96), pp. 109-116. , In C. H. Dagli, M. Akay, C. L. P. Chen, B. R. Fernández, & J. Ghosh (Eds.), New York: ASME Press; Scheier, C., Pfeifer, R., Classification as sensory-motor coordination (1995) In Proceedings European Conference on Artificial Life, ECAL-95, pp. 656-667; Simons, D.J., Levin, D.T., Change blindness (1997) Trends in Cognitive Sciences, 1, pp. 261-267; Thelen, E., Smith, L., (1994) A Dynamic Systems Approach to the Development of Cognition and Action, , Cambridge, MA: MIT Press (Bradford Books); Thornton, C., Separability is a learner's best friend (1997) Proceedings Fourth Neural Computation and Psychology Workshop: Connectionist Representations, pp. 40-47. , In J. A. Bullinaria, D. W. Glasspool, & G. Houghton (Eds.), London: Springer; Thorpe, S.J., Imbert, M., Biological constraints on connectionist models (1989) Connectionism in Perspective, pp. 109-116. , In R. Pfeifer, Z. Schreter, & F. Fogelman-Soulie (Eds.), London: Wiley; Vapnik, V.N., Chervonenkis, A., On the uniform convergence of relative frequencies of events to their probabilities (1989) Theory Prob. Appl., 16, pp. 246-280; Wilson, S.W., The animat path to AI (1991) In Proceedings of the First International Conference on Simulation of Adaptive Behavior, pp. 15-21. , In J.-A. Meyer, & S. W. Wilson (Eds.), From animals to animats. Cambridge, MA: MIT Press (A Bradford Book)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,